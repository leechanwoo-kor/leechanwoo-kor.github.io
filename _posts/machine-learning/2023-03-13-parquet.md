---
title: "[Python] 파케이(Parquet)" 
categories:
  - Python
tags:
  - Parquet
toc: true
toc_sticky: true
toc_label: "파케이(Parquet)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/224581927-81db8be1-169a-486c-9f20-b42d4aa146de.png)

# 파케이(Parquet)

Pandas나 PySpark등을 사용하다보면 \*.csv 포맷으로는 만족하지 못하는 경우가 많다.

예를 들어
- Data Type이 저장되지 않는다.
- 너무 많은 데이터는 저장해도 CSV의 이점(엑셀로 열어볼 수 있다)을 살리지 못한다.
- 특정 Column만 선택하는 것이 불가능하다. (= 전체 파일을 항상 모두 열어야 한다)
- 용량이 상대적으로 작지만 크다 (압축을 하지 않은 경우)
- (종종) Escaping이 잘 되지 않은 경우에는 파일 Parsing이 깨진다.
- 한글이 들어간 csv의 경우 "MS Excel"에서는 BOM이 없으면 UTF-8을 제대로 인식하지 못한다. (한편, EUC-KR 인코딩은 잘 읽는다.)

등등 여러가지 이슈가 있다. 그렇다면 어떤 형식을 써야할까?

<br>

## CSV vs. JSON vs. Parquet

원본 데이터를 곧바로 가져다 사용하는 경우(=Athena, RedShift, BigQuery, DB 등이 데이터소스가 아닌 경우)에는 보통 csv, json, parquet 이 세가지 형식이 가장 범용적이다.

그 중에서도 특히 csv와 json을 자주 사용한다.

작은 데이터의 경우 csv를, API에서는 json을 제공하는 경우가 많다.

![image](https://user-images.githubusercontent.com/55765292/224583064-fa983a95-cf2e-4860-8111-e48f8bafd404.png){: .align-center}

그림에서 볼 수 있듯 파일 형식에 따라 표현할 수 있는 방식이 다르다.

하지만 결론은 대부분 "Parquet 파일을 써라!" 인 경우가 많다.

<br>

## 컬럼기반 저장 포맷

컬럼기반(열 지향) 데이터베이스는 컬럼단위로 데이터가 저장이 된다. 그래서 데이터를 미리 컬럼단위로 압축시키고, 필요한 컬럼만 빠르게 읽고, 집계하는데 있어서 빠르다.

- 일반적인 데이터구조

![image](https://user-images.githubusercontent.com/55765292/224584013-0be64d4a-a56c-46eb-abd4-d2e9fecc3e67.png){: .align-center}

<사람들이 생각하는 데이터 구조>{: .text-center}

- 행 기반 저장 방식

![image](https://user-images.githubusercontent.com/55765292/224584034-d05d1668-801d-4a05-95ee-ee247da8417f.png){: .align-center}

<실제 데이터 저장 방식>{: .text-center}

- 컬럼 기반의 저장 방식

![image](https://user-images.githubusercontent.com/55765292/224584048-f4e702d9-e0ef-4414-94a6-5e05c92c014a.png){: .align-center}

<Parquet 형식의 데이터 저장 방식>{: .text-center}

마찬가지로 컬럼기반 저장포맷인 파케이의 목적도 필요한 데이터만 디스크로부터 읽어 I/O를 최소화하고, 데이터 크기를 줄이는 것이다.

<br>

## Parquet의 장점

컬럼 기반의 저장 방식이 주는 이점 세가지를 들 수 있습니다.

1. 압축률이 더 좋다. 유사한 데이터들이 모여있기 때문에 데이터들이 많이 모이면 압축하기가 좋습니다. 이는 압축 방식에 대한 이해가 필요합니다.
2. I/O 사용률이 줄어든다. 데이터를 읽어 들일 때 일부 컬럼만을 스캔하기 때문입니다.
3. 컬럼별로 적합한 인코딩을 사용할 수 있다. 각 컬럼의 데이터들은 동일한 유형의 데이터를 저장하기 때문입니다. 따라서 컬럼마다 서로 다른 (데이터형에 유리한) 인코딩을 사용할 수 있습니다.

<br>

## 파일 타입별 벤치마크

<br>

### 파일 형식에 따른 데이터 저장, 로드 시간 비교

- csv는 로드/저장시 high comp low io로 처리할 수 있다. 호환성이 뛰어나고 변환 가능한 포맷에서는 위력을 발휘할 수 있다. 하지만 특정 데이터를 다룬다면 다른 포맷을 꼭 확인해 봐야한다.

![image](https://user-images.githubusercontent.com/55765292/224584378-9cc82b53-4602-4c3c-b711-510459e31877.png){: .align-center}

<br>

- 메모리 관련하여 hdf은 좋지 않은 성능을 보여준다. csv는 저장 /로드 일반 텍스트 문자열 동안 추가 메모리를 필요하지 않는다.(바로 저장한다) feather와 parquet 매우 좋은 성능을 나타낸다.

![image](https://user-images.githubusercontent.com/55765292/224584418-68bb0fb5-d800-40a2-bc4c-52a5c097d3d7.png){: .align-center}

<br>

- 파일 크기. parquet 형식은 대량의 데이터를 효율적으로 저장하기 위해 개발되었다.

![image](https://user-images.githubusercontent.com/55765292/224584444-f0c0a6d0-8b65-49e3-8228-70a614d7700d.png){: .align-center}

