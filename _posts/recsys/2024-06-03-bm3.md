---
title: "[Recommendation System] Bootstrap Latent Representations for Multi-modal Recommendation"
categories:
  - Recommendation System
tags:
  - Recommendation System
toc: true
toc_sticky: true
toc_label: "Bootstrap Latent Representations for Multi-modal Recommendation"
toc_icon: "sticky-note"
---

# ABSTRACT

본 논문에서는 추천 정확도를 향상시키기 위해 이미지와 텍스트 설명과 같은 아이템의 멀티 모달 정보를 활용하는 멀티 모달 추천 문제를 연구합니다.

기존의 최신 방식은 사용자-아이템 상호작용 그래프 외에도 사용자 및/또는 아이템의 학습된 표현을 보강하기 위해 보조 그래프(예: 사용자-사용자 또는 아이템-아이템 관계 그래프)를 사용하는 것이 일반적입니다. 이러한 표현은 종종 그래프 컨볼루션 네트워크를 사용하여 보조 그래프에서 전파되고 집계되는데, 특히 큰 그래프의 경우 계산과 메모리 비용이 엄청나게 많이 들 수 있습니다.

또한 기존의 멀티 모달 추천 방법은 일반적으로 베이지안 개인화 랭킹(Bayesian Personaliaed Ranking, BPR) 손실에서 무작위로 샘플링된 부정적 예시를 활용하여 사용자/아이템 표현의 학습을 유도하므로 큰 그래프에서 계산 비용이 증가하고 훈련 과정에 노이즈 감독 신호가 발생할 수도 있습니다.

위의 문제를 해결하기 위해, 저희는 보조 그래프의 증강이나 네거티브 샘플이 필요 없는 새로운 자체 감독 멀티 모달 추천 모델인 BM3를 제안합니다. 구체적으로 BM3는 먼저 간단한 드롭아웃 증강을 통해 사용자와 아이템의 표현에서 잠재적인 대조적 보기를 부트스트랩합니다. 그런 다음 사용자-아이템 상호작용 그래프를 재구성하고 모달리티 간 및 모달리티 내 관점에서 모달리티 특징을 정렬하여 사용자와 아이템의 표현을 학습하기 위해 세 가지 멀티모달 목표를 공동으로 최적화합니다. BM3는 부정적인 예시와 대조해야 하는 필요성과 대조 보기 생성을 위한 추가 대상 네트워크의 복잡한 그래프 증강을 모두 완화합니다. BM3는 노드 수가 20만 개에서 20만 개에 이르는 세 가지 데이터 세트에서 기존 추천 모델보다 성능이 뛰어나면서도 학습 시간을 2~9배 단축하는 것으로 나타났습니다.

코드 구현은 [https://github.com/enoche/BM3](https://github.com/enoche/BM3)

# CCS CONCEPTS

- 정보 시스템(Information systems) → 추천 시스템(Recommender systems).

# KEYWORD

멀티 모달 추천(Multi-modal Recommendation), 부트스트랩(Bootstrap), 자기 지도 학습(Self-supervised learning)

## ACM Reference Format:

Xin Zhou, Hongyu Zhou, Yong Liu, Zhiwei Zeng, Chunyan Miao, Pengwei Wang, Yuan You, and Feijun Jiang. 2023. Bootstrap Latent Representations for Multi-modal Recommendation. In Proceedings of the ACM Web Conference 2023 (WWW ’23), April 30-May 4, 2023, Austin, TX, USA. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3543507.3583251

# INTRODUCTION

빠르게 성장하는 이커머스 비즈니스에서 추천 시스템은 사용자가 수백만 개의 상품 중에서 마음에 드는 상품이나 서비스를 찾을 수 있도록 돕는 중요한 역할을 합니다. 실제로 딥러닝 기술은 주로 과거 사용자와 아이템 간의 상호작용을 활용하여 아이템에 대한 사용자의 선호도를 모델링하고 사용자에게 아이템을 추천하기 위해 추천 시스템에 널리 적용되어 왔습니다. 그러나 아이템의 풍부한 멀티모달 콘텐츠 정보(예: 텍스트, 이미지, 동영상)는 아직 완전히 탐색되지 않았습니다.

추천 정확도를 높이기 위해 최근 멀티모달 추천에 관한 연구에서는 기존의 사용자-아이템 추천 패러다임에 아이템 멀티모달 정보를 통합하는 효과적인 방법을 연구하고 있습니다. 예를 들어, 일부 방법은 멀티모달 특징을 아이템의 잠재적 표현과 연결하거나, 주의 메커니즘을 활용하여 아이템의 멀티모달 특징에 대한 사용자의 선호도를 파악합니다. 그래프 기반 추천에 대한 연구가 급증하면서, 그래프 신경망(GNN)을 사용하여 아이템 멀티모달 정보를 활용하고 사용자 및 아이템 표현의 학습을 강화하는 연구도 있습니다. 예를 들어, 그래프 컨볼루션 네트워크를 사용하여 사용자-아이템 상호작용 그래프에서 다양한 아이템 멀티모달 정보를 개별적으로 전파하고 집계합니다. 추천 성능을 더욱 향상시키기 위해 사용자-사용자 관계 그래프 및 아이템-아이템 관계 그래프 와 같은 다른 보조 그래프 구조도 멀티모달 정보로부터 사용자 및 아이템 표현의 학습을 향상시키는 데 활용되었습니다.

기존의 GNN 기반 멀티모달 방법은 최첨단 추천 정확도를 달성할 수 있지만, 대규모 그래프가 포함된 시나리오에서는 다음과 같은 문제로 인해 적용에 어려움을 겪을 수 있습니다. 첫째, 관찰된 사용자-아이템 상호작용 쌍을 양수 샘플로, 무작위로 샘플링된 사용자-아이템 쌍을 음수 샘플로 취급하는 베이지안 개인화 랭킹(BPR) 손실과 같은 쌍별 랭킹 손실을 기반으로 사용자 및 아이템 표현을 학습하는 경우가 많습니다. 이러한 네거티브 샘플링 전략은 큰 그래프에서 엄청난 비용을 초래할 수 있으며, 훈련 프로세스에 잡음이 많은 감독 신호를 가져올 수 있습니다. 예를 들어, 이전 연구에 따르면 LightGCN의 기본 균일 샘플링은 에포크당 25% 이상의 훈련 시간을 소모하는 것으로 확인되었습니다. 둘째, 보조 그래프 구조를 활용하는 방법은 대규모 보조 그래프를 구축하거나 훈련할 때 엄청난 메모리 비용이 발생할 수 있습니다. 기존 그래프 기반 멀티모달 방법의 계산 복잡성에 대한 자세한 분석은 표 1과 표 4에서 확인할 수 있습니다.

자기 지도 학습(Self-Supervised Learning, SSL)은 부정적인 샘플 없이 사용자와 아이템의 표현을 학습할 수 있는 솔루션을 제공합니다. 컴퓨터 비전(Computer Vision, CV)에서 자연어 처리(Natural Language Processing, NLP)에 이르는 다양한 영역의 연구에 따르면 SSL은 지도 학습보다 경쟁력이 있거나 더 나은 결과를 얻을 수 있는 것으로 나타났습니다. SSL의 주요 아이디어는 두 개의 비대칭 네트워크, 즉 온라인 네트워크와 목표 네트워크를 사용하여 샘플의 서로 다른 왜곡된 버전에서 얻은 표현의 유사성을 극대화하는 것입니다. 그러나 양성 샘플로만 훈련하면 모델이 사소한 상수 해에 빠지게 됩니다. 이러한 붕괴 문제를 해결하기 위해 BYOL과 SimSiam은 온라인 네트워크에 추가 "예측자" 네트워크를 도입하고 목표 네트워크에 특별한 "기울기 정지" 연산을 도입했습니다. 최근 BUIR은 BYOL을 추천 영역으로 이전하여 평가 데이터 세트에서 경쟁력 있는 성능을 보여줍니다.

이 논문에서는 멀티모달 추천을 위한 부트스트랩 멀티모달 모델(**B**ootstrapped **M**ulti-**M**odal **M**odel, BM3)을 제안합니다. 이 모델은 먼저 대상 네트워크를 제거하여 현재의 SSL 프레임워크를 단순화함으로써 모델 파라미터의 절반을 줄일 수 있습니다. 또한 BM3는 서로 다른 증강 간의 유사성을 유지하기 위해 온라인 네트워크에서 생성된 잠재적 임베딩을 교란하는 간단한 드롭아웃 메커니즘을 통합합니다. 이는 그래프 증강 또는 이미지 증강을 통해 입력을 교란하는 현재의 SSL 패러다임과는 다릅니다. 이 설계는 보조 그래프를 도입하지 않기 때문에 기존 그래프 증강 기법의 메모리와 계산 비용을 모두 절감할 수 있습니다. 마지막으로, 멀티모달 추천에 특화된 손실 함수를 설계했습니다. 이는 사용자-아이템 상호작용 그래프의 재구성 손실을 최소화하고 모달리티 간 및 모달리티 내 관점에서 학습된 특징을 정렬합니다.

주요 기여 사항을 요약하면 다음과 같습니다. 첫째, 멀티 모달 추천을 위한 새로운 자기 지도 학습 방법인 BM3를 제안합니다. BM3에서는 그래프 증강 대신 간단한 잠재 표현 드롭아웃 메커니즘을 사용해 음수 샘플 없이 대조 학습을 위한 사용자 또는 아이템의 목표 보기를 생성합니다. 둘째, 네거티브 샘플 없이 BM3를 훈련하기 위해 세 가지 목표를 공동으로 최적화하는 다중 모드 대비 손실(Multi-Modal Contrastive Loss, MMCL) 함수를 설계합니다. 기존의 사용자-아이템 상호 작용 그래프 재구성 손실을 최소화하는 것 외에도 MMCL은 서로 다른 모달리티 간에 학습된 특징을 더욱 정렬하고 특정 모달리티에서 다른 증강 뷰의 표현 간의 불일치를 줄입니다. 마지막으로 노드 수가 20만 개에서 200만 개에 이르는 세 가지 데이터 세트에서 BM3의 효과와 효율성을 검증합니다. 실험 결과, BM3는 최신 멀티 모달 추천 방식에 비해 상당한 개선을 달성하는 동시에 기본 방식보다 2~9배 빠르게 학습하는 것으로 나타났습니다.

# 2. RELATED WORK

## 2.1 Multi-modal Recommendation

### 2.1.1 딥러닝 기반 모델(Deep Learning-based Models).

협업 필터링(Collaborative Filtering, CF) 방식의 성공으로 인해 대부분의 초기 멀티모달 추천 모델은 CF 패러다임 위에 사용자의 선호도를 탐색하는 딥러닝 기법을 활용합니다. 예를 들어, BPR방식을 기반으로 구축된 VBPR은 아이템의 시각적 특징을 활용합니다. 사전 학습된 컨볼루션 신경망을 활용하여 아이템의 시각적 특징을 파악하고 이를 잠재 시각 공간으로 선형적으로 변환합니다. 예측을 위해 VBPR은 잠재 시각적 특징과 ID 임베딩을 연결하여 아이템을 표현합니다. 또한, 딥스타일은 BPR 프레임워크 내에서 시각적 특징과 스타일 특징을 모두 사용하여 아이템의 표현을 보강합니다. 멀티모달 정보에 대한 사용자의 선호도를 파악하기 위해 추천 모델에도 주의 메커니즘이 채택되었습니다. 예를 들어, VECF는 VGG 모델을 활용하여 이미지에 대한 사전 세분화를 수행하고 다양한 이미지 영역에 대한 사용자의 관심을 포착합니다. MAML은 2계층 신경망을 사용하여 아이템의 텍스트 및 시각적 특징에 대한 사용자의 선호도를 파악합니다.

### 2.1.2 그래프 기반 멀티모달 모델(Graph-based Multi-modal Models).

최근에는 추천 시스템에 GNN을 도입한 또 다른 연구에서 사용자-아이템 상호작용 그래프와 보조 그래프에 구조 정보를 통합하여 사용자 및 아이템 표현을 크게 향상시킬 수 있습니다. 아이템 멀티 모달 정보를 활용하기 위해 MMGCN은 그래프 컨볼루션 네트워크(GCN)의 메시지 전달 메커니즘을 채택하고 모달별 사용자-아이템 이분 그래프를 구성하여 멀티 홉 이웃의 정보를 캡처하여 사용자 및 아이템 표현을 향상시킬 수 있습니다. MMGCN을 기반으로 하는 DualGNN은 모델 선호도 학습 모듈이 포함된 사용자 동시 발생 그래프를 도입하여 아이템의 여러 모달리티에서 사용자의 선호도를 파악합니다. 사용자-아이템 그래프에 의도하지 않은 상호작용이 포함될 수 있으므로 GRCN은 노이즈 에지를 식별하고 오탐 에지를 보정하여 사용자-아이템 상호작용 그래프의 구조를 개선하는 그래프 정제 계층을 도입합니다. 아이템 간의 의미 정보를 명시적으로 마이닝하기 위해 LATTICE는 각 양식에 대해 아이템-아이템 관계 그래프를 구성하고 이를 융합하여 잠재 아이템 그래프를 얻습니다. 이 그래프는 GCN을 사용하여 아이템의 정보가 고도로 연결된 친화성으로부터 전파되고 집계된 후 동적으로 업데이트됩니다. FREEDOM은 아이템-아이템 그래프의 학습이 무시할 수 있는 수준임을 감지하고 효과적이고 효율적인 추천을 위해 그래프를 동결합니다.

그래프 기반 멀티모달 모델은 새로운 최첨단 추천 정확도를 달성하지만, 사용자 및 아이템 증강을 위한 보조 그래프가 필요하고 BPR 손실이 있는 표현 학습을 위해 많은 수의 네거티브가 필요한 경우가 많습니다. 이 두 가지 요구 사항은 그래프 크기가 증가함에 따라 높은 계산 복잡성과 엄청난 메모리 비용으로 이어질 수 있으며, 대규모 그래프가 필요한 시나리오에서 이러한 모델의 효율성을 제한할 수 있습니다.

## 2.2 Self-supervised Learning (SSL)

SSL 기반 방법은 다양한 CV 및 NLP 작업에서 경쟁력 있는 결과를 달성했습니다. 우리 모델은 관찰된 데이터만 사용하는 SSL을 기반으로 하므로, SSL 방법에 대한 검토는 네거티브 샘플링이 필요하지 않은 방법에 초점을 맞춥니다.

현재 SSL 프레임워크는 엔티티 비교를 위한 일반적인 모델인 샴 네트워크에서 파생되었습니다. BYOL과 SimSiam은 비대칭 샴 네트워크를 사용하여 놀라운 결과를 달성합니다. 특히 BYOL은 최적화되고 반복적으로 업데이트되는 두 개의 결합 인코더(즉, 온라인 인코더와 대상 인코더)를 제안합니다. 온라인 인코더는 타깃 인코더에 최적화되어 있고 타깃 인코더는 모멘텀 인코더입니다. 목표 인코더의 매개변수는 온라인 인코더의 지수 이동 평균으로 업데이트됩니다. BYOL은 네트워크 붕괴를 방지하기 위해 온라인 인코더의 예측자와 타깃 인코더의 "정지 기울기" 연산자를 모두 사용합니다. 심시암은 "스톱 그라데이션" 연산자가 붕괴를 방지하는 데 중요하다는 것을 확인합니다. 그러나 온라인 인코더와 타겟 인코더 간에 매개변수를 공유합니다. 반대로 Barlow Twins는 두 개의 대조적 표현에서 계산된 교차 상관 행렬을 가능한 한 동일성 행렬에 가깝게 정렬할 수 있는 혁신적인 목적 함수를 설계하여 대칭 아키텍처를 사용합니다.

최근 제안된 자가 지도 프레임워크인 BUIR은 BYOL에서 파생된 것으로, 긍정적인 상호작용을 통해서만 사용자와 아이템의 표현을 학습합니다. 이 프레임워크는 다양한 보기를 도입하고 느리게 움직이는 평균 네트워크를 활용하여 온라인 인코더로 대상 인코더의 파라미터를 업데이트합니다. 동일한 입력이 서로 다르지만 관련성이 있는 인코더에 공급되어 대조적인 보기를 생성합니다.

CV와 NLP에서 SSL이 급성장함에 따라 멀티모달 기능이 추천에서 SSL 패러다임에 따라 사용자와 아이템의 표현을 향상시킬 수 있는지 여부와 그 방법은 아직 밝혀지지 않았습니다. 이 논문에서는 멀티모달 추천을 위한 단순하면서도 매우 효율적인 SSL 모델을 제안합니다. 이 모델은 큰 그래프에서 계산 복잡성과 메모리 비용을 줄이면서 뛰어난 정확도를 달성할 수 있습니다.

# 3 BOOTSTRAPPED MULTI-MODAL MODEL

이 섹션에서는 그림 1에 표시된 것처럼 a) 멀티모달 잠재 공간 변환기, b) 대비 뷰 생성기, c) 멀티모달 대비 손실의 세 가지 구성 요소를 포함하는 부트스트랩 멀티모달 모델에 대해 자세히 설명합니다.

# 3.1 Multi-modal Latent Space Convertor

$e_u, e_i \in \mathbb{R}^𝑑$는 사용자 $u \in U$와 아이템 $i \in I$의 입력 ID 임베딩을 나타내며, 여기서 $d$는 임베딩 차원이고 $U$, $I$는 각각 사용자 및 아이템의 집합입니다. 이들의 기본 번호는 각각 $\vert U \vert$와 $\vert I \vert$로 설정됩니다. 사전 학습된 모델에서 얻은 양식별 특징을 $e_m \in \mathbb{R}^{d_m}$로 표시하며, 여기서 $m \in M$은 전체 양식 집합 $M$에서 특정 양식을 나타내고, $d_m$는 특징의 차원을 나타냅니다. $M$의 기본 수는 $\vert M \vert$으로 표시됩니다. 이 논문에서는 시각 $v$와 텍스트 $t$라는 두 가지 모달리티를 고려합니다. 그러나 이 모델은 두 가지 이상의 모달리티가 있는 시나리오로 쉽게 확장할 수 있습니다. 멀티 모달 특징 공간은 서로 다르므로 먼저 멀티 모달 특징과 ID 임베딩을 동일한 잠재 공간으로 변환합니다.

### 3.1.1 다중 모달 특징(Multi-modal Features).

서로 다른 모달리티에서 얻은 아이템의 특징은 서로 다른 차원과 서로 다른 특징 공간에 있습니다. 다중 모달 특징 벡터 $e_m$의 경우 먼저 다층 퍼셉트론(MLP) 기반의 투영 함수 𝑓𝑚를 사용하여 이를 잠재 저차원으로 투영합니다. 그런 다음

$h_m = e_m W_m + b_m, (1)$

여기서 $W_m \in \mathbb{R}^{d_m \times d}, b_m \in \mathbb{R}^d$는 $f_m$의 MLP에서 선형 변환 행렬과 바이어스를 나타냅니다. 이러한 방식으로 각 단일 모달 잠재 표현 $h_m$는 ID 임베딩과 동일한 공간을 공유합니다.

### 3.1.2 ID 임베딩(ID Embeddings).

이전 연구에서는 멀티모달 추천에서 ID 임베딩이 중요한 역할을 한다는 것을 확인했습니다. 사용자와 아이템의 ID 임베딩은 잠재 공간 내에서 직접 초기화할 수 있지만, 사용자-아이템 상호작용 그래프에 대한 구조적 정보를 인코딩하지는 않습니다. 최근 추천에 GCN을 적용한 성공 사례에서 영감을 얻어, 잔존 연결이 있는 LightGCN의 백본 네트워크를 사용하여 사용자-아이템 상호작용 그래프의 구조를 인코딩합니다.

노드 집합 $V = U \cup I$, 에지 집합 $E$를 가진 주어진 그래프 $G = (V, E)$를 노드 수는 $\vert V \vert$로, 에지 수는 $\vert E \vert$로 표시한다고 가정합니다. 인접 행렬은 $A \in \mathbb{R}^{\vert V \vert \times \vert V \vert}$로 표시되고 대각도 행렬은 $D$로 표시됩니다. $G$에서 에지는 관찰된 사용자-아이템 상호작용을 설명합니다. 사용자가 아이템과 상호작용을 하는 경우, 사용자 노드와 아이템 노드 사이에 에지를 구축합니다. 또한, 사용자 및 아이템의 모든 임베딩을 $l$ 계층에 쌓아 $l$ 번째 계층의 ID 임베딩을 나타내기 위해 $H^l \in \mathbb{R}^{\vert V \vert \times d}$를 사용합니다. 구체적으로, 초기 ID 임베딩 $H^0$은 모든 사용자와 아이템의 임베딩 $e_u$와 $e_i$의 모음입니다. 레이어 $l + 1$에서 숨겨진 ID 임베딩 $H^{l+1}$을 계산하기 위한 일반적인 피드 포워드 전파 GCN은 다음과 같이 재귀적으로 수행됩니다:

$H^{l + 1} = \sigma \bigg(\hat{A}H^lW^l\bigg), (2)$

여기서 $\sigma(\cdot)$는 비선형 함수입니다, ReLu 함수, $\hat{A} = \hat{D}^{-1/2} (A+I) \hat{D}^{-1/2}$는 인접 행렬 $A$의 재노멀라이제이션, $\hat{D}$는 $A + I$의 대각도 행렬입니다. 노드 분류를 위해 GCN의 마지막 계층은 $softmax$ 분류기를 통해 노드의 라벨을 예측하는 데 사용됩니다.

LightGCN은 바닐라 GCN에 더해 추천을 위해 특징 변환 $W^l$와 비선형 활성화 $\sigma(\cdot)$ 레이어를 제거하여 구조를 단순화합니다. 이 두 레이어가 추천 성능에 부정적인 영향을 미친다는 사실을 발견했기 때문입니다. LightGCN의 단순화된 그래프 컨볼루션 레이어는 다음과 같이 정의됩니다:

$H^{l+1} = (D-^{1/2}AD^{-1/2})H^l, (3)$

여기서 $(l + 1)$번째 숨겨진 레이어의 노드 임베딩은 $l$ 번째 레이어에서 전이 행렬 $D^{-1/2}AD^{-1/2}$를 사용하여 선형적으로만 집계됩니다. 전이 행렬은 위에서 언급한 가중치 인접 행렬과 정확히 일치합니다.

사용자 및 아이템 최종 표현을 위해 숨겨진 레이어의 모든 표현을 집계하기 위해 판독 함수를 사용합니다. 그러나 GCN은 과도한 평활화 문제를 겪을 수 있습니다. LATTICE에 이어, 항목의 최종 표현을 얻기 위해 항목 초기 임베딩 $H^0_i$에 잔여 연결을 추가합니다. 즉, 다음과 같습니다:

$H_u = READOUT(H^0_u, H^1_u, H^2_u, \dots, H^L_u);$

$H_i = READOUT(H^0_i, H^1_i, H^2_i, \dots, H^L_i) + H^0_i, (4)$

여기서 READOUT 함수는 어떤 미분 가능한 함수가 될 수 있습니다. 최종 ID 임베딩 업데이트에는 LightGCN의 기본 평균 함수를 사용합니다.

멀티모달 잠재 공간 변환기를 사용하면 사용자 ID 임베딩, 아이템 ID 임베딩, 단일 모달 아이템 임베딩의 세 가지 유형의 잠재 임베딩을 얻을 수 있습니다. 다음 섹션에서는 음수 샘플 없이 효율적인 파라미터 최적화를 위해 BM3에서 손실을 설계하는 방법을 설명합니다.

![image](https://github.com/leechanwoo-kor/leechanwoo-kor.github.io/assets/55765292/8efda952-d76f-4491-b791-4775df785ea7)

## 3.2 Multi-modal Contrastive Loss

SSL에 대한 이전 연구에서는 모델이 사소한 상수 해를 도출하는 것을 방지하기 위해 정지-그라데이션 전략을 사용했습니다. 또한, 온라인 및 타겟 네트워크를 사용하여 모델 매개변수를 교사-학생 방식으로 학습하도록 합니다. BM3는 데이터 증강을 온라인 네트워크의 인코딩 이후로 연기함으로써 현재의 SSL 패러다임을 단순화합니다. 먼저 BM3의 데이터 증강을 설명합니다.

### 3.2.1 대비 뷰 생성기(Contrastive View Generator).

선행 연구에서는 그래프 증강을 사용하여 자기 지도 학습을 위해 원본 그래프의 두 가지 대체 보기를 생성합니다. 입력된 특징은 두 그래프를 통해 인코딩되어 대비 보기를 생성합니다. 계산 복잡성과 메모리 비용을 줄이기 위해 BM3는 노드 드롭아웃과 유사한 간단한 잠재 임베딩 드롭아웃 기법을 사용하여 그래프 증강의 필요성을 제거합니다. 드롭아웃 비율 $p$에서 $h$의 대조적 잠재 임베딩 $\dot{h}$는 다음과 같이 계산됩니다:

$\dot{h} = h \cdot Bernoulli(p). (5)$

원래의 임베딩 $h$를 MLP의 예측자에 공급하는 동안 대비 뷰 $\dot{h}$에도 정지 그라데이션을 배치합니다.

$\tilde{h} = hW_p + b_p, (6)$

여기서 $W_p \in \mathbb{R}^{d \times d}, b_p \in \mathbb{R}^d$ 는 선형 변환 행렬과 예측자 함수 $f_p$ 의 바이어스를 나타냅니다.

### 3.2.2 그래프 재구성 손실(Graph Reconstruction Loss).

BM3는 양의 사용자-아이템 쌍$(u,i)$을 입력으로 받습니다. 생성된 온라인 표현 $(\dot{h}_u, \dot{h}_i)$의 대조적 보기$(\tilde{h}_u, \tilde{h}_i)$를 사용해 대칭화된 손실 함수를 $(\tilde{h}_u, \dot{h}_i)$와 $(\dot{h}_u, \tilde{h}_i)$ 사이의 음의 코사인 유사성으로 정의합니다:

$\mathcal{L}_{rec} = C(\tilde{h}_u, \dot{h}_i) + C(\dot{h}_u, \tilde{h}_i). (7)$

위 방정식에서 함수 $C(\cdot, \cdot)$는 다음과 같이 정의됩니다:

$C(h_u, h_i) = - \dfrac{h^𝑇_u h_i}{\Vert h_u \Vert _2 \Vert h_i \Vert _2}, (8)$

여기서 $\Vert \cdot \Vert _2$는 l2-norm입니다. 총 손실은 모든 사용자-아이템 쌍에 대한 평균입니다. 여기에는 사용자 $u$가 주어졌을 때 긍정적으로 교란된 항목 $i$의 예측을 최대화하려는 의도와 그 반대의 경우도 마찬가지라는 직관이 숨어 있습니다. 이 손실의 가능한 최소값은 -1입니다.

마지막으로, 대상 네트워크에서 기울기를 중지하고 온라인 네트워크에서만 손실의 역전파를 강제합니다. 스톱 그라디언트$(sg)$ 연산자를 따르고 식 (7)을 다음과 같이 업데이트하여 연산자를 구현합니다:

$\mathcal{L}_{rec} = C(\tilde{h}_u, sg(\dot{h}_i)) + C(sg(\dot{h}_u), \tilde{h}_i). (9)$

정지 기울기 연산자를 사용하면 대상 네트워크는 $(\dot{h}_u, \dot{h}_i)$에서 기울기를 수신하지 않습니다.

### 3.2.3 모달리티 간 특징 정렬 손실(Inter-modality Feature Alignment Loss).

또한, 항목의 멀티 모달 특징을 대상 ID 임베딩과 추가로 정렬합니다. 이 정렬은 유사한 멀티모달 특징을 가진 아이템의 ID 임베딩이 서로 가깝게 정렬되도록 유도합니다. 항목 $i$의 각 단일 모달 잠재 임베딩 $h_m$에 대해 대비 보기 생성기는 대비 쌍을 $(\tilde{h}^i_m, \dot{h}^i_m)$로 출력합니다. 음의 코사인 유사도를 사용하여 $\dot{h}_i$와 $\tilde{h}^i_m$ 사이의 정렬을 수행합니다:

$\mathcal{L}_{align} = C(\tilde{h}^i_m, \dot{h}_i). (10)$

### 3.2.4 모달리티 내 특징 마스크 손실(Intra-modality Feature Masked Loss.

마지막으로 BM3는 모달리티 내 특징 마스크 손실을 사용하여 잠재 임베딩의 스파스 표현으로 예측자의 학습을 더욱 장려합니다. 스파스는 대규모 트랜스포머에서 규모 효율성이 입증되었습니다. 콘트라스트 뷰 생성기를 사용하여 잠재 임베딩의 하위 집합 $h_m$를 드롭아웃으로 무작위로 마스킹하고 희소 임베딩을 $\dot{h}^i_m$로 표시합니다. 모달리티 내 특징 마스크 손실은 다음과 같이 정의됩니다:

$\mathcal{L}_{mask} = C(\tilde{h}^i_m, \dot{h}^i_m). (11)$

또한 온라인 임베딩(즉, $h_u$ 및 $h_i$)에 정규화 페널티를 추가합니다. 최종 손실 함수는 다음과 같습니다:

$\mathcal{L}$ = $\mathcal{L}_{rec}$ + $\mathcal{L}_{align}$ + $\mathcal{L}_{mask}$ + $\lambda \cdot (\Vert h_u \Vert^2_2 + \Vert h_i \Vert^2_2). (12)$

## 3.3 Top-K Recommendation

