---
title: "[Recommendation System] Bootstrap Latent Representations for Multi-modal Recommendation"
categories:
  - Recommendation System
tags:
  - Recommendation System
toc: true
toc_sticky: true
toc_label: "Bootstrap Latent Representations for Multi-modal Recommendation"
toc_icon: "sticky-note"
---

## ABSTRACT

본 논문에서는 추천 정확도를 향상시키기 위해 이미지와 텍스트 설명과 같은 아이템의 멀티 모달 정보를 활용하는 멀티 모달 추천 문제를 연구합니다.

기존의 최신 방식은 사용자-아이템 상호작용 그래프 외에도 사용자 및/또는 아이템의 학습된 표현을 보강하기 위해 보조 그래프(예: 사용자-사용자 또는 아이템-아이템 관계 그래프)를 사용하는 것이 일반적입니다. 이러한 표현은 종종 그래프 컨볼루션 네트워크를 사용하여 보조 그래프에서 전파되고 집계되는데, 특히 큰 그래프의 경우 계산과 메모리 비용이 엄청나게 많이 들 수 있습니다.

또한 기존의 멀티 모달 추천 방법은 일반적으로 베이지안 개인화 랭킹(Bayesian Personaliaed Ranking, BPR) 손실에서 무작위로 샘플링된 부정적 예시를 활용하여 사용자/아이템 표현의 학습을 유도하므로 큰 그래프에서 계산 비용이 증가하고 훈련 과정에 노이즈 감독 신호가 발생할 수도 있습니다.

위의 문제를 해결하기 위해, 저희는 보조 그래프의 증강이나 네거티브 샘플이 필요 없는 새로운 자체 감독 멀티 모달 추천 모델인 BM3를 제안합니다. 구체적으로 BM3는 먼저 간단한 드롭아웃 증강을 통해 사용자와 아이템의 표현에서 잠재적인 대조적 보기를 부트스트랩합니다. 그런 다음 사용자-아이템 상호작용 그래프를 재구성하고 모달리티 간 및 모달리티 내 관점에서 모달리티 특징을 정렬하여 사용자와 아이템의 표현을 학습하기 위해 세 가지 멀티모달 목표를 공동으로 최적화합니다. BM3는 부정적인 예시와 대조해야 하는 필요성과 대조 보기 생성을 위한 추가 대상 네트워크의 복잡한 그래프 증강을 모두 완화합니다. BM3는 노드 수가 20만 개에서 20만 개에 이르는 세 가지 데이터 세트에서 기존 추천 모델보다 성능이 뛰어나면서도 학습 시간을 2~9배 단축하는 것으로 나타났습니다.

코드 구현은 [https://github.com/enoche/BM3](https://github.com/enoche/BM3)

## CCS CONCEPTS

- 정보 시스템(Information systems) → 추천 시스템(Recommender systems).

## KEYWORD

멀티 모달 추천(Multi-modal Recommendation), 부트스트랩(Bootstrap), 자기 지도 학습(Self-supervised learning)

### ACM Reference Format:

Xin Zhou, Hongyu Zhou, Yong Liu, Zhiwei Zeng, Chunyan Miao, Pengwei Wang, Yuan You, and Feijun Jiang. 2023. Bootstrap Latent Representations for Multi-modal Recommendation. In Proceedings of the ACM Web Conference 2023 (WWW ’23), April 30-May 4, 2023, Austin, TX, USA. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3543507.3583251

## INTRODUCTION

빠르게 성장하는 이커머스 비즈니스에서 추천 시스템은 사용자가 수백만 개의 상품 중에서 마음에 드는 상품이나 서비스를 찾을 수 있도록 돕는 중요한 역할을 합니다. 실제로 딥러닝 기술은 주로 과거 사용자와 아이템 간의 상호작용을 활용하여 아이템에 대한 사용자의 선호도를 모델링하고 사용자에게 아이템을 추천하기 위해 추천 시스템에 널리 적용되어 왔습니다. 그러나 아이템의 풍부한 멀티모달 콘텐츠 정보(예: 텍스트, 이미지, 동영상)는 아직 완전히 탐색되지 않았습니다.

추천 정확도를 높이기 위해 최근 멀티모달 추천에 관한 연구에서는 기존의 사용자-아이템 추천 패러다임에 아이템 멀티모달 정보를 통합하는 효과적인 방법을 연구하고 있습니다. 예를 들어, 일부 방법은 멀티모달 특징을 아이템의 잠재적 표현과 연결하거나, 주의 메커니즘을 활용하여 아이템의 멀티모달 특징에 대한 사용자의 선호도를 파악합니다. 그래프 기반 추천에 대한 연구가 급증하면서, 그래프 신경망(GNN)을 사용하여 아이템 멀티모달 정보를 활용하고 사용자 및 아이템 표현의 학습을 강화하는 연구도 있습니다. 예를 들어, 그래프 컨볼루션 네트워크를 사용하여 사용자-아이템 상호작용 그래프에서 다양한 아이템 멀티모달 정보를 개별적으로 전파하고 집계합니다. 추천 성능을 더욱 향상시키기 위해 사용자-사용자 관계 그래프 및 아이템-아이템 관계 그래프 와 같은 다른 보조 그래프 구조도 멀티모달 정보로부터 사용자 및 아이템 표현의 학습을 향상시키는 데 활용되었습니다.

기존의 GNN 기반 멀티모달 방법은 최첨단 추천 정확도를 달성할 수 있지만, 대규모 그래프가 포함된 시나리오에서는 다음과 같은 문제로 인해 적용에 어려움을 겪을 수 있습니다. 첫째, 관찰된 사용자-아이템 상호작용 쌍을 양수 샘플로, 무작위로 샘플링된 사용자-아이템 쌍을 음수 샘플로 취급하는 베이지안 개인화 랭킹(BPR) 손실과 같은 쌍별 랭킹 손실을 기반으로 사용자 및 아이템 표현을 학습하는 경우가 많습니다. 이러한 네거티브 샘플링 전략은 큰 그래프에서 엄청난 비용을 초래할 수 있으며, 훈련 프로세스에 잡음이 많은 감독 신호를 가져올 수 있습니다. 예를 들어, 이전 연구에 따르면 LightGCN의 기본 균일 샘플링은 에포크당 25% 이상의 훈련 시간을 소모하는 것으로 확인되었습니다. 둘째, 보조 그래프 구조를 활용하는 방법은 대규모 보조 그래프를 구축하거나 훈련할 때 엄청난 메모리 비용이 발생할 수 있습니다. 기존 그래프 기반 멀티모달 방법의 계산 복잡성에 대한 자세한 분석은 표 1과 표 4에서 확인할 수 있습니다.

자기 지도 학습(Self-Supervised Learning, SSL)은 부정적인 샘플 없이 사용자와 아이템의 표현을 학습할 수 있는 솔루션을 제공합니다. 컴퓨터 비전(Computer Vision, CV)에서 자연어 처리(Natural Language Processing, NLP)에 이르는 다양한 영역의 연구에 따르면 SSL은 지도 학습보다 경쟁력이 있거나 더 나은 결과를 얻을 수 있는 것으로 나타났습니다. SSL의 주요 아이디어는 두 개의 비대칭 네트워크, 즉 온라인 네트워크와 목표 네트워크를 사용하여 샘플의 서로 다른 왜곡된 버전에서 얻은 표현의 유사성을 극대화하는 것입니다. 그러나 양성 샘플로만 훈련하면 모델이 사소한 상수 해에 빠지게 됩니다. 이러한 붕괴 문제를 해결하기 위해 BYOL과 SimSiam은 온라인 네트워크에 추가 "예측자" 네트워크를 도입하고 목표 네트워크에 특별한 "기울기 정지" 연산을 도입했습니다. 최근 BUIR은 BYOL을 추천 영역으로 이전하여 평가 데이터 세트에서 경쟁력 있는 성능을 보여줍니다.

이 논문에서는 멀티모달 추천을 위한 부트스트랩 멀티모달 모델(**B**ootstrapped **M**ulti-**M**odal **M**odel, BM3)을 제안합니다. 이 모델은 먼저 대상 네트워크를 제거하여 현재의 SSL 프레임워크를 단순화함으로써 모델 파라미터의 절반을 줄일 수 있습니다. 또한 BM3는 서로 다른 증강 간의 유사성을 유지하기 위해 온라인 네트워크에서 생성된 잠재적 임베딩을 교란하는 간단한 드롭아웃 메커니즘을 통합합니다. 이는 그래프 증강 또는 이미지 증강을 통해 입력을 교란하는 현재의 SSL 패러다임과는 다릅니다. 이 설계는 보조 그래프를 도입하지 않기 때문에 기존 그래프 증강 기법의 메모리와 계산 비용을 모두 절감할 수 있습니다. 마지막으로, 멀티모달 추천에 특화된 손실 함수를 설계했습니다. 이는 사용자-아이템 상호작용 그래프의 재구성 손실을 최소화하고 모달리티 간 및 모달리티 내 관점에서 학습된 특징을 정렬합니다.

주요 기여 사항을 요약하면 다음과 같습니다. 첫째, 멀티 모달 추천을 위한 새로운 자기 지도 학습 방법인 BM3를 제안합니다. BM3에서는 그래프 증강 대신 간단한 잠재 표현 드롭아웃 메커니즘을 사용해 음수 샘플 없이 대조 학습을 위한 사용자 또는 아이템의 목표 보기를 생성합니다. 둘째, 네거티브 샘플 없이 BM3를 훈련하기 위해 세 가지 목표를 공동으로 최적화하는 다중 모드 대비 손실(Multi-Modal Contrastive Loss, MMCL) 함수를 설계합니다. 기존의 사용자-아이템 상호 작용 그래프 재구성 손실을 최소화하는 것 외에도 MMCL은 서로 다른 모달리티 간에 학습된 특징을 더욱 정렬하고 특정 모달리티에서 다른 증강 뷰의 표현 간의 불일치를 줄입니다. 마지막으로 노드 수가 20만 개에서 200만 개에 이르는 세 가지 데이터 세트에서 BM3의 효과와 효율성을 검증합니다. 실험 결과, BM3는 최신 멀티 모달 추천 방식에 비해 상당한 개선을 달성하는 동시에 기본 방식보다 2~9배 빠르게 학습하는 것으로 나타났습니다.

## 2. RELATED WORK

### 2.1 Multi-modal Recommendation

_2.1.1 딥러닝 기반 모델(Deep Learning-based Models)._ 협업 필터링(Collaborative Filtering, CF) 방식의 성공으로 인해 대부분의 초기 멀티모달 추천 모델은 CF 패러다임 위에 사용자의 선호도를 탐색하는 딥러닝 기법을 활용합니다. 예를 들어, BPR방식을 기반으로 구축된 VBPR은 아이템의 시각적 특징을 활용합니다. 사전 학습된 컨볼루션 신경망을 활용하여 아이템의 시각적 특징을 파악하고 이를 잠재 시각 공간으로 선형적으로 변환합니다. 예측을 위해 VBPR은 잠재 시각적 특징과 ID 임베딩을 연결하여 아이템을 표현합니다. 또한, 딥스타일은 BPR 프레임워크 내에서 시각적 특징과 스타일 특징을 모두 사용하여 아이템의 표현을 보강합니다. 멀티모달 정보에 대한 사용자의 선호도를 파악하기 위해 추천 모델에도 주의 메커니즘이 채택되었습니다. 예를 들어, VECF는 VGG 모델을 활용하여 이미지에 대한 사전 세분화를 수행하고 다양한 이미지 영역에 대한 사용자의 관심을 포착합니다. MAML은 2계층 신경망을 사용하여 아이템의 텍스트 및 시각적 특징에 대한 사용자의 선호도를 파악합니다.

_2.1.2 그래프 기반 멀티모달 모델(Graph-based Multi-modal Models)._ 최근에는 추천 시스템에 GNN을 도입한 또 다른 연구에서 사용자-아이템 상호작용 그래프와 보조 그래프에 구조 정보를 통합하여 사용자 및 아이템 표현을 크게 향상시킬 수 있습니다. 아이템 멀티 모달 정보를 활용하기 위해 MMGCN은 그래프 컨볼루션 네트워크(GCN)의 메시지 전달 메커니즘을 채택하고 모달별 사용자-아이템 이분 그래프를 구성하여 멀티 홉 이웃의 정보를 캡처하여 사용자 및 아이템 표현을 향상시킬 수 있습니다. MMGCN을 기반으로 하는 DualGNN은 모델 선호도 학습 모듈이 포함된 사용자 동시 발생 그래프를 도입하여 아이템의 여러 모달리티에서 사용자의 선호도를 파악합니다. 사용자-아이템 그래프에 의도하지 않은 상호작용이 포함될 수 있으므로 GRCN은 노이즈 에지를 식별하고 오탐 에지를 보정하여 사용자-아이템 상호작용 그래프의 구조를 개선하는 그래프 정제 계층을 도입합니다. 아이템 간의 의미 정보를 명시적으로 마이닝하기 위해 LATTICE는 각 양식에 대해 아이템-아이템 관계 그래프를 구성하고 이를 융합하여 잠재 아이템 그래프를 얻습니다. 이 그래프는 GCN을 사용하여 아이템의 정보가 고도로 연결된 친화성으로부터 전파되고 집계된 후 동적으로 업데이트됩니다. FREEDOM은 아이템-아이템 그래프의 학습이 무시할 수 있는 수준임을 감지하고 효과적이고 효율적인 추천을 위해 그래프를 동결합니다.

그래프 기반 멀티모달 모델은 새로운 최첨단 추천 정확도를 달성하지만, 사용자 및 아이템 증강을 위한 보조 그래프가 필요하고 BPR 손실이 있는 표현 학습을 위해 많은 수의 네거티브가 필요한 경우가 많습니다. 이 두 가지 요구 사항은 그래프 크기가 증가함에 따라 높은 계산 복잡성과 엄청난 메모리 비용으로 이어질 수 있으며, 대규모 그래프가 필요한 시나리오에서 이러한 모델의 효율성을 제한할 수 있습니다.

### 2.2 Self-supervised Learning (SSL)

SSL 기반 방법은 다양한 CV 및 NLP 작업에서 경쟁력 있는 결과를 달성했습니다. 우리 모델은 관찰된 데이터만 사용하는 SSL을 기반으로 하므로, SSL 방법에 대한 검토는 네거티브 샘플링이 필요하지 않은 방법에 초점을 맞춥니다.

현재 SSL 프레임워크는 엔티티 비교를 위한 일반적인 모델인 샴 네트워크에서 파생되었습니다. BYOL과 SimSiam은 비대칭 샴 네트워크를 사용하여 놀라운 결과를 달성합니다. 특히 BYOL은 최적화되고 반복적으로 업데이트되는 두 개의 결합 인코더(즉, 온라인 인코더와 대상 인코더)를 제안합니다. 온라인 인코더는 타깃 인코더에 최적화되어 있고 타깃 인코더는 모멘텀 인코더입니다. 목표 인코더의 매개변수는 온라인 인코더의 지수 이동 평균으로 업데이트됩니다. BYOL은 네트워크 붕괴를 방지하기 위해 온라인 인코더의 예측자와 타깃 인코더의 "정지 기울기" 연산자를 모두 사용합니다. 심시암은 "스톱 그라데이션" 연산자가 붕괴를 방지하는 데 중요하다는 것을 확인합니다. 그러나 온라인 인코더와 타겟 인코더 간에 매개변수를 공유합니다. 반대로 Barlow Twins는 두 개의 대조적 표현에서 계산된 교차 상관 행렬을 가능한 한 동일성 행렬에 가깝게 정렬할 수 있는 혁신적인 목적 함수를 설계하여 대칭 아키텍처를 사용합니다.

최근 제안된 자가 지도 프레임워크인 BUIR은 BYOL에서 파생된 것으로, 긍정적인 상호작용을 통해서만 사용자와 아이템의 표현을 학습합니다. 이 프레임워크는 다양한 보기를 도입하고 느리게 움직이는 평균 네트워크를 활용하여 온라인 인코더로 대상 인코더의 파라미터를 업데이트합니다. 동일한 입력이 서로 다르지만 관련성이 있는 인코더에 공급되어 대조적인 보기를 생성합니다.

CV와 NLP에서 SSL이 급성장함에 따라 멀티모달 기능이 추천에서 SSL 패러다임에 따라 사용자와 아이템의 표현을 향상시킬 수 있는지 여부와 그 방법은 아직 밝혀지지 않았습니다. 이 논문에서는 멀티모달 추천을 위한 단순하면서도 매우 효율적인 SSL 모델을 제안합니다. 이 모델은 큰 그래프에서 계산 복잡성과 메모리 비용을 줄이면서 뛰어난 정확도를 달성할 수 있습니다.

## 3 BOOTSTRAPPED MULTI-MODAL MODEL

이 섹션에서는 그림 1에 표시된 것처럼 a) 멀티모달 잠재 공간 변환기, b) 대비 뷰 생성기, c) 멀티모달 대비 손실의 세 가지 구성 요소를 포함하는 부트스트랩 멀티모달 모델에 대해 자세히 설명합니다.

## 3.1 Multi-modal Latent Space Convertor

$e_u, e_i \in \mathbb{R}^𝑑$는 사용자 $u \in U$와 아이템 $i \in I$의 입력 ID 임베딩을 나타내며, 여기서 $d$는 임베딩 차원이고 $U$, $I$는 각각 사용자 및 아이템의 집합입니다. 이들의 기본 번호는 각각 $|U|$와 $|I|$로 설정됩니다. 사전 학습된 모델에서 얻은 양식별 특징을 $e_m \in \mathbb{R}^{d_m}$로 표시하며, 여기서 $m \in M$은 전체 양식 집합 $M$에서 특정 양식을 나타내고, $d_m$는 특징의 차원을 나타냅니다. $M$의 기본 수는 $|M|$으로 표시됩니다. 이 논문에서는 시각 $v$와 텍스트 $t$라는 두 가지 모달리티를 고려합니다. 그러나 이 모델은 두 가지 이상의 모달리티가 있는 시나리오로 쉽게 확장할 수 있습니다. 멀티 모달 특징 공간은 서로 다르므로 먼저 멀티 모달 특징과 ID 임베딩을 동일한 잠재 공간으로 변환합니다.

_3.1.1 다중 모달 특징(Multi-modal Features)._ 서로 다른 모달리티에서 얻은 아이템의 특징은 서로 다른 차원과 서로 다른 특징 공간에 있습니다. 다중 모달 특징 벡터 $e_m$의 경우 먼저 다층 퍼셉트론(MLP) 기반의 투영 함수 𝑓𝑚를 사용하여 이를 잠재 저차원으로 투영합니다. 그런 다음

$h_m = e_m W_m + b_m, (1)$

여기서 $W_m \in \mathbb{R}^{d_m \times d}, b_m \in \mathbb{R}^d$는 $f_m$의 MLP에서 선형 변환 행렬과 바이어스를 나타냅니다. 이러한 방식으로 각 단일 모달 잠재 표현 $h_m$는 ID 임베딩과 동일한 공간을 공유합니다.
