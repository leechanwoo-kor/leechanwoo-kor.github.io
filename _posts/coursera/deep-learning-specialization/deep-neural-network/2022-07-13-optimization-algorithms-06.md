---
title: "[Ⅱ. Deep Neural Network] Optimization Algorithms (6)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
  - Tensorflow
  - Deep Learning
  - Mathematical Optimization
  - hyperparameter tuning
toc: true
toc_sticky: true
toc_label: "Optimization Algorithms (6)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/177095282-038ee3ed-f543-4793-9eff-f2d5ac239f36.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Optimization Algorithms

## Optimization Algorithms

### Learning Rate Decay

학습 알고리즘의 속도를 높이는 데 도움이 될 수 있는 것 중 하나는 시간이 지남에 따라 학습률을 천천히 줄이는 것입니다. 이것을 학습률 감소라고 합니다. 이것을 어떻게 구현할 수 있는지 한번 보겠습니다.

![image](https://user-images.githubusercontent.com/55765292/178630333-9b77e5f0-8f87-4acf-820d-de63fa6fe690.png)

![image](https://user-images.githubusercontent.com/55765292/178630366-d7c40933-7cc5-4ac1-a20a-23e5bab67eab.png)

![image](https://user-images.githubusercontent.com/55765292/178630381-2135840a-3362-4d6b-b4b7-da9066184827.png)


