---
title: "[Ⅱ. Deep Neural Network] Optimization Algorithms (3)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
  - Tensorflow
  - Deep Learning
  - Mathematical Optimization
  - hyperparameter tuning
toc: true
toc_sticky: true
toc_label: "Optimization Algorithms (3)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/177095282-038ee3ed-f543-4793-9eff-f2d5ac239f36.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Optimization Algorithms

## Optimization Algorithms

### Exponentially Weighted Averages
이제 몇 가지 최적화 알고리즘을 보여드리고 싶습니다. 이것들은 기울기 하강보다 더 빠릅니다. 이러한 알고리즘을 이해하기 위해서는 지수 가중 평균이라는 것을 사용할 줄 알아야합니다. 지수 가중 이동 평균이라고도 하는데요. 이 부분에 대해 먼저 이야기 해보고 이 내용을 바탕으로 조금 더 상세한 최적화 알고리즘 내용을 다루어 보겠습니다.

![image](https://user-images.githubusercontent.com/55765292/178212358-5072544b-1e18-4e6e-9b59-2fc5e5276627.png)

위 그림은 런던의 요일별 날씨를 나타냅니다. 그래서 1월 1일 온도는 화씨 40도 였습니다. 섭씨로는 4도입니다. 그리고 1월 2일에는 섭씨 온도가 9도였습니다. 일년에서 반 정도 지난 시점에는, 1년이 365일이기 때문에 180일 정도가 지난 시점이겠죠, 그러면 5월 말 정도가 되겠군요. 여기서 보면 그 날짜에는 화씨 60도, 섭씨 15도였습니다. 따라서 여름으로 갈수록 따듯해지기 시작하고 1월에는 더 추웠습니다.

그래서 이것으로 데이터를 플로팅합니다. 여름이 시작하는 어느날, 연말의 데이터 등이 있습니다. 이 데이터는 약간의 노이즈가 있는 것으로 보이며 온도의 추세, 지역 평균 또는 이동 평균을 계산하려면 위의 식처럼 하면 됩니다.

일단 $v_0$ 값을 0 으로 초기화 합니다. 그 다음으로, 일 별로 값으로 표시되는 모든 항목의 0.9배에 해당 날짜 온도의 0.1배를 더한 가중치로 평균을 냅니다. 그렇게해서 쎄타 1의 값은 첫째날의 온도가 됩니다. 그리고 둘째날에는 가중 평균을 적용시킬 것입니다. 0.9 곱하기 이전 값 더하기 0.1 곱하기 오늘 날씨 온도 등등입니다. 둘째날 더하기 0.1 곱하기 쎼타 3 등등 말이죠.

v라는 날에 대한 더욱 일반적인 공식은 $v_t = 0.9v_{t-1} + 0.1\theta_t$입니다. 이것을 계산하고 빨간색으로 표시하면 위 그림처럼 나옵니다. 일별 날짜 온도를 이동 평균값으로 나타낸 지수 가중 평균이 나옵니다.

![image](https://user-images.githubusercontent.com/55765292/178212447-03f3fde2-6457-4da1-9b98-de823d936341.png)

그러면 이전 그림에서 봤던 공식을 다시 한번 보겠습니다. 이전에 0.9의 값이었던 값을 베타로 변경할텐데요. 이를 식으로 표현하면

$v_t = \beta v_{t-1} + (1-\beta)\theta_t$

로 나타납니다. 그래서 이전에 베타의 값이 0.9였는데요. 나중에 그 이유에 대해 아시겠지만, 이 값을 산출할 때, $v_t$의 값이 대략적으로 
$\cfrac{1}{1-\beta} \times days' temperature$가 되는 것이라고 생각하면 됩니다. 그렇기 때문에 베타가 0/9가 되는 경우 이것은 이전 10일 동안의 평균 기온과 비슷하다고 생각하시면 됩니다. 그리고 그것은 빨간색 선이었고요.

자, 다른 것을 한번 시도해보죠. 베타를 1과 매우 가까운 값으로 지정해보겠는데요. 베타 값이 0.98이라고 해봅시다. 그러면 $\cfrac{1}{1-0.98} = 50$이 됩니다. 이것은 대략적으로 지난 50일 간의 평균 기온과 비슷하다고 생각하면 됩니다. 이것을 그래프에 나타내면 초록색 라인이 됩니다.

이렇게 매우 큰 베타값에서의 특징 2가지를 살펴보겠습니다. 그래프에 나타나는 것은 훨씬 더 부드러운 결과값인데요. 그 이유는 평균값을 더 많은 일수로 구하기 때문입니다. 그렇기 때문에 이 커브는 곡선이 덜 있고 부드러운 모양이 나오고요.

그러나 반대로 훨씬 더 큰 온도 윈도우에서 평균을 내고 있기 때문에 곡선이 이제 오른쪽으로 더 이동했습니다. 더 큰 윈도우에 대한 평균을 구하는 경우엔 이 공식은 지수 평균 가중의 공식이고 더 느리게 적용되며 온도가 변하는 경우입니다. 약간의 시간차 즉 잠재기가 늘어납니다.

그리고 그 이유는 베타가 0.98인 경우에 그러면 이전 값에 많은 가중치를 부여하고 지금 보고 있는 항목에 0.02에 불과한 훨씬 작은 가중치를 부여합니다. 그래서 온도가 변하는 경우 온도가 상승하거나 떨어지는 경우 지수 평균 가중이 적용됩니다. 베타가 너무 크면 더 천천히 적응합니다.

자 다른 값으로 한번 더 볼까요. 베타를 또 극한 숫자로 지정할 경우에, 예를 들어 0.5라고 하면, 그런 다음 공식을 사용합니다. 이것은 단 이틀의 온도에 대한 평균과 같은 것이며, 이것을 그래프에 나타내면 노란색의 선이 됩니다. 그리고 이틀간의 평균 기온을 구하면 훨씬 더 작은 범위의 평균치를 구하는 것인데요. 데이터에 노이즈가 많고 이상치에 훨씬 더 취약합니다. 그러나 이것은 온도 변화에 훨씬 더 빨리 적응합니다.

이 공식이 그렇기 때문에 많이 도입되는데, 지수 가중 평균이라고 합니다. 지수 가중치라고 하며, 통계 문헌에서는 이동 평균이라고도 합니다. 이용어를 짧게는 지수 가중 평균이라고 할 것이며, 이 매개변수를 변형 시켜주면서 또는 나중에 하이퍼 매개변수를 변형시키면서, 러닝 알고리즘에서는 다양한 효과를 목격할 수 있고, 그리고 어느 사이에 있는 특정 값이 가장 잘 작동하는 경우가 있을 것입니다.

그러면 녹색 또는 노란색 곡선보다 온도의 베타 평균처럼 보일 수 있는 빨간색 곡선이 표시됩니다. 이제 지수 가중 평균을 계산하는 방법에 대한 기본 사항을 알게 되었습니다. 다음에는 이것이 하는일에 대한 직관을 좀 더 알아보겠습니다.


### Understanding Exponentially Weighted Averages
이전에는 지수 가중 평균에 대해서 이야기했었는데요. 신경망을 훈련하는데 사용할 여러 최적화 알고리즘의 주요 요소가 될 것입니다. 그러므로 이번에는 이런 알고리즘이 하는 내용에 대한 직관적인 부분에 대해서 조금 자세히 살펴보도록 하겠습니다.

![image](https://user-images.githubusercontent.com/55765292/178218111-05ef37dd-5ae4-4c20-b7dc-d8f51de317dd.png)

![image](https://user-images.githubusercontent.com/55765292/178218198-e031dc47-024a-439b-874c-90e3889b85f1.png)

![image](https://user-images.githubusercontent.com/55765292/178218284-bf37b2f2-ccb4-481d-881b-b703588afc2d.png)


