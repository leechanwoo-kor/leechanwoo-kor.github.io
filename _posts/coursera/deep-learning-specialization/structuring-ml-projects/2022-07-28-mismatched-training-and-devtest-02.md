---
title: "[Ⅲ. Structuring Machine Learning Projects] Mismatched Training and Dev/Test Set (2)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
  - Deep Learning
  - Inductive Transfer
  - Machine Learning
  - Multi-Task Learning
  - Decision-Making
toc: true
toc_sticky: true
toc_label: "Mismatched Training and Dev/Test Set (2)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/179931579-167db454-5d9d-4e0d-a8fe-454770dc97a6.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Structuring Machine Learning Projects

## Error Analysis

### Bias and Variance with Mismatched Data Distributions

학습 알고리즘의 편향과 분산 값 예측은 해야 할 작업의 우선순위를 결정하는 데 도움을 줍니다. 하지만 훈련 세트가 개발/시험 세트와 다른 분포에서 오는 경우 편향과 분산을 분석하는 방법이 달라집니다. 한번 살펴보겠습니다.

---

![image](https://user-images.githubusercontent.com/55765292/181418524-55f59587-9bf2-4abe-b7f2-14bedc266c16.png)

계속해서 고양이 분류기 예시로 보겠습니다. 인간은 이 작업에서 거의 완벽에 가까운 능력을 보인다고 가정해 봅시다. 그러면 베이즈 오류/베이즈 최적화 오류가 이 문제의 경우 0%임을 알 수 있습니다. 오류 분석을 하기 위해서는 보통 훈련 오류를 보고 개발 세트의 오류도 봅니다.

이번 예시에서 훈련 오류는 1% 개발 오류는 10%라고 해 보겠습니다. 만약 개발 데이터가 훈련 세트와
동일한 분포에서 왔다면 아주 큰 분산 문제가 생길 것입니다.

알고리즘이 훈련 세트를 잘 일반화시키지 못하는 것이죠. 개발 세트에서는 잘 했는데 갑자기 문제가 생기는 겁니다. 하지만 훈련 데이터와 개발 데이터가 다른 분포에서 올 때에는 이렇게 쉽게 단정할 수 없습니다.

또 사실 저게 개발 세트에서 잘 하고 있는 모습인지도 모릅니다. 훈련 세트가 고해상도에 아주 선명한 이미지로 되어 있었기 때문에 훈련 세트는 아주 쉬웠고 개발 세트가 훨씬 더 어려웠을 수도 있습니다. 

그래서 사실 분산 문제가 없을 수 있고 지금의 결과는 개발 세트에 정확히 분류하기 어려운 이미지들이 더 많이 포함되어 있음을 반영하는 것일 수 있습니다.

이 분석의 문제는 훈련 오류에서 개발 오류로 넘어갔을 때 한 번에 두 가지가 바뀌었다는 것입니다.

먼저 알고리즘이 훈련 세트에서는 데이터를 봤지만 개발 세트에서는 아니었다는 것입니다. 다음으로는 개발 세트의 데이터 분포가 다릅니다.

그리고 두 가지를 한번에 바꾸었기 때문에 9%로 증가한 오류 중 얼마만큼이 알고리즘이 개발 세트에 있는 데이터를 보지 못해 생기는 오류인지 알기 어렵습니다. 이건 분산에서 오는 문제겠죠.

또 얼마만큼의 오류가 단순히 개발 세트 데이터가 달라서 생기는 것인지 구분하기도 쉽지 않습니다.

이런 효과들을 확인하기 위해서는 훈련-개발 세트라고 부를 새로운 데이터를 정의하는 것이 도움이 될 것입니다. 이것이 새로운 데이터의 부분집합인데요.

일부 추출해서 빼낸 이 데이터는 훈련 세트와 동일한 분포를 가집니다. 하지만 신경망 네트워크에서 따로 훈련시키는 데이터는 아닙니다.

이게 어떤 뜻이냐면 이전에는 일부 훈련 세트와 개발 세트, 그리고 시험 세트를 이렇게 설정했었습니다. 개발과 시험 세트는 같은 분포를 훈련 세트는 다른 분포를 가질 것입니다.

이제는 훈련 세트들을 무작위로 섞은 뒤 일부 훈련 세트를 추출해 이를 훈련-개발 세트라고 할 것입니다. 개발과 시험 세트가 같은 분포로 되어 있듯 훈련 세트와 훈련-개발 세트도 같은 분포로 되어 있을 것입니다.

하지만 차이점은 이제 신경망을 훈련 세트에서만 훈련시킨다는 것입니다. 훈련-개발 부분에서는 따로 훈련을 진행하지 않을 것입니다. 오류 분석을 위해서는 인식기의 오류를 훈련 세트에서 보고 훈련-개발 세트 개발 세트에서도 봐야 합니다.

이번 예시에서는 훈련 오류가 1% 훈련-개발 세트에서의 오류는 9% 개발 세트에서의 오류는 전과
마찬가지로 10%라고 해 봅시다.

여기서 내릴 수 있는 결론은 훈련 데이터에서 훈련 개발 데이터로 넘어갈 때 오류가 많이 늘었다는 것입니다. 그리고 훈련 데이터와 훈련-개발 데이터의 유일한 차이는 신경망이 이 첫 부분을 다뤘다는 것입니다.

이 부분에 대한 훈련은 확실히 받았지만 훈련-개발 데이터의 경우 그렇지 못했습니다. 이런 부분은 바로 분산 문제가 있다는 걸 말해 주는데요. 훈련-개발 오류가 훈련 세트와 같은 분포도를 가진 데이터로 측정되었기 때문에 그렇습니다.

이제 신경망이 훈련 세트에서 잘 작동하더라도 같은 분포에서 온 훈련-개발 세트의 데이터에 대한 일반화가 잘 되지 않는다는 것을 알게 되었습니다. 같은 분포를 가졌더라도 처음 보는 데이터에 대한 일반화는 잘 되지 않는 것입니다.

이 예시에서는 그렇기 때문에 분산 문제가 발생합니다.

또 다른 예시를 보겠습니다. 훈련 오류가 1% 훈련-개발 오류가 1.5%라고 해 보죠. 그런데 개발 세트에서는 오류가 10%입니다. 이 경우 낮은 분산 문제가 있습니다. 왜냐하면 신경망이 이미 본 적 있는 훈련 데이터에서 본 적이 없는 훈련-개발 데이터로 갈 때는 오류가 약간만 올라가다가 이후 개발 세트로 가자 급상승합니다.

이는 전형적인 데이터 불일치 문제입니다. 데이터가 일치하지 않는 것이죠. 학습 알고리즘이 훈련-개발이나 개발 데이터로 훈련된 것이 아니기 때문입니다.

또 이 두 데이터 세트는 서로 다른 분포에서 왔습니다. 어떤 알고리즘을 학습해도 훈련-개발에선 잘 작동하고 개발에서는 잘 작동하지 않습니다. 알고리즘이 왜인지 여러분이 중요하게 생각하는 분포와 다른 분포에서 잘 작동하는 법을 배우게 된 것입니다.

이를 데이터 불일치 문제라고 합니다.

몇 가지 예시를 더 보겠습니다. 훈련 오류, 훈련-개발 오류 개발 오류입니다. 훈련 오류는 10% 훈련-개발 오류는 11% 개발 오류는 12%입니다 Bayes 오류에서 인간의 프록시 레벨은 약 0%입니다.

이런 종류의 성능이 있다면 편향이 생기는데요 회피가능 편향 문제입니다. 인간 수준보다 훨씬 떨어지기 때문이죠. 따라서 이것은 실제로 높은 편향 설정입니다.

마지막 예시입니다. 훈련 오류가 10% 훈련-개발 오류가 11% 개발 오류가 20%이면 두 가지 이슈가 있어 보입니다.

첫째, 회피가능 편향이 꽤 높습니다 훈련 세트에서조차 그리 잘하고 있지 않기 때문이죠. 인간은 0% 오류에 가까운 반면 우리의 훈련 세트는 10%의 오류를 내고 있습니다.

분산은 조금 작아 보이는데요. 데이터 불일치는 꽤 큽니다. 이 예시에서는 편향 혹은 회피가능 편향 문제 데이터 불일치 문제가 크다고 볼 수 있습니다.

이제 다룬 내용을 보고 일반적인 원리를 적어보겠습니다.

---

![image](https://user-images.githubusercontent.com/55765292/181418546-98ae14fa-f182-4684-ad2d-ccdd16c1c18e.png)

![image](https://user-images.githubusercontent.com/55765292/181418578-83e48355-a755-43ff-90b2-35a70552e48c.png)

