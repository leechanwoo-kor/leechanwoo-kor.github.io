---
title: "[Ⅲ. Structuring Machine Learning Projects] End-to-end Deep Learning (1)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
  - Deep Learning
  - Inductive Transfer
  - Machine Learning
  - Multi-Task Learning
  - Decision-Making
toc: true
toc_sticky: true
toc_label: "End-to-end Deep Learning (1)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/179931579-167db454-5d9d-4e0d-a8fe-454770dc97a6.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Structuring Machine Learning Projects

## End-to-end Deep Learning

### What is End-to-end Deep Learning?

딥 러닝의 최근 발전상 중 가장 흥미로운 것은 종단간 딥 러닝이었습니다. 그렇다면 종단간 학습은 무엇일까요? 간단히 얘기하면, 여러 단계를 처리하는 데이터 처리 시스템이나 학습 시스템이 있었는데요. 종단간 딥 러닝은 이런 여러 단계를 하나의 신경망으로 변환합니다.

---

<img width="1074" alt="image" src="https://user-images.githubusercontent.com/55765292/182766883-c131c92a-707f-4d14-94b7-0cee357531d4.png">

예시를 몇 가지 살펴볼까요. 음성 인식을 예로 들면 오디오 클립과 같은 입력값 X를 가져와 오디오 클립 전사물인 출력값 Y에 매핑하는 것이 목적인데요. 그래서 전통적으로 음성 인식은 많은 단계를 필요로 했습니다.

먼저 몇 가지 오디오의 설계된 수제 특성을 추출합니다. MFCC라고 들어 보셨을 텐데요. 이는 오디오를 위한 설계된 수제 특성 세트를 추출한 뒤 일부 저수준 특성을 추출하는 알고리즘입니다. 머신러닝 알고리즘을 적용하여 오디오 클립에서 음소를 찾을 수 있습니다.

음소는 소리의 기본 단위입니다. 예를 들면 캣이라는 단어는 세 가지 소리로 구성되어 있습니다. ㅋ /ㅐ /ㅌ 으로 추출할 수 있는 것이지요. 그리고 나서 개별 단어를 만들기 위해 음소를 결합합니다. 그런 다음 이를 묶어 오디오 클립의 전사물을 만듭니다. 여러 단계로 이루어진 이런 파이프 라인과는 대조적으로 종단간 학습은 거대한 신경망을 훈련시켜 여기에 오디오 클립을 넣고 전사물이 직접 출력되도록 하는 것입니다.

AI의 한가지 흥미로운 사회학적 영향은 종단간 딥 러닝이 효과를 내기 시작함에 따라 몇몇 연구원들이 파이프 라인의 개별 단계 설계에 많은 시간을 보냈다는 것입니다. 또 단지 음성 인식 뿐 아니라 다른 쪽의 연구원들도 있었는데요. 컴퓨터 비전 등의 영역에서 여러 논문을 쓰거나 커리어의 상당 부분에서 특성이나 파이프라인의 기타 요소를 엔지니어링하는 데 많은 시간을 할애하고 있었습니다.

그래서 종단간 딥 러닝이 그냥 최종 훈련 세트를 가지고 x와 y의 함수 매핑을 직접 학습하면서 이러한 많은 중간 단계를 우회했을 때 일부 분야에서는 이 대안적인 AI 구축 시스템을 받아들이는 것이 쉽지 않았습니다. 왜냐하면 일부 중간 구성 요소들에 대한 수년간의 연구가 무용지물이 되는 경우도 있었기 때문입니다.

종단간 딥 러닝의 과제 중 하나는 잘 작동하기 위해 많은 양의 데이터가 필요하다는 것입니다. 예를 들면 음성인식 시스템 구축을 위해 3000시간짜리 데이터를 훈련하고 있다면 전통적인 파이프라인 이 완전히 전통적인 파이프 라인은 아주 잘 작동합니다.

하지만 종단간 접근법의 경우 큰 데이터 세트가 있는 경우에야 이를 테면 만 시간의 데이터나 최대 십만 시간짜리 데이터 정도가 되어야 갑자기 잘 작동하기 시작합니다. 작은 데이터 세트가 있을 경우 좀더 전통적인 파이프라인 접근법도 그만큼 잘 작동합니다. 심지어는 종종 더 낫지요 종단간 접근법이 정말 빛을 발하기 위해서는 큰 데이터 세트가 필요합니다.

만약 중간 정도 양의 데이터가 있을 경우 중간 접근법도 있습니다 오디오를 입력하고 특성을 우회하고 신경망에서 음소를 출력하는 법을 학습합니다. 그리고 다른 단계들도요. 이는 종단간 학습을 향한 한 걸음이 될 것이지만 그것이 전부는 아닙니다.

---

<img width="1183" alt="image" src="https://user-images.githubusercontent.com/55765292/182766934-04aec196-4741-4cb5-ba35-46a02ecdf1f4.png">

바이두의 양칭 린이 만든 얼굴 인식 회전문 사진입니다. 이건 문에 접근하는 사람을 쳐다보는 카메라입니다. 카메라가 사람을 인식하면 회전식 출입문이 자동으로 돌아가 사람을 통과시킵니다. 그래서 시설 출입을 위해 RFID 배지를 긁는 대신 점점 더 많은 사무실에서 중국, 그리고 가능하면 다른 나라들에서도 더 많이 그냥 회전식 출입문에 다가가 얼굴이 인식되면 RFID 배지가 없어도 안으로 들어갈 수 있습니다.

그렇다면 어떻게 이런 시스템을 구축할까요? 한 가지 방법은 카메라가 캡처하는 이미지를 보는 것입니다. 이걸 카메라 이미지라고 합시다. 누군가 회전식 출입문에 다가가면 카메라가 캡처하는 이미지 X입니다. 여기서 시도할 수 있는 것은이미지 X에서 사람 Y의 신원으로 직접 매핑되는 함수를 배우는 것입니다.

하지만 이는 최선의 접근법이 아니었습니다. 그리고 한 가지 문제는 회전문에 접근하는 사람은 다양한 방향에서 올 수 있다는 것입니다. 녹색 위치에서 올 수도 있고 파란색 위치에서 올 수도 있습니다. 또 카메라에 더 가까이 있을 경우 이미지에서 더 크게 나오기도 합니다. 때로는 이미 카메라에 아주 가까이 있어서 얼굴이 훨씬 크게 보일 수도 있습니다.

그래서 이 회전식 출입문을 만들기 위해 실제로는 원 이미지를 그대로 받아들이지 않고 신원 파악을 위해 그 이미지를 신경망에 공급했습니다. 하지만 현 시점에서 최선의 방법은 다단계 접근법입니다.

먼저 얼굴 감지를 위해 프로그램을 하나만 돌려 봅니다. 이 첫번째 감지기는 사람의 얼굴이 어디에 있는지 알아냅니다. 얼굴을 발견하고 나면 그 이미지 부분을 확대하고 잘라 얼굴이 가운데에 오게 합니다. 그리고 이 빨간색 사진은 신경망에 제공되고 신경망은 학습을 시도하거나 해당 인물의 신원을 파악하려 할 수도 있습니다.

그리고 연구원들은 모든 것을 한달음에 배우려고 하는 대신 이 문제를 두 가지 간단한 단계로 나누어 1단계로 얼굴이 어디에 있는지 알아내고 2단계로 얼굴을 보고 그 사람이 누구인지 알아냈습니다. 이 두 번째 접근법은 학습 알고리즘 또는 두 가지 학습 알고리즘이 훨씬 단순한 두 작업을 해결하고 전반적으로 더 나은 성능을 제공하게 해 주었습니다.


2단계가 실제로 훈련된 방식은 이렇습니다. 여러분의 네트워크에서 훈련된 방식과 같은데요. 두 개의 이미지를 입력하고 네트워크는 이 두 이미지 입력값을 처리해 두 이미지가 같은 사람인지 아닌지를 말해줍니다. 직원 만 명의 ID를 파일에 기록해 두면 이 빨간색 사진을 가지고 파일에 있는 직원 만 명의 ID와 빠르게 대조해 이 빨간색 사진에 있는 사람이 실제로 시설 또는 사무 빌딩에 출입할 수 있는 만 명의 직원 중 하나인지 파악합니다. 이는 직원들이 작업장에 출입할 수 있도록 하는 회전식 출입문입니다.

그러면 2단계 접근방식은 왜 더 효과적일까요? 두 가지 이유가 있습니다 첫째, 해결 중인 두 문제가 실제로는 훨씬 더 단순하다는 것입니다. 둘째, 두 하위 작업에 대한 데이터가 많다는 것입니다. 특히, 안면 인식을 위해 얻을 수 있는 데이터가 많고 1번 작업의 경우 여기서 과제는 사진을 보고 사람의 얼굴이 어디 있는지 찾는 것입니다.

이를 위한 데이터가 많은데요. 라벨 데이터 X, Y입니다 여기서 X는 사진이고 y는 사람 얼굴의 위치를 나타냅니다. 그래서 1번 작업을 잘 수행하는 신경망을 만들 수 있습니다. 또 2번 작업에도 많은 데이터가 따로 있습니다.

오늘날 주요 기업들은 수억장의 인물 사진을 보유하고 있습니다. 그래서 이 빨간 사진이나 저 사진처럼 잘린 확대샷을 보면 오늘날의 선도적인 안면 인식 팀들은 두 개의 이미지를 보고 이들이 동일 인물인지 아닌지 파악을 시도할 수 있는 이미지를 적어도 몇억 개 보유하고 있습니다. 이렇게 두번째 작업에 사용할 수 있는 데이터도 많습니다.

반면 만약 모든 것을 동시에 학습하려 한다면 X, Y형식의 데이터가 훨씬 적습니다. 여기서 X는 회전식 출입문에서 찍힌 이미지이고 Y는 그 사람의 신원입니다. 따라서 이 종단간 학습 문제를 해결하기에는 데이터가 충분치 않지만 하위 작업 1, 2를 해결하는 데에는 충분한 데이터가 있기 때문에 실제로는 이를 두 개의 하위 문제로 나누면 순수한 종단간 딥 러닝 접근법 대비 더 나은 성능을 얻을 수 있습니다.

하지만 종단간 접근법에 필요한 데이터가 충분하다면 아마 종단간 접근법이 더 효과적일 것입니다. 하지만 이는 오늘날 실제로 가장 효과적인 방법은 아닙니다. 몇가지 예를 더 살펴보겠습니다 

---

<img width="1131" alt="image" src="https://user-images.githubusercontent.com/55765292/182766986-875b6c3f-c516-408e-8003-44573825be86.png">

기계 번역을 봅시다 전통적으로 기계 번역 시스템은 길고 복잡한 파이프 라인을 가지고 있는데요. 예를 들면 먼저 영어 텍스트를 가지고 텍스트 분석을 합니다. 기본적으로 텍스트에서 많은 특성을 추출하는 것이죠. 그리고 아주 많은 단계를 거쳐 영어 텍스트를 프랑스어로 번역하게 됩니다. 기계 번역을 위해 영어-프랑스어 문장이 많이 있기 때문입니다.

종단간 딥 러닝은 기계번역에 꽤 효과적입니다. 이는 오늘날 X-Y 쌍의 큰 데이터 세트 영어 문장과 그에 대응하는 프랑스어 번역을 대량으로 모으는 것이 가능하기 때문입니다. 이 예에서는 종단간 딥 러닝이 잘 작동합니다.

마지막 예를 들어 보겠습니다. 아이 손의 엑스레이 사진을 보고 나이를 추정하고 싶다고 해 봅시다. 저는 이 문제를 처음 보고 아주 멋진 범죄 현장조사 작업이라고 생각했습니다. 비극적으로 발견한 아이의 해골을 통해 그 아이가 몇 살인지 알아보고자 했습니다. 하지만 엑스레이로 아이의 나이를 추정하는 것이 적용되는 대부분의 사례들은 범죄 현장조사보다 덜 극적인 것으로 드러났습니다.

소아과 의사들은 이를 사용해 아이의 정상 발육 여부를 추정하고 있습니다. 여기에 대한 비 종단간 접근법은 이미지를 찾은 다음 뼈를 분할하거나 인식하는 것입니다. 그럼 먼저 뼈가 어디에 있는지 찾아봅시다. 뼈가 어디 있을까요? 뼈가 어디 있을까요? 이렇게 계속 하는 겁니다. 그런 다음 그리고 다양한 뼈의 길이를 알면 아이의 평균 손 뼈 길이를 나타내는 위 표를 보고 아이의 나이를 추정할 수 있습니다. 이 방법은 꽤 효과적입니다.

반면 만일 사진에서 바로 아이의 나이로 넘어간다면 이를 직접적으로 수행하기 위한 데이터가 많이 필요할 겁니다. 그리고 제가 알기로 이 접근법은 오늘날 그만큼 잘 작동하지 않는데 종단간 방식으로 이 작업을 훈련할 데이터가 충분하지 않기 때문입니다.

이와 반대로, 이 문제를 두 단계로 나누어 생각해 볼 수 있습니다. 1단계는 비교적 간단한 문제입니다. 그렇게 많은 데이터가 필요하지 않을 수도 있습니다. 뼈 구분에 그렇게 많은 엑스레이 사진이 필요하지 않을 수도 있습니다. 그리고 2단계에서는 많은 아이들의 손 통계를 수집해 자료가 많이 없어도 꽤 정확한 추정치를 얻을 수 있습니다.

그래서 이런 다단계 접근 방식의 전망은 밝습니다. 종단간 접근법보다 더 효과적일 수도 있는데요. 적어도 종단간 접근법에 필요한 데이터를 충분히 얻기까지는요 종단간 딥 러닝 작동 방식을 살펴보았습니다. 이는 아주 효과적일 수 있고 시스템을 단순화할 수 있으며 설계된 수제 개별 요소를 많이 만들 필요도 없습니다.

하지만 동시에 만병 통치약도 아닙니다. 항상 효과적인 것도 아닙니다.
