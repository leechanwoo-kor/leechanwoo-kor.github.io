---
title: "[Ⅲ. Structuring Machine Learning Projects] Setting Up your Goal (1)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
  - Deep Learning
  - Inductive Transfer
  - Machine Learning
  - Multi-Task Learning
  - Decision-Making
toc: true
toc_sticky: true
toc_label: "Setting Up your Goal (1)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/179931579-167db454-5d9d-4e0d-a8fe-454770dc97a6.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Structuring Machine Learning Projects

## Setting Up your Goal

### Satisficing and Optimizing Metric
하이퍼 파라미터를 튜닝하거나 알고리즘 교육에 다른 아이디어를 시도하거나 머신러닝 시스템을 만드는 데 있어 다양한 옵션을 시도하는 등 어떤 경우라도 단일 실수 평가 지표가 있다면 진행 속도가 훨씬 빨라지는 것을 보게 될 것입니다. 이 지표는 새롭게 시도한 것들이 더 잘 작동하는지 더 안 좋은 결과를 내는지 알려 주기 때문입니다. 그래서 보통 팀들이 머신러닝 프로젝트를 시작할 때 단일 실수 평가 지표를 사용할 것을 권장합니다.

---

![image](https://user-images.githubusercontent.com/55765292/180695909-7e1cbdd5-6479-4b62-b1e7-798de1afb183.png)

예시를 한번 보겠습니다. 응용 머신러닝은 실증적 증거에 기반한 절차입니다. 어떤 아이디어가 있으면 이를 코드화하고 실험을 해 결과를 획득하고 그 결과를 이용해 아이디어를 정제합니다. 이러한 절차를 계속 루프처럼 반복해 알고리즘을 계속 개선해 나갑니다.

예를 들어 분류기 A를 전에 만들어 두었다고 해 봅시다. 그리고 하이퍼 파라미터와 훈련 세트 등에 변화를 주어 새로운 분류기 B를 훈련했다고 해봅시다. 한가지 합리적인 분류기 성능 평가 방법은 정밀도와 재현율을 보는 것입니다. 정확히 정밀도와 재현율이 어떻게 되어 있는지 보는 것은 이번 예시에서 사실 그리 중요하지 않습니다. 간단히 말해 정밀도의 정의는 고양이 인식 분류기를 예로 들면 몇 퍼센트가 고양이인지 보여주는 정확도입니다.

만약 분류기 A가 95%의 정확도를 보인다면 분류기 A가 고양이를 올바르게 판별하는 확률은 95%입니다. 재현율은 실제 고양이 이미지 중 몇 퍼센트가 분류기를 통해 올바르게 인식이 되었는가를 뜻합니다. 그렇다면 만약 분류기 A의 재현율이 90%라고 하면 모든 개발 세트의 이미지에서 실제로 고양이인 이미지를 90% 정확도로 인식했다는 뜻입니다. 그러니 정밀도와 재현율의 정의를
너무 신경쓸 필요는 없습니다.

정밀도와 재현율 간에는 트레이드오프가 존재하는 것으로 밝혀졌는데 둘 다 신경 쓸 수 밖에 없습니다. 만약 분류기가 어떤 것이 고양이라고 하면 그럴 확률이 매우 높기를 바랄 것입니다. 동시에 분류기가 실제 고양이 이미지의 대부분을 고양이라고 올바르게 인식하길 바랄 것입니다. 그렇기 때문에 분류기를 정밀도와 재현율의 기준에서 평가하는 것이 합리적인 것이라고 할 수 있습니다.

평가 측정 지표로 정밀도와 재현율을 사용할 때의 문제는 여기에서 그렇듯 분류기 A가 재현율에 강하고 분류기 B는 정밀도에 강한 경우 어떤 분류기가 더 좋은지 알기 어려울 수 있습니다. 여러 아이디어와 하이퍼 파라미터를 시도해 보고 있다면 단지 분류기 두 개만이 아니라 열댓 개를 테스트해 본 뒤 약 12가지의 분류기를 테스트해봐서 가장 좋은 것을 고르는 것이 좋습니다.

그 뒤로는 계속 반복 수행할 수 있습니다. 또 이 두 가지의 평가 지표로는 둘 중 하나를 빨리 선택하거나 열 개 중 하나를 선택하는 것이 어렵습니다. 그래서 분류기를 선택할 때 추천드리는 것은 정밀도와 재현율이라는 수치 두 개를 사용하기보다는 정밀도와 재현율을 결합한 새로운 평가 지표를 찾는 것입니다.

머신러닝 에서는 정밀도와 재현율을 결합할 때 F1 score라는 것을 쓰는 게 정석입니다. F1 score의 상세내용은 그리 중요하지 않습니다만 대략적으로 P라는 정밀도 값과 R이라는 재현율 값의 평균이라고 보시면 됩니다. 공식적으로 F1 score는 다음 공식으로 정의되는데요.

$\dfrac{2}{\cfrac{1}{P} + \cfrac{1}{R}}$

수학에서는 이 공식을 정밀도 P와 재현율 R의 조화평균이라고 합니다. 비공식적으로는 정밀도와 재현율의 평균값을 구하는 것이라고 생각하시면 편합니다. 산술 평균이 아니라 이 공식으로 정의된 조화 평균을 사용합니다. 정밀도와 재현율의 균형을 맞추는 데에는 장점이 있습니다만.

이번 예시에서는 분류기 A가 더 나은 F1 score를 갖는다는 것을 바로 보실 수 있습니다. F1 score가 정밀도와 재현율을 결합하는 데 합리적인 방법이라고 가정하면 분류기 A가 B보다 낫다고
빠르게 판단할 수 있겠지요.

평가 지표를 사용하면 분류기 A와 B 중 무엇이 더 나은지 빨리 파악할 수 있어 개발 세트와 단일 실수 평가 지표를 함께 사용하면 머신 러닝 알고리즘 개선을 위한 반복 수행 속도를 높일 수 있습니다.

---

![image](https://user-images.githubusercontent.com/55765292/180695930-6cf6f82a-f99b-44ea-af22-1b9ec64364d5.png)

다른 예시를 보시죠 고양이 애호가들을 위해 4대륙에 고양이 어플을 만든다고 해 봅시다 미국, 중국, 인도 그리고 나머지 지역에서요. 그리고 2가지 분류기가 이 네 대륙에서 얻은 데이터에서 다양한 오류를 냈다고 해 봅시다. 알고리즘 A는 미국 유저가 제출한 사진에서 3% 오류를 내는 식으로요.

그렇다면 이 서로 다른 시장 또는 대륙에서 분류기가 얼마나 잘 작동하는지 추적하는 것이 합리적일 수 있습니다. 하지만 이 네 수치를 추적하면서 이를 보고 알고리즘 A와 B 중 무엇이 더 나은지 빨리 결정하는 것은 쉽지 않습니다. 그리고 여러 분류기로 테스트를 하게 되면 많은 수치를 보며 하나를 빨리 고르는 것은 꽤나 어렵습니다.

그래서 이번 예시에서 추천하는 것은 네 개 대륙에서의 성능을 추적하는 동시에 평균을 계산하는 것입니다. 평균 성능이 합리적인 단일 실수 평가 지표라고 하면 평균값을 산출함으로써 알고리즘 C가 가장 낮은 평균 오류값을 가지고 있다는 것을 빠르게 확인할 수 있습니다.

그럼 바로 C를 선택해 진행할 수 있겠죠. 지속적으로 반복 수행을 할 알고리즘을 골라야 합니다. 머신러닝에서의 작업은 보통 아이디어를 내고 이를 시도해 본 뒤 그 아이디어가 도움이
되었는지 확인하는 절차를 따릅니다.

단일 실수 평가 지표를 이용해 전체적인 효율성을 높이거나 프로젝트 팀의 효율적인 의사결정을 도울 수 있습니다. 효과적인 평가 지표를 구축하는 방법에 대한 논의가 아직 완전히 끝난 것은 아닙니다.
