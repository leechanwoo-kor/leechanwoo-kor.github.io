---
title: "[Ⅳ. Convolutional Neural Networks] Special Applications (2)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
  - Deep Learning
  - Facial Recognition System
  - Convolutional Neural Network
  - Tensorflow
  - Object Detection and Segmentation
toc: true
toc_sticky: true
toc_label: "Special Applications (2)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/183551502-3482e2d7-efb0-4815-9c94-b662606b4842.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Special Applications

## Face Recognition

### Triplet Loss

신경망의 파라미터를 학습하는 한 가지 방법은 여러분의 얼굴 사진에 좋은 인코딩을 제공하며 **삼중항 손실 함수**에 경사 하강을 정의하고 적용하는 것입니다.

이게 무슨 말인지 한번 보도록 하겠습니다.

#### Learning Objective

![image](https://user-images.githubusercontent.com/55765292/187105916-39d53623-29d1-4c4b-8ccc-ac62358f6150.png)

**삼중항 손실**을 적용하려면 이미지 쌍을 비교해야 합니다. 주어진 그림에서 신경망의 파라미터를 배우려면 동시에 여러 그림을 봐야 합니다.

예를 들어, 좌측 이미지 쌍이 주어지면 여러분은 인코딩이 동일하기를 바랍니다. 왜냐하면 이들은 같은 사람이기 때문이죠.

반면, 우측 이미지 쌍이 주어지면 여러분은 이들이 다른 사람이기 때문에 상당히 달라지기를 바랍니다. 삼중항 손실의 용어적으로 여러분이 하실일은 항상 앵커의 이미지를 보고 앵커 이미지와 긍정적인 이미지 사이의 거리를 두려고 합니다.

이건 정말 긍정적 예시이죠. 같은 사람이긴 하지만 비슷하다는 뜻입니다. 반면, 쌍을 비교할 때는 거리가 훨씬 멀리 떨어져 있는 부정적인 예제를 갖는 앵커를 사용하려고 합니다.

이는 삼중항 손실이라는 용어를 발생시키는 것이며 동시에 3가지 이미지를 보고있다는 것을 뜻합니다. 여러분은 부정적 이미지뿐 아니라 앵커 이미지, 긍정적 이미지를 보게 될 것입니다. 앵커, 긍정적, 부정적을 A, P, N으로 줄여보겠습니다.

이걸 공식화하기 위해서 여러분이 원하는 것은 인코딩의 신경망 파라미터가 다음과 같은 속성을 가지는 것입니다. 앵커 인코딩에서 앵커 사이의 인코딩에서 긍정적인 예시의 인코딩을 뺀 값을 원하는 것이고, 특히, 앵커의 인코딩과 부정적의 제곱 사이의 거리 또는 제곱 노름보다 작거나 같기를 원하는 것이죠.

물론 여기가 d(A, P)이며, 이것은 d(A, N)입니다. d를 거리 함수로 생각할 수 있습니다. 알파벳 d로 시작하므로 d라고 이름을 붙였습니다.

$||f(A)-f(P)||^2 - ||f(A)-f(N)||^2 ≤ 0$

그러나 이제, 우리는 이 표현에 약간의 변화를 줄 텐데요. 즉 이것이 만족되는지 확인하는 한가지는 모든 것이 0과 같다는 것을 배우는 것 입니다 f가 항상 0을 출력한다면, 이 값은 0 - 0, 즉 0이며, 이 값은 0 - 0이며, 0이므로, 음, 어떤 이미지의 f가 모두 0의 벡터라면, 여러분은 거의 이 방정식을 만족시킬 수 있습니다.

신경망이 0을 출력하지 않는다는 것을 확인하기 위해 모든 인코딩에서는 또는 모든 인코딩들이 서로 동일하게 설정되지 않아야 합니다. 신경망이 삼중 출력을 주는 또다른 방법은 모든 이미지에 대한 인코딩이 다른 모든 이미지에 대한 인코딩과 동일하면 0 - 0이 됩니다.

여러분의 신경망이 그러한 것을 못하도록 하기 위해 목표를 수정하여 0보다 작을 필요는 없다고 하는것이지만 0보다 약간 작아야 합니다.

따라서, 특히 부정적 알파보다 작을 필요가 있다고 하면 알파는 또 다른 하이퍼 파라미터인데요. 이것은 신경망이 삼중 해결을 출력하지 못하게 합니다.

관례상 일반적으로 우리는 네거티브 알파 대신 이쪽에 플러스 알파라고 씁니다 그리고 이것을 마진$\alpha$이라 부르는데 이것은 서포트 벡터 기계에 대한 문헌을 보았다면 익숙한 용어 이실 겁니다.

우리는 또한 이 마진 파라미터를 추가하여 위에 이 방정식을 수정할 수 있습니다. 마진을 0.2로 설정했다고 합시다.

이 예제에서 앵커의 d와 포지티브가 0.5 인 경우, 앵커와 네거티브 사이의 d가 0.51처럼 조금만 더 크면 만족하지 못할 것입니다. 1에서. 0.51이 0.5보다 크더라도 여러분은 충분하지 않다는 것을 말하고 있습니다.

우리는 d(A, N)이 d(A, P) 보다 훨씬 더 클 것을 원하죠. 특히, 여러분은 이것이 적어도 0.7 이거나 혹은 그 이상이 되기를 원합니다.

대안적으로, 이 마진 또는 이 간격을 0.2 이상으로 설정하려면 이 값을 밀어 올리거나 아래로 밀어서 따라서 이 하이퍼파라미터 알파 0.2의 간격이 앵커와 부정적 사이의 거리 대 앵커와 네거티브의 거리 사이에 있어야 하죠. 그게 바로 마진 파라미터가 하는 일입니다.

이것은 앵커 긍정적 쌍과 앵커 부정적 쌍을 서로서로 더 멀어질 수 있도록 밀어내는 것이죠. 자, 여기 아래의 방정식과 다음 그림를 봅시다. 그것을 공식화하고, 삼중항 손실 함수를 정의 내려봅시다.

#### Loss function

![image](https://user-images.githubusercontent.com/55765292/187105954-b3ae5e1d-8877-426e-8716-c92c7dbbdbd8.png)

**삼중항 손실 함수**는 3중 이미지에 정의되어 있습니다. 주어진 세 개의 이미지인 A, P, 그리고 N, 앵커의 긍정적인 예와 부정적인 예, 그러니까 긍정적인 예는 앵커와 동일인물인데 네거티브는 앵커와는 다른 사람이에요.

손실을 다음과 같이 정의 할 것입니다. 이 예제에서 손실은 실제로 세 개의 이미지에서 정의되어 있습니다. 이전 그림에서 봤던 것을 우선 복사하겠습니다.

$||f(A) - f(P)||^2$와 $||f(A) - f(N)||^2$ 의 제곱을 뺀 것입니다. 그리고 나서 알파, 즉 마진 파라미터를 더하면 여러분이 원하시는것은 이것이 0보다 적거나 같은 것입니다.

따라서 손실 함수를 정의하려면 이 값과 0 사이의 최대 값을 취해 봅시다. 따라서 여기에서 최대 값을 취하는 효과는 이것이 0보다 작기만 하면 손실은 0입니다.

왜냐하면, 최대 값은 0 보다 작거나 같으며 0 이 0일 때이기 때문입니다. 제가 녹색으로 강조 표시해둔 이걸 만드는 목표를 여러분이 달성한다면 0보다 작거나 같게 만드는 목표를 달성한 경우 이 예제의 손실은 0과 같습니다.

그러나 다른 한편으로 이것이 0보다 클 때 최대 값을 취하면 최대값은 제가 녹색으로 밑줄 그은 이부분을 선택하므로 긍정적 손실을 갖게 됩니다.

따라서 이것을 최소화하려고 시도하면 이것은 이것을 0 또는 0 이하로 보내려고 하는 효과가 있는거죠. 그리고 0 이하 이거나 0과 같을 때, 신경망은 그것이 얼마나 더 네거티브한지는 신경 쓰지 않습니다.

따라서, 이것은 단일 삼중에 대한 손실을 정의하는 방법이며 신경망에 대한 전체 비용 함수는 서로 다른 세 쌍둥이에서 이러한 개별 손실의 훈련 세트에 대해 합산될 수 있습니다.

만약 여러분이 훈련 데이터를 가지고 있다면 1,000 명의 다른 사람의 사진이 10,000 개라면 여러분이 해야 할 일은 사진을 만 장 찍어서 이렇게 트리플렛을 고르는 데 쓰시면 됩니다.

그런 다음 이러한 유형의 비용 함수에 경사 하강을 사용하여 학습 알고리즘을 훈련합니다. 훈련 세트에서 가져온 이미지 세 개에 따라 정의됩니다. 이 세 장의 데이터 집합을 정의하려면 여러분은 A와 P의 쌍 같은 사람의 사진이 필요합니다.

시스템을 교육하려면 동일한 사람의 사진이 여러 개 있는 훈련 세트가 필요합니다. 그게 바로 이 예에서 제가 만약 여러분이 1,000 명의 다른 사람의 사진이 10,000 개라면 데이터 세트 전체를 구성하기 위해 평균적으로 1,000명당 10장의 사진이 있을 수 있습니다. 각 사람의 사진이 하나뿐이라면 이 시스템을 실제로 훈련 할 수 없습니다.

하지만 물론 시스템을 교육한 후에 여러분은 그것을 얼굴 인식 시스템의 경우 여러분이 알아보려고 할 수 있는 누군가의 사진 한 장만 가지고 있는 원샷 학습 문제에 적용할 수 있습니다.

하지만 여러분의훈련 세트에서는 고정 이미지와 긍정적인 이미지 쌍을 가질 수 있도록 적어도 훈련 세트에 있는 일부 사용자에 대해 동일한 사람의 이미지가 여러 개 있는지 확인해야 합니다.

자, 실제로 훈련 세트를 구성하려면 어떻게 이 트리플렛을 골라야 할까요?

#### Choosing the triplets A,P,N

![image](https://user-images.githubusercontent.com/55765292/187105974-5aa8f65d-93dc-4101-877a-17a5a81c888c.png)

문제점 중의 하나는 만약 여러분이 A, P와 N를 여러분의 훈련 세트에서 무작위로 선택할 경우, A와 P는 동일한 사람이고 A와 N은 다른 사람이어야 합니다.

만약 당신은 그들이 무작위가 되도록 그들을 선택할 경우, 이 제약 조건을 매우 쉽게 만족할 수 있습니다. 두 개의 무작위로 선택된 사람들의 그림이 주어 졌기 때문에 A와 P 보다 A와 N은 아주 많이 다를 가능성을 가지고 있습니다.

이 표기법을 여전히 기억하고 있기를 바라는데요 d(A,P)는 이 인코딩의 마지막 몇 그림에서 높게 작성됩니다. 이 값은 우리가 이전 선에서 가졌던 인코딩들 사이의 제곱 노름 거리와 같습니다. 그러나 A와 N이 무작위로 선택된 다른 사람이라면 그러면 왼쪽의 용어보다 훨씬 더 큰, 마진 도우미보다 훨씬 더 큰 가능성이 있고 신경망은 그것으로부터 많은 것을 배우지 못할 것입니다.

훈련 세트를 구성하기 위해서는 세 트리플, A, P, N을 선택하는 것인데 그들은 훈련하기 가장 "힘든" 존재입니다. 그래서 여러분이 원하는 것은 이 제약이 만족되는 트리플렛이죠.

"힘든" 이 트리플렛은 만약 당신이 A, P, N에 대한 값을 선택한다면, 따라서 d (A, P)는 실제로, d (A, N)에 상당히 근접해 있을 수 있습니다.

이 경우, 학습 알고리즘 오른쪽에 있는것을 위로 올리려고 특별히 노력하거나 또는 왼쪽에 있는 것을 아래로 밀어내야 합니다. 따라서 왼쪽과 오른쪽 사이에 최소 알파의 간격이 있게 말이죠.

이 트리플렛을 선택하는 것의 효과는 학습 알고리즘의 계산 효율성이 높아지는 것 입니다. 트리플렛을 무작위로 선택하면 너무 많은 트리플렛이 정말 쉬울 것이고 경사 하강은 아무 소용이 없을 것입니다.

왜냐하면 여러분의 신경망이 꽤 그것을 바로 잡기 떄문입니다. 경사 하강 절차가 이러한 양을 트리플렛으로부터 더 멀리 밀어내기 위해 몇 가지 작업을 수행해야 하는 것은 오직 "힘든"을 선택하는겁니다.

관심이 있으시면 자세한 내용은 Florian Schroff, Dmitry Kalenichenko, James Philbin에 의해 이 논문에 제시되는데 그들은 FaceNet이라고 불리는 시스템을 가지고 있고 여기에서 제가 제시하는 많은 아이디어들이 나온 곳입니다.

이것은 알고리즘이 딥러닝 세계에서 어떻게 명명되는지에 대한 재미있는 사실이며 특정 도메인에서 작업하는 경우, 우리는 그것을 블랭크라고 부릅니다. 블랭크넷 혹은 딥블랭크라고 불리는 시스템을 종종 보실 수 있을 겁니다.

우리는 얼굴 인식에 대해 이야기 해 왔습니다. 이 논문은 FaceNet이라고 불리는 것인데요. 최근에 여러분은 단지 딥페이스만 보았습니다. 그러나 블랭크네트 또는 딥블랭크의 이 아이디어는 딥 러닝 세계에서 알고리즘을 어떻게 명명하는지에 대한 매우 인기 있는 방법입니다.

훈련할 수 있는 가장 유용한 트리플렛을 선택함으로써 알고리즘 속도를 높이기 위한 다른 세부 사항들을 배우고 싶다면 자유롭게 그 논문을 살펴보아야 합니다. 이건 좋은 논문입니다.

#### Training set using triplet loss

![image](https://user-images.githubusercontent.com/55765292/187105989-2b8e4c5a-e4a0-4238-bec9-81d936dd1fda.png)

마무리하기 위해서 삼중항 손실을 훈련시키기 위해서 여러분은 훈련 세트를 가지고 그것을 많은 트리플들에 맵핑합니다. 여기에 앵커와 긍정적을 가진 트리플이 있는데요. 이 두 가지 경우에 사람은 동일하며, 다른 사람의 부정적 입니다.

여기 또 다른 것이 있습니다 앵커와 긍정적은 같은 사람입니다. 하지만 앵커와 부정적은 다른 사람이거나 등등 그렇습니다.

앵커, 긍정적 그리고 부정적 트리플을 찾기위해 여러분이 해야 할 일은 경사 하강을 사용하여 이전 그림에서 정의한 비용 함수 J를 최소화 하는 것입니다. 그것은 인코딩을 학습하기 위해 신경망의 모든 파라미터에 역전파를하는 효과가 있습니다. 그래서 두 이미지의 d가 같은 사람의 이미지일 때 작을 것이고, 다른 사람의 두 개의 이미지일 때 클 것입니다.

---

얼굴 인식을 위한 좋은 인코딩을 출력하기 위해 신경망을 훈련시키는 방법은 여기까지입니다. 이제 오늘날의 얼굴 인식 시스템, 특히 대규모 상용 얼굴 인식 시스템은 매우 큰 데이터 세트에 대해 훈련된 것으로 나타났습니다.

백만 개 이미지의 데이터 세트는 드문 일이 아닙니다. 일부 기업은 1,000만 이미지 노쓰를 사용하고 있으며 일부 기업은 이러한 시스템을 교육하기 위해 1억 이미지 노쓰를 보유하고 있습니다.

매우 큰 데이터 집합이며, 심지어 현대적인 기준에도 불구하고 이러한 데이터 세트 자산은 획득하기 쉽지 않습니다.

다행히도 일부 회사는 이러한 대규모 네트워크를 훈련하고 파라미터를 온라인에 게시했습니다. 이러한 네트워크를 처음부터 훈련하려고 하기보다 이 도메인은 데이터 볼륨 크기가 크기 때문에 처음부터 모든 작업을 수행하는 대신 다른 사용자의 사전 교육 모델을 다운로드하는 것이 유용할 수 있습니다. 모든 걸 처음부터 혼자서 하려고 하기보다는 말이죠.

하지만 다른 사람의 사전 교육 모델을 다운로드 하여도 이러한 아이디어를 응용하기 위해 처음부터 적용해야 할 경우에 이러한 알고리즘이 어떻게 훈련되었는지 아는 것은 여전히 유용하다고 생각합니다.


### Face Verification and Binary Classification

**삼중항 손실**은 얼굴 인식을 위한 컨볼네트의 파라미터를 배우는 좋은 방법 중 하나입니다. 이러한 파라미터를 학습하는 또 다른 방법이 있습니다. 얼굴 인증이 어떻게 선형 이진 분류 문제로 제기 될 수 있는지 보여 드리겠습니다.

#### Learning the similarity function

![image](https://user-images.githubusercontent.com/55765292/187125314-5612488b-2cf3-4a80-b579-8b7c5323ae8a.png)

신경망을 훈련시키는 또 다른 방법은 이 샴 네트워크 쌍을 가져 와서 이 두 가지 임베딩을 산출하도록 합니다. 아마도 128 차원의 임베딩일텐데요. 어쩌면 더 높은 차원일수도 있죠.

그리고 나서 이들을 로지스틱 회귀분석 단위에 입력해서 예측을 하게 합니다. 여기서 두 사람이 같은 사람이라면 목표 출력은 1 이 되고 이 둘이 다른 사람의 경우는 0이 됩니다. 따라서 이것이 얼굴 인식을 이진 분류 문제로 취급하는 이유입니다.

이것은 이와 같은 시스템을 훈련시키기 위한 삼중항 손실의 대안입니다. 이 최종 로지스틱 회귀분석 단위는 실제로 무슨 일을 할까요?

출력 $\hat{y}$은 시그모이드 함수이며 몇 가지 특성 세트에 적용될 것입니다. 하지만 단지 인코딩만 하는 것은 아니고 인코딩 사이의 차이점을 알아내는 것입니다. 이게 무슨 뜻인지 보시죠.

예를 들어, K의 합은 절대값의 1에서 128까지입니다. 

$\hat{y} = \sigma(\displaystyle\sum_{k=1}^{128}w_i|f(x^{(i)})_k-f(x^{(j)})_k|+b)$

이 표기법에서 함수 $f(x^{(i)})$는 이미지 $x_i$의 인코딩이고 K는 이 벡터의 cave 컴포넌트를 선택하는 것을 의미합니다. 이렇게 해서 이 두 인코딩 간의 요소 y 차이를 절대값으로 얻는 것입니다. 이 128개의 숫자를 로지스틱 회귀 분석에 입력하는 특성으로 생각할 수 있습니다.

그러면 작은 회귀분석이 일반적인 로지스틱 회귀분석 단위와 유사한 추가 파라미터 w, i 및 b를 가질 수 있음을 알게 될 것입니다. 그리고 이 128개의 특성에 대해 적절한 대기 훈련을 실시하여 이 두 이미지가 같은 인물인지 다른 인물인지를 예측할 수 있습니다. 같은 사람이든 다른 사람이든 0 또는 1을 예측하는 법을 배우는 데 도움이 될 것입니다.

그리고 녹색으로 밑줄 친 수식을 계산하는 방법에 대한 몇 가지 다른 분산이 있습니다.

예를 들어, 다른 수식은 $f(x^{(i)})_k - f(x^{(j)})_k$를 제곱한 후 f(x^{(i)})_k + f(x^{(j)})_k로 나누는 것입니다. 이것은 카이 제곱 공식이라고 불리는데요. 그리스의 알파벳 카이에서 비롯되었습니다. 이것은 때때로 카이 제곱 유사도라고도 합니다.

그리고 이것과 다른 분산은 이 DeepFace 논문에서 연구됩니다. 예전에 언급했어요. 따라서 이 학습 공식에서 입력은 한 쌍의 이미지이므로 이것이 여러분이 훈련 입력 x이고 이 출력 y는 여러분이 비슷하거나 다른 이미지를 입력하는지에 따라 이것은 0 이거나 1 이 됩니다.

그리고 이전과 마찬가지로 여러분의 훈련은 샴 네트워크 입니다. 그러니까 그것이 의미하는 것은 이는 이 위쪽에 있는 신경망은 이 아래 쪽 파라미터와 연결되어 있다는 겁니다.

그리고 이 시스템은 꽤 잘 작동 할 수 있습니다.

마지막으로 언급할만한 것은 신경 배치를 상당히 도와 줄 수 있는 계산법 입니다. 즉, 위에 새로운 이미지라면 이 직원은 출입구가 열려주길 바라며 걸어오는 직원이고 아래 데이터베이스 이미지에서 나온 것이라고 합시다.

그러면 매번 이 임베딩을 산출 할 필요 없이 미리 계산 계산해두는 것입니다.

따라서 신입 사원이 들어올 때 이 위쪽 구성 요소를 사용하여 인코딩을 산출하고 사용하면 됩니다. 그리고 나서 이걸 미리 산출 된 인코딩과 비교 한 다음 그걸 사용해서 $\hat{y}$ 예측합니다.

왜냐하면 여러분은 raw 이미지를 저장할 필요가 없고 또한 직원 데이터베이스가 매우 큰 경우 매번 모든 사원 데이터베이스에 대해 이러한 인코딩을 매번 계산할 필요가 없기 때문입니다.

이러한 자유 컴퓨팅 개념에서는 이러한 인코딩이 중요한 산출을 저장할 수 있습니다. 그리고 이러한 유형의 사전 계산은 얼굴 인식을 이진 분류 문제로 취급하는 샴 센트럴 아케텍쳐 뿐만 아니라 마지막 강의들에서 설명한 것처럼 삼중항 손실 함수를 사용하여 인코딩을 학습했을 때도 모두 작동합니다.

#### Face verification supervised learning

![image](https://user-images.githubusercontent.com/55765292/187125336-44cb4a37-519a-4302-b356-31f7e34b38d2.png)

마지막으로 정리하자면 얼굴 인증 지도 학습을 다루기 위해 여러분은 이미지 쌍의 훈련 세트를 생성합니다. 여기서는 세 개로 된 이미지 쌍이 되겠네요. 처음 타겟 라벨은 1이 됩니다. 이것들이 같은 사람의 사진이고 그리고 다음 태그 라벨이 0인 경우 이것들이 다른 사람의 사진이고 다른 쌍을 사용하여 훈련할때, 역전파를 사용하여 과학자들이 신경망을 훈련하기 위해서요.

그래서 여러분이 보셨던 얼굴 검증을 처리 버전, 즉 더 나아가 이진 분류 문제로서의 얼굴 인식인데요. 이것 또한 잘 작동합니다. 이런 식으로 여러분이 이제 아셨기를 바랍니다. 훈련하기 위해 원샷 학습을 할 수있는 여러분의 얼굴 검증이나 얼굴 검증 시스템입니다.
