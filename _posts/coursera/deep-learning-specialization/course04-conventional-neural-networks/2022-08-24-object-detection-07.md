---
title: "[Ⅳ. Convolutional Neural Networks] Object Detection (7)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
  - Deep Learning
  - Facial Recognition System
  - Convolutional Neural Network
  - Tensorflow
  - Object Detection and Segmentation
toc: true
toc_sticky: true
toc_label: "Object Detection (7)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/183551502-3482e2d7-efb0-4815-9c94-b662606b4842.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Object Detection

## Detection Algorithms

### U-Net Architecture Intuition

전치 컨볼루션으로 이제 여러분은 단위 아키텍처의 세부 사항으로 넘어갈 준비가 되었습니다. 이번에는 먼저 아키텍처에 대해 간단히 살펴보고 단위의 작동 방식에 대한 직관을 구축합니다. 그리고 이어서 자세한 내용을 함께 살펴보겠습니다.

#### Deep Learning for Semantic Segmentation

![image](https://user-images.githubusercontent.com/55765292/186337258-d8a59dbf-4150-4177-a9b4-ded04bb9794d.png)

여기에 영상 분할을 위한 신경망 아키텍처의 대략적인 그림입니다. 그래서 우리는 신경망의 첫 번째 부분에는 일반 컨볼루션을 사용합니다. 이전에 보신 신경망과 비슷합니다.

신경망의 이 부분은 이미지를 압축합니다. 여러은 매우 큰 이미지에서 이 활성화의 높아진 부분은 훨씬 적은 이미지로 변했습니다. 즉, 차원이 훨씬 작기 때문에 공간 정보가 많이 손실된 것이고 하지만 훨씬 더 깊습니다.

예를 들어, 이 중간 층은 이미지의 오른쪽 아래에 대략적으로 고양이가 있는 것처럼 보이는 것을 나타낼 수 있습니다. 그러나 상세한 공간 정보가 손실 이유는 높아진 부분이 훨씬 더 적기 때문입니다.

그런 다음 이 신경망의 두 번째 절반은 전치 컨볼루션을 사용하여 표현 크기를 원래 입력 이미지의 크기로 되돌립니다. 이제 이 아키텍처에는 한 가지 변경 사항이 있어 훨씬 더 효율적으로 동작할 수 있습니다. 이를 유닛 아키텍처로 변환합니다.

즉, 이렇게 초기 레이어에서 이후 레이어로의 연결을 건너뜁니다. 따라서 이 이전 활성화 블록은 이후 블록에 직접 복사됩니다. 우리는 왜 이것을 하는 것을 원할까요?

이를 위해 고양이 영역을 결정하기 위한 다음 마지막 층이 밝혀졌습니다. 두 가지 유형의 정보가 유용하죠.

하나는 상위 레벨, 공간, 이 이전 레이어에서 얻은 높은 수준의 컨텍스트 정보입니다. 신경망이 바라건대 높은 수준의 컨텍스트 정보는 이미지의 오른쪽 아래 모서리 또는 오른쪽 부분에서 고양이와 같은 일이 일어나고 있다는 것을 알아냈습니다.

하지만 누락된 것은 매우 상세하고 미세한 공간적 정보입니다. 왜냐하면 이 일련의 활성화는 공간 해상도가 낮기 때문입니다. 그래서 건너뛰기 연결은 신경망이 고해상도, 낮은 레벨의 함수 정보를 가질 수 있게 해주는데 픽셀 위치마다 얼마나 많은 좋은 물질이 이 픽셀 안에 들어있는지 말이죠.

나중에 이 이후 레이어으로 바로 가기 위해 건너뛰기 연결을 사용합니다. 이런 식으로 이 레이어의 해상도는 낮지만, 높은 수준의, 공간적, 높은 수준의 문맥적 정보와 낮은 수준의 정보를 모두 얻을 수 있습니다.

하지만 특정 픽셀이 고양이의 일부인지 아닌지에 대한 판단을 위한 정보처럼 보다 상세한 텍스처입니다.

유닛이 어떻게 작동하는지에 대해 간략하고 높은 수준의 직관을 볼 수 있습니다. 이어서 구현 방법에 대한 자세한 내용을 살펴보겠습니다.


### U-Net Architecture

작업한 많은 응용 프로그램에 유닛 아키텍처가 유용하다는 것을 알게 되었고 오늘날 컴퓨터 시각의 가장 중요하고 기초적인 신경 네트워크 아키텍처 중 하나가 있습니다.

U-Net이 어떻게 작동하는지 정확하게 자세히 살펴보도록 하죠.

#### U-Net

![image](https://user-images.githubusercontent.com/55765292/186337681-63b878c7-99a5-4230-9b05-c1b4ec4aa0e9.png)

이것이 U-Net의 모습입니다. 이 그림에서 많은 일이 일어나고 있다는 것을 알고 있고 한 번에 한 단계씩 나눠서 진행해도 괜찮습니다. 하지만 저는 여러분에게 유닛 아키텍처의 최종 결과를 보여드리고 싶습니다.

그리고 이것은 U-Net이라고 불리는 이유인데, 왜냐하면 U처럼 보이기 때문입니다. 하지만 이것을 분해해서 한 번에 한 조각씩 다시 만들어 보도록 하죠. 그래서 우리는 이 다이어그램에 있는 모든 것들이 실제로 무엇을 하고 있는지 확실히 알 것입니다.

이 아이디어들은 Fisher와 Thomas Bronx에 대한 Olaf Ranneberger 때문이었습니다. 재미있는 사실은 그들이 유닛 논문을 썼을 때 그들은 의학적 이미지 세그멘테이션 응용을 생각하고 있었습니다.

실제로 의학 영상을 세그멘테이션하는 것이죠. 그러나 이러한 아이디어는 다른 많은 컴퓨터 시각 시맨틱 세그멘테이션 애플리케이션에도 유용한 것으로 밝혀졌습니다.

---

![image](https://user-images.githubusercontent.com/55765292/186337734-db836648-9b96-4add-aaec-adbf6f99788f.png)

단위에 대한 입력은 이미지입니다. 예를 들어, 3채널 RGB 채널의 경우 $h \times w \times 3$입니다. 이 이미지를 그와 같은 얇은 레이어로 시각화 할 것입니다. 이전에 신경망 레이어를 가지고 그들을 그린 것을 알고 있는데 이와 같은 3개의 D 블록으로서, 여기서는 w가 3으로 증가할 수 있습니다.

그러나 단위도를 더 단순하게 보이게 하려면 이 가장 자리만 보고 상상하면 됩니다. 그래서 여러분이 보시는 것은 이것입니다. 그리고 나머지는 제가 그린 짙은 파란색 사각형 뒤에 숨어 있습니다. 이것이 바로 이것입니다.

이것의 높이는 h, 그리고 이것의 폭은 오른쪽 3이며, 채널 수로 볼 때 깊이는 3입니다. 그래서 매우 얇아 보이죠.

따라서 유닛 다이어그램을 단순화하려면 저는 이 알고리즘을 설명하기 위해 3개의 D자형 대신 이 직사각형을 사용할 것입니다. 유닛의 첫번째 부분은 일반 피드 포워드 신경망 컨볼루션 레이어를 사용합니다.

그래서 저는 검은색 화살표를 사용하여 컨볼루션 레이어를 나타낼건데, 다음에 값 활성화 함수가 표시됩니다. 그래서 다음 레이어는 우리는 채널의 수를 조금 늘렸지만, 차원은 여전히 높낮이, 너비, 그리고 활성화 기능이 있는 또 다른 나선형 레이어입니다. 지금 우리는 여전히 신경망의 절반을 했습니다.

맥스 풀을 사용하여 높이와 너비를 줄일 것입니다. 그래서 아마 높이와 너비가 더 낮은 일련의 활동들로 끝날 수도 있지만 그래서 채널의 수가 증가하고 있습니다.

그리고 무선 활성화 기능이 있는 정상 피트 포워드 컨볼루션의 두 레이어가 더 있고 그리고 나서 다시 Max 풀링 공급이 있습니다. 그래서 여러분은 그것을 얻을 수 있습니다. 그리고 여러분은 다시 반복합니다. 그러면 결국 여러분은 이것을 얻게 됩니다.

지금까지 일반적인 컨볼루션 레이어에는 활성화 기능이 있습니다. 이전에 사용하던 최대 풀링 레이어입니다. 그래서 제가 하고 있는 이 레이어의 높이는 아주 작다는 것을 알 수 있습니다.

그래서 우리는 전치 콘볼루션 레이어를 적용하기 시작할 것입니다. 녹색 화살표 옆에 적어두면 이 신경망의 차원을 다시 세울 수 있습니다.

따라서, 첫 번째 전치 컨볼루션 레이어 또는 트랜스 코브 레이어로 그것과 비슷한 일련의 활성화를 얻게 될 것입니다. 이 예제에서는 높이와 너비를 늘리지 않았습니다. 하지만 우리는 채널의 수를 감소시켰습니다.

하지만 유닛을 만들기 위해 해야 할 일이 하나 더 있는데요. 그것은 이 회색 화살표로 표시하려는 스킵 연결을 추가하는 것 입니다. 건너뛰기 연결은 이 활성화 세트를 가져다가 오른쪽으로 복사하는 역할을 합니다. 그래서 결국에는 여러분이 가지고 있는 일련의 활동들이 이런 식이 됩니다.

옅은 청색 부분은 전치 컨볼루션으로부터 나오며 그리고 어두운 파란색 부분이 왼쪽에서 방금 복사되었습니다. 유닛을 계속 구축하기 위해 일반 컨볼루션을 몇 층 더 적용할 예정입니다.

검은색 화살표로 표시된 값 활성화 함수에 이어 다른 전치 컨볼루션 레이어를 적용합니다. 녹색 화살표와 여기 우리는 이 이미지의 높이와 폭을 늘리기 시작할 것입니다. 그리고 지금은 높이가 점점 커지고 있습니다.

하지만 여기서도 스킵 연결을 적용할 것입니다. 그래서 다시 한 번 회색 화살표가 있는데 이 화살표들이 이 활성화 세트를 가지고 있고 저는 이것을 그냥 오른쪽에 복사했습니다. 더 많은 컨볼루션 레이어 및 다른 전치 콘볼루션 건너뛰기 연결 말이죠.

다시 한 번 이전과 동일하게 사용할 것입니다. 그리고 그것을 오른쪽으로 복사한 다음 더 복잡한 레이어로 복사하면 그 뒤에 또 다른 전치 컨볼루션이 있습니다. 연결을 건너뛰고 이를 복사합니다.

이제 원래의 입력 이미지, 높이 및 너비인 일련의 활성화로 돌아왔습니다. 몇 가지 레이어의 정상 요금 전달 컨볼루션과 그리고 마지막으로 이것을 우리의 세그멘테이션 맵에 매핑하기 위해 자홍색 화살표로 표시하고자 하는 한 개의 컨볼루션을 사용하여 최종적으로 이 결과를 출력할 것입니다.

이 출력 레이어의 차원은 $h \times w$가 되므로, 그래서 클래스 별 원래 입력 차원과 동일합니다. 따라서 만약 여러분에게 세 개의 클래스가 있는 경우에는 이것은 세개가 될 것입니다.

만약 여러분이 여러분의 세그멘테이션에서 인식하려고 시도할 10개의 다른 클래스가 있다면 그 마지막 숫자는 10이 될 것입니다. 이것은 여러분이 가지고 있는 $h \times w$ 픽셀의 모든 픽셀에 대해 배열이나 벡터, 즉 픽셀의 n개 클래스 번호에 대해 픽셀이 각각의 다른 클래스에서 나올 가능성을 알려줍니다.

이 n개 클래스 위에 arg max를 구하면 각 픽셀을 클래스 중 하나로 분류할 수 있으며 오른쪽에 표시된 세그멘테이션 맵처럼 시각화할 수 있습니다.
