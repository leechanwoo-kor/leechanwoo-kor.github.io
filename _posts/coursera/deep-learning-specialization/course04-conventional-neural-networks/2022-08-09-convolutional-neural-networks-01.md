---
title: "[Ⅳ. Convolutional Neural Networks] Convolutional Neural Networks (1)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
  - Deep Learning
  - Facial Recognition System
  - Convolutional Neural Network
  - Tensorflow
  - Object Detection and Segmentation
toc: true
toc_sticky: true
toc_label: "Convolutional Neural Networks (1)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/183551502-3482e2d7-efb0-4815-9c94-b662606b4842.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Convolutional Neural Networks

## Foundations of Convolutional Neural Networks

### Convolutional Neural Networks

컴퓨터 비전은 딥러닝 덕분에 빠르게 발전하고 있는 분야 중 하나입니다.

딥러닝 컴퓨터 비전은 현재 자율주행차가 주변의 다른 차들과 보행자들을 피하기 위해 그들이 어디에 있는지 알아내는 데 도움을 주고 있습니다. 안면 인식은 예전보다 훨씬 성능이 좋아져서 아마도 여러분 중 몇몇은 조만간 혹은 이미 얼굴만으로 잠긴 핸드폰을 열거나 심지어 잠긴 문을 열 수도 있을 것입니다.

여러분의 핸드폰에는 틀림없이 음식 사진이나 호텔 사진 혹은 재미있는 풍경 사진들을 보여주는 앱들이 많이 있을 것입니다. 그런 앱들을 만드는 몇몇 회사들은 딥러닝을 사용해서 가장 매력적이고 가장 아름답거나 혹은 가장 적절한 사진들을 당신에게 보여주도록 하고 있습니다.

그리고 딥러닝이 심지어 새로운 유형의 예술을 탄생시키기도 한다고 생각합니다. 그래서, 컴퓨터 비전에 대한 딥러닝에 대해 저뿐만 아니라 여러분 또한 흥미로워 할 것이라고 생각하는 두 가지 이유가 있습니다.

첫째, 컴퓨터 비전의 급속한 발전은 비록 몇 년 전만 해도 불가능했지만 새로운 응용 프로그램들을 가능하게 했습니다. 그리고 이러한 툴을 학습함으로써 아마 이러한 새로운 제품과 애플리케이션을 고안해 낼 수 있을 것입니다.

둘째, 컴퓨터 비전 시스템을 구축하지 않더라도 컴퓨터 비전 연구 커뮤니티가 새로운 신경망 아키텍처와 알고리즘을 고안하는데 매우 창의적이고 독창적이기 때문에 실제로 다른 영역에서도 많은 교잡을 만들어 낼 수 있다는 것을 알게 되었습니다.

예를 들어, 저는 음성 인식 작업을 할 때 실제로 컴퓨터 비전에서 아이디어를 얻어 음성 문헌에 차용하기도 했습니다. 따라서, 컴퓨터 비전에 대한 작업을 끝내지 않더라도 이 과정에서 배운 아이디어 중 일부가 알고리즘과 아키텍처에 도움이 되기를 바랍니다.

---

![image](https://user-images.githubusercontent.com/55765292/183552218-57b01909-358f-4229-af37-a6f62bbe02a1.png)

이 과정에서 우리가 학습하게 될 컴퓨터 비전 문제점들의 몇 가지 예시입니다.

여러분은 이미 64 x 64 사이즈의 이미지가 고양이인가? 라고 생각할 수 있는 영상 인식이라고 불리기도 하는 이미지 분류를 보았습니다. 컴퓨터 비전 문제점의 또 다른 예시는 물체 감지입니다. 그래서 만약 여러분이 자율주행차를 만들고 있다면 이 이미지 안에 다른 차들이 있다는 것을 알 필요가 없을지도 모릅니다.

하지만 대신 당신은 이 사진에서 다른 차들을 피하기 위해서 그들의 위치를 파악해야 합니다. 일반적으로 물체 감지에서 우리는 이러한 다른 물체가 자동차와 그림을 의미하지 알아낼 뿐만 아니라 그것들 주변에 네모를 그려야 합니다. 이러한 물체가 그림에서 어디에 있는지 인식하는 다른 방법이 있습니다.

그리고 이 예시에서 같은 사진 안에 여러 대의 자동차가 있다는 것이나 적어도 한 대가 여러분의 자동차에서 일정 거리 안에 있을 수도 있다는 것을 알아차려야 합니다.

여기 또 다른 예가 있는데 아마도 더 재미있는 것은 신경 스타일 전달일 것입니다. 그림 한 장이 있는데 여러분이 다른 스타일로 이 그림을 다시 칠하고 싶다고 가정해 보겠습니다. 신경 스타일 전달입니다. 컨텐츠 이미지가 있고 스타일 이미지가 있습니다. 사실 오른쪽 이미지는 피카소의 작품입니다. 그리고 신경망으로 하여금 이미지들을 조합하여 왼쪽의 콘텐츠 이미지를 오른쪽의 스타일 이미지로 다시 칠해서 마침내 아래와 같은 그림이 만들어집니다.

그래서 이런 알고리즘이 새로운 유형의 작품을 만들어 내도록 하는 것입니다. 그리고 이 과정에서는 여러분도 이것을 직접 하는 방법을 배우게 될 것입니다. 컴퓨터 비전 문제의 과제 중 하나는 입력이 정말 커질 수 있다는 것입니다.

---

![image](https://user-images.githubusercontent.com/55765292/183552265-7a9f9cd6-56e0-4e46-99ef-25b65f21fd29.png)

예를 들어 이전 강의들에서 여러분은 64 x 64 크기의 이미지로 작업을 했습니다. 3가지 색상 채널이었기 때문에 64 x 64 x 3이라고 할 수 있습니다. 이것들을 곱해보면 12288이 됩니다. 따라서 입력 값인 x의 크기는 12288가 되는 것이죠. 나쁘지는 않습니다.

하지만 64 x 64는 사실 매우 작은 크기의 이미지입니다. 1000 x 1000 픽셀의 이미지처럼 더 큰 이미지로 작업 한다면 100만 픽셀이 되는 것이죠. RGB 채널이 3개이기 때문에 입력 값의 크기는 1000 x 1000 x 3 이며 300만이 되는 것입니다. 만일 이것을 작은 화면에서 본다면 선명하지 않을 수 있으나 이것은 저해상도인 64 x 64 이미지이고 이것은 높은 해상도의 1000 x 1000 이미지입니다.

입력값이 300만이라면 이 x의 크기가 300만이 됩니다. 결국 첫 번째 은닉 층에서 1000개의 은닉 유닛이 있다면 총 무게는 W1 행렬이 됩니다. 만일 과정 1이나 2에서 다루었던 표준 혹은 완전히 연결된 네트워크를 사용한다면 이것은 1000 x 3000000 차원의 행렬이 될 것입니다. x는 R에 300만을 곱한 값이 되기 때문이죠.

300만을 3m이라고 표시하겠습니다. 이는 곧 이 행렬은 매개변수가 30억으로 아주 크다는 것을 의미합니다. 매개변수가 이렇게 많으면 신경망 네트워크가 과적합을 방지하기에 충분한 데이터를 얻는 것이 어렵습니다.

또한 매개변수가 30억인 신경망을 훈련하기 위한 계산적 요구사항과 메모리 요구사항은 실행이 불가능 합니다. 하지만 컴퓨터 비전 어플리케이션에서 작은 이미지들만 한정적으로 사용하는 것을 원치 않습니다. 큰 이미지들을 사용하고 싶죠.

그러기 위해서는 합성공 신경망의 기본 구성 요소 중 하나인 합성공 연산을 더 잘 구현해야 합니다. 이것이 무엇을 의미하고 여러분이 어떻게 실행할 수 있을지 이어서 다뤄보도록 하겠습니다. 에지 검출의 예시를 통해 합성공을 설명하도록 하겠습니다.


### Edge Detection Example

합성곱 연산은 합성곱 신경망의 기본 구성 요소 중 하나입니다. 이번에는 에지 검출을 동기를 부여하는 예시로 사용해서 어떻게 합성곱 연산이 작동하는지 알아보도록 하겠습니다.

---

![image](https://user-images.githubusercontent.com/55765292/183565009-9005e4b9-78be-4fd6-a488-1a63e8200dea.png)

이전에는 신경망의 초기 레이어가 엣지를 검출한 다음 일부 나중 레이어가 객체의 원인을 감지하고 이후의 레이어가 이 경우 사람의 얼굴과 같은 완전한 객체의 원인을 감지하는 방법에 대해 알아보았습니다. 이번에서 이미지 안의 엣지를 어떻게 감지하는지 알아보겠습니다.

예시를 하나 들어봅시다. 컴퓨터가 사진 속의 물체를 알아낼 수 있도록 이와 같은 그림이 주어지면 가장 먼저 할 수 있는 일은 이 이미지에서 수직 엣지를 검출하는 것입니다.

예를 들어 이 이미지는 건물들이 있는 곳에는 수직선들이 있고 보행자들도 어느 정도 수직선으로 보입니다. 그래서 이런 것들은 수직선 엣지 검출로 식별됩니다. 수평선 엣지도 검출할 수 있는데 예를 들면 난간은 강력하게 수평선으로 검출되고 이런 부분도 수평선으로 식별됩니다.

그렇다면, 이런 이미지에서는 엣지를 어떻게 검출할까요? 

---

![image](https://user-images.githubusercontent.com/55765292/183565024-5e33e04f-0f28-4211-b4d6-e458c48cca37.png)

예시를 하나 보겠습니다. 여기 6 x 6 그레이 스케일 이미지가 있는데 그레이 스케일이라서 별도의 RGB 채널에 있기 때문에 6 x 6 x 3의 행렬이 아니라 6 x 6 x 1의 행렬입니다.

이 이미지에서 수직선 엣지를 검출하기 위해서 3 x 3의 행렬을 만들어야 하는데 합성곱 신경망 용어로 폴른은 **필터**라고 불려집니다. 1, 1, 1, 0, 0, 0, -1, -1, -1, 이렇게 생긴 3 x 3 필터 혹은 3 x 3 행렬을 만들어 보겠습니다. 종종 논문에서는 이것을 필터가 아니라 **커널**이라고 부르기도 하는데 여기에서는 **필터**라고 하겠습니다.

6 x 6 이미지를 컨볼브 하면 합성곱 연산은 이런 별표로 표현되고 3 x 3필터로 컨볼브 합니다. 표기에서 아쉬운 점은 수학에서는 별표가 합성곱을 나타내는 표준 기호이지만 파이썬에서는 곱셈이나 산술연산을 나타낸다는 것입니다. 이 별표는 용도가 두 가지이지만 여기에서 별표는 합성곱을 나타내도록 하겠습니다.

이 합성곱 연산의 결과는 4 x 4 이미지로 생각하고 해석할 수 있는 4 x 4 행렬이 됩니다. 이 4 x 4 결과를 계산하는 방법은 다음과 같습니다.

4 x 4 행렬의 좌측 상단인 첫 번째 요소를 계산하려면 3 x 3 필터를 가져와서 원래 입력 이미지의 3 x 3 영역 위에 붙여 넣어야 합니다. 1, 1, 1, 0, 0, 0, -1, -1, -1 이라고 썼습니다. 그 후에 아다마르 곱을 취하면 첫 번째는 3 x 1이 되고 밑으로 내려와서 두 번째는 1 x 1이 되고 1 x 1 더하기 2 x 1 1이고 이것을 다 더하면 9개의 숫자가 나옵니다.

그러면 중간 열은 0 x 0 더하기 5 x 0 더하기 7 x 0 가장 오른쪽 열은 1 x -1 8 x -1 더하기 2 x -1 이 9개의 숫자를 모두 더하면 -5가 되고 -5는 여기에 적겠습니다. 이 9개의 숫자들은 어느 순서로 더해도 상관없습니다. 저는 첫 번째 열, 두 번째 열, 세 번째 열 순서로 한 것뿐입니다.

다음으로 두 번째 요소를 계산하려면 이 네모 칸을 오른쪽으로 한번 옮깁니다. 초록색으로 표시한 부분은 지우도록 하겠습니다. 동일한 방법으로 아다마르 곱을 구하고 더하면 됩니다. 여기에 있는 0 x 1에 더하기 5 x 1 더하기 7 x 1 더하기 1 x 0, 더하기 8 x 0 더하기 2 x 0 더하기 2 x -1, 더하기 9 x -1 더하기 5 x -1 9개의 숫자를 모두 더하면 값은 -4가 되고 계속 이런 방법으로 하면 됩니다.

이것을 오른쪽으로 옮겨서 9번 곱하고 더하면 0 이 되고 여기는 8 이 됩니다. 다시 확인해보면 2 + 9 + 5 = 16이 되죠. 중간열은 0이 되고 가장 오른쪽 열은 (4 + 1 + 3) x -1이고 -8 이 되니 16이고, 왼쪽 열은 -8이니까 여기는 8이 됩니다.

그 다음, 다음 행의 이 요소를 계산하기 위해서는 파란색 정사각형을 한 줄 내려서 여기에 위치하도록 합니다. 동일하게 아다마르 곱을 하고 모든 값을 더해주세요. 그렇게 하면 여기는 -10이 됩니다. 이것을 오른쪽으로 한 칸 옮기면 - 2, 2, 3 등의 값이 나오게 됩니다.

이런식으로 모든 행렬의 값을 채워줍니다. 오른쪽 3 x 3 구역에서는 -16이 나옵니다. 6 x 6 행렬을 3 x 3 행렬로 컨볼브하면 4 x 4 행렬이 나옵니다. 이것은 이미지와 필터입니다.

사실 이것은 다양한 크기의 행렬입니다. 왼쪽에 있는 행렬은 이미지로 해석하기 편리하고 가운데에 있는 것은 필터로 해석하고 오른쪽은 다른 이미지로 해석할 수 있습니다. 이것이 수직선 엣지 검출이 되는데 다음 그림에서 이유를 보여드리겠습니다.

계속 진행하기 전에 한 마디 덧붙이자면 이것을 프로그래밍 언어로 구현하면 실제로 대부분의 외국어는 컨볼루션을 표현할 때 별표가 아닌 다른 함수를 사용합니다.

예를 들어 이전 문제에서 Conv-forward라는 함수를 사용하거나 실행시켰습니다. 이것을 텐서플로로 하면 tf.nn.cont2d 함수가 있습니다. 다음 시간에 살펴볼 CARIS 프로그램 펌웨어의 딥러닝 프로그래밍 프레임워크에서는 컨볼루션을 수행하는 cont2d라는 함수가 있습니다.

하지만 컴퓨터 비전을 잘 지원하는 모든 딥러닝 프레임워크에는 이 합성곱 연산을 구현하기 위해 몇 가지 기능이 있습니다. 왜 수직선 엣지 검출을 시행하는 것일까요? 다른 예시를 살펴보겠습니다

---

![image](https://user-images.githubusercontent.com/55765292/183565043-75602a4a-aa97-4c9a-a180-9ef7eee82f0a.png)

이를 설명하기 위해 단순화된 이미지를 사용하겠습니다. 이미지의 왼쪽 절반은 10이고 오른쪽 절반은 0인 간단한 6 x 6 이미지가 있습니다. 이것을 그림으로 표시하면 이렇게 나타납니다. 왼쪽 절반인 10은 밝은 픽셀에 강한 값이고 오른쪽 절반은 어두운 픽셀에 강한 값으로 표현됩니다. 검정색으로도 표현할 수 있지만 회색을 사용해서 0을 표시하겠습니다.

그러나 이 이미지에 흰색에서 검정색으로 또는 흰색에서 더 어두운 색상으로 전환될 때 이 이미지의 중앙 바로 아래에 매우 강한 수직 엣지가 있음을 볼 수 있습니다. 이것을 3 x 3필터로 컨볼브하면 이 3 x 3필터는 다음과 같이 표현됩니다. 왼쪽에는 밝은 픽셀이 있고 중간 톤의 0이 가운데에 있고 오른쪽에는 더 어두운 픽셀로 표현됩니다. 오른쪽과 같은 행렬을 갖게 됩니다.

이 연산과정을 확인해 보면, 예를 들어, 이 0 은 아다마르 곱을 취하고 이 3 x 3 블록을 곱하여 얻은 것입니다. 따라서 왼쪽 열에서는 10 + 10 + 10이 되고, 중간 열은 0이 되고 -10, -10, -10이라서 여기는 0이 되는 것입니다.

반면 반대로, 10 + 10 + 10 - 0 - 0으로 여기에 30이 나온다면 여기는 30이 되는 것이죠. 이것을 가장 오른쪽 행렬의 이미지에 표시하면 6 x 6 이미지의 중간에 수직 엣지가 검출된 것처럼 중간에는 연한 픽셀의 구역이 생기게 됩니다.

여기에서는 크기가 약간 잘못되어 감지된 엣지가 실제로 두꺼워 보이는데 이것은 작은 이미지를 사용했기 때문입니다 만약 6 x 6 이미지가 아니라 1000 x 1000 이미지를 사용했다면 이미지에서 수직 엣지를 검출할 때 제대로 진행되었다는 것을 알 수 있습니다.

이 예시에서 중간에 있는 이 밝은 영역은 이미지 중간 바로 아래에 강한 수직 엣지가 있는 것처럼 보이는 출력 이미지 방식입니다. 수직 엣지 검출에서 벗어나기 위한 하나의 직관은 수직 엣지가 3 x 3 영역이라는 것인데 왼쪽에는 밝은 픽셀이 있는 3 x 3 필터를 사용하고 있기 때문에 가운데와 오른쪽에는 어두운 픽셀이 있는 것은 별로 신경 쓰지 않아도 됩니다.

이 6 x 6 이미지의 중간은 왼쪽에 밝은 픽셀이 있고 오른쪽에 더 어두운 픽셀이 있을 수 있기 때문에 수직 엣지는 저기라고 생각합니다. 합성곱 연산은 이미지에서 편리하게 수직 엣지를 찾고 구체화시킬 수 있게 합니다.

합성곱 연산자가 어떻게 작동하는지 살펴보았습니다. 다음에는 합성곱 신경망의 기본 구성 요소 중 하나로서 어떻게 사용할 수 있을지 알아보겠습니다.
