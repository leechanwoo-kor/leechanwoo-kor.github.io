---
title: "[Ⅳ. Convolutional Neural Networks] Convolutional Neural Networks (2)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
  - Deep Learning
  - Facial Recognition System
  - Convolutional Neural Network
  - Tensorflow
  - Object Detection and Segmentation
toc: true
toc_sticky: true
toc_label: "Convolutional Neural Networks (2)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/183551502-3482e2d7-efb0-4815-9c94-b662606b4842.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Convolutional Neural Networks

## Foundations of Convolutional Neural Networks

### More Edge Detection

합성곱 연산을 통해 수직 엣지 검출기를 구현하는 방법을 살펴 보았습니다. 이번에는 포지티브 엣지와 네거티브 엣지 사이의 차이 즉 밝은 엣지에서 어두운 엣지 반대 경우의 전환의 차이에 대해 알아보겠습니다. 또한 지금까지 해왔던 것처럼 엣지 검출기를 손으로 코딩하는 대신 다른 유형의 엣지 검출기와 알고리즘을 학습하는 방법도 학습하게 될 것입니다.

---

![image](https://user-images.githubusercontent.com/55765292/183600083-9143e2a8-943f-45b6-96ac-96650bd3b176.png)

이전에 사용했던 예시입니다. 6 x 6의 왼쪽은 밝고 오른쪽은 어두운 이 이미지를 수직 엣지 검출 필터와 컨볼브해서 이미지 가운데에 수직
엣지가 검출되도록 했습니다. 색상이 뒤집힌 이미지에서 왼쪽은 어둡고 오른쪽이 더 밝아지면 어떻게 될까요?

그러면 10 은 이미지의 오른쪽, 0은 왼쪽에 위치하게 됩니다. 이것을 동일한 엣지 검출 필터로 컨볼브하면 중간 부분은 30이 아닌 -30이 도출되며 이미지는 이렇게 됩니다. 전환되는 명암이 반대로 되기 때문에 30도 뒤바뀌게 됩니다. 그리고 - 30은 이것이 밝은 색에서 어두운 색으로 바뀌는 것이 아니라 어두운 색에서 밝은 색으로 바뀌는 것임을 보여줍니다.

그리고 이 두 가지 경우 중 어느 것인지 상관하지 않는다면 이 출력 행렬의 절대값을 취할 수 있습니다. 그러나 이 특정 필터는 밝은 색에서 어두운 색으로 변하는 엣지와 어두운 색에서 밝은 색으로 변화하는 엣지의 차이점을 만들어냅니다. 엣지 검출의 예시를 좀 더 보도록 하겠습니다.

---

![image](https://user-images.githubusercontent.com/55765292/183600543-91b44819-c9d5-4287-9fbd-da9b115d60cd.png)

이전에 봤던 이 3 x 3 필터를 사용하면 수직 엣지를 검출할 수 있습니다. 따라서 이 3 x 3 필터를 사용하여 수평 엣지를 검출할 수 있다는 사실이 놀랍지 않습니다. 참고로 이 필터에 의한 수직 엣지의 픽셀은 왼쪽은 상대적으로 밝고 오른쪽에서 상대적으로 어두운 3 x 3 영역입니다. 마찬가지로 수평 엣지는 픽셀이 위쪽이 상대적으로 밝고 아래쪽 행이 상대적으로 어두운 3 x 3 영역이 됩니다.

예시가 하나 있는데 이 예시는 조금 더 복잡합니다. 좌측 상단과 우측 하단 코너에는 10이 있습니다. 따라서 이것을 이미지로 그리면 0이 있는 곳이 더 어두워지기 때문에 어둡게 칠하고 왼쪽 상단과 오른쪽 하단은 더 밝을 것입니다.

이것을 수평 엣지 검출기와 컨볼브하면 이렇게 됩니다. 몇 가지 예시를 보겠습니다. 이 30은 이 3 x 3영역에 대응하는데요. 상단에는 밝은 픽셀이 있고 하단에는 어두운 픽셀이 있습니다. 바로 여기입니다. 강한 포지티브 엣지를 발견할 수 있습니다. 그리고 -30은 이 영역에 대응하게 되는데  하단은 더 밝고 상단은 더 어둡습니다. 이것이 바로 네거티브 엣지의 예시입니다.

다시 말해서, 우리가 6 x 6같은 상대적으로 작은 이미지로 작업하고 있다는 것을 보여주는 증거입니다. 그러나 예를 들어 -10같은 이 중간 값들은 왼쪽의 포지티브 엣지 부분을 담아내고 오른쪽에 네거티브 엣지를 담아낸다는 사실을 보여주고 그것들을 함께 섞으면 중간 값을 얻게 됩니다.

그러나 예를 들어 체크판 패턴의 1000 x 1000 이미지처럼 매우 큰 경우 10의 전환 영역을 볼 수 없습니다. 중간 값은 이미지의 사이즈에 비해 꽤 작습니다.

요약하자면 다양한 필터를 사용하여 수직 및 수평 엣지를 찾을 수 있습니다.

---

![image](https://user-images.githubusercontent.com/55765292/183600571-748ac159-5e43-49e9-88c5-9a66bee87b71.png)

우리가 사용한 3 x 3 수직 엣지 검출 필터는 하나의 가능한 선택입니다. 역사적으로 컴퓨터 비전 문헌에서최고의 숫자 집합이 무엇인지에 대해 상당한 양의 논쟁이 있었습니다.

따라서 여러분이 사용할 수 있는 또 다른 것은 아마도 1, 2 1, 0, 0, 0, -1, -2, -1 일겁니다. 이것을 **소벨** 필터라고 합니다. 이것의 장점은 중앙 행, 중앙 픽셀에 조금 더 무게를 실어 이것을 조금 더 견고하게 만든다는 것입니다.

하지만 컴퓨터 비전 연구원들은 1, 2, 1 대신 3, 10, 3이 되는 다른 숫자들을 사용할 것 같군요. 그러면 -3, -10, -3이 되겠죠. 이것을 **샤르** 필터라고 합니다.

이것은 약간 다른 특징을 갖고 있습니다. 그리고 오직 수직 엣지 검출만을 위한 것입니다. 이것을 90도 돌리면 수직 엣지 검출을 볼 수 있습니다. 딥 러닝의 등장과 함께 우리가 배운 것 중 하나는 복잡한 이미지에서 엣지를 감지할 때 컴퓨터 비전 연구원이 이 9개의 숫자를 직접 선택하도록 할 필요가 없다는 것입니다.

아마도 여러분은 그것들을 배우고 역 전파를 통해 배울 수 있는 이 행렬의 9개의 숫자를 매개 변수로 다루게 될 것입니다. 목표는 9개의 매개변수를 학습하여 6 x 6 이미지로 만들고 이를 3 x 3 필터로 컨볼브하여 좋은 엣지 검출기를 제공하는 것입니다.

이후에는 이 9개의 숫자를 매개 변수로 취급함으로 역 전파가 1, 1, 1, 0, 0, 0, -1, -1을 학습하거나 혹은 소벨 필터나 샤르 필터를 학습하거나, 손으로 코딩한 필터보다 데이터 통계를 캡처하는 데 훨씬 더 나은 다른 것을 배우게 될 것입니다. 그리고 수직 및 수평 엣지가 아닌 45도, 70도, 73도 또는 선택한 방향에 있는 엣지를 감지하는 방법을 배우게 될 것입니다.

그리고 이 모든 숫자들을 매개 변수가 되게 하고 데이터로부터 자동으로 학습함으로써 컴퓨터 비전 연구원들이 일반적으로 손으로 코딩할 수 있는 것보다 훨씬 더 강력하게 신경망이 실제로 낮은 수준의 특징을 배울 수 있다는 것을 알게 되었습니다.

이 모든 계산에는 여전히 합성곱 연산이 근간에 있으며 이 작업을 통해 역전파는 원하는 3 x 3 필터를 학습한 다음 전체 이미지, 이 위치, 이 위치, 이 위치에 적용할 수 있습니다. 기능을 작동하기 위해 수직 엣지, 수평 엣지, 또는 다른 각도의 엣지 또는 영어로 이름조차 없는 다른 필터인지 감지하려고 합니다.

---

따라서 이 9개의 숫자를 학습할 매개변수로 취급할 수 있다는 아이디어는 컴퓨터 비전에서 가장 강력한 아이디어 중 하나였습니다. 이후에는 실제로 이 9개의 숫자를 학습하기 위해 역 전파를 사용하는 방법에 대해 알아보겠습니다.

하지만 먼저 기본 합성곱 연산에 대한 몇 가지 다른 세부 사항 다른 변형에 대해 알아보겠습니다. 이어서 패딩을 사용하는 방법과 합성곱에 대해 다양한 스트라이드를 사용하는 방법에 대해 논의하고 싶습니다. 이 두 가지가 합성곱 신경망 빌딩블록의 중요한 요소들이 될 것입니다.

---

### Padding

심층 신경망을 구축하기 위해 실제로 사용해야 하는 기본 합성곱 연산에 대한 한 가지 수정 사항은 패딩입니다 어떻게 작동하는지 보겠습니다.

---

![image](https://user-images.githubusercontent.com/55765292/183630969-5b427266-e16c-40f1-8a72-ce5e5902be87.png)

지난 강의에서는 6 x 6 이미지를 3 x 3 필터와 컨볼브했을 때 4 x 4 행렬로 된 4 x 4 결과가 나온다는 것을 보았습니다. 3 x 3 필터로 가능한 위치의 수는 3 x 3 필터가 6 x 6 행렬에 들어갈 수 있는 위치가 4 x 4 밖에 없기 때문입니다.

수학적으로 봤을 때 n x n 이미지를 f x f 필터로 컨볼브하면 출력의 크기는 (n-f+1) x (n-f+1) 이 될 것입니다. 이 예시에서 6 - 3 + 1 = 4 이기 때문에 출력이 4 x 4가 되는 이유입니다.

여기에는 두 가지 단점이 있는데 하나는 합성곱 연산을 적용할 때마다 이미지가 축소된다는 것입니다. 6 x 6에서 4 x 4로 줄어든다면 이미지가 1 x 1의 크기로 굉장히 작아지기 전까지 단 몇 번의 연산만 수행할 수 있습니다.

엣지를 검출하거나 다른 기능을 설정할 때마다 이미지가 축소되는 것을 원치 않을 수 있습니다. 이것이 한 가지 단점입니다.

두 번째 단점은 이것이 3x3 영역에 닿기 때문에 모서리나 가장자리에 있는 픽셀은 이 작은 픽셀이 결과 중 하나에서만 사용되는 것처럼 터치된다는 것입니다.

반면에 중간에 있는 픽셀을 선택하면 해당 픽셀과 겹치는 3 x 3 영역이 많이 있기 때문에 모서리나 엣지의 픽셀이 결과에서 훨씬 적게 사용되는 것과 같습니다. 따라서 이미지 엣지 근처에서 많은 정보가 버려집니다.

축소되는 결과 등 이러한 두 가지 문제점을 해결하기 위해서 여러 층으로 이루어진 심층 인공 신경망을 구축할 때, 100개의 레이어로 된 심층 인공 신경망에서 수행할 때마다 100개의 레이어로 된 심층 신경망의 각 레이어의 크기가 줄어든다면, 100개의 레이어 이후에는 매우 작은 이미지만 남기 때문에 이미지가 줄어드는 것을 원하지 않습니다.

이것이 첫 번째 문제점이고 또 다른 문제는 이미지의 엣지에서 많은 정보를 버려진다는 것입니다.

이 두 가지 문제점을 해결하기 위해서는 합성곱 연산을 최대로 적용해야 합니다. 이미지를 패딩하면 됩니다.

이 경우 가장자리에 1 픽셀의 추가 경계가 있는 이미지를 패드 한다고 가정해 보겠습니다. 이렇게 하면 6 x 6 이미지 대신 8 x 8 이미지로 패딩을 한 것이고 8 x 8 이미지와 3 x 3 이미지를 컨볼브하면 이런 이미지가 나옵니다.

4 x 4 이미지 대신 6 x 6 이미지가 생기게 되었고 원래의 크기인 6 x 6를 유지할 수 있게 되었습니다. 따라서 패딩할 때 p 크기만큼 패딩한다면 이 경우는 p=1입니다. 1 픽셀의 추가적인 경계선으로 모든 테두리를 패딩하기 때문이죠. 출력은 (n+2p-f+1) x (n+2p-f+1) 이므로 (6 + 2 x 1 -3 + 1) x (6 + 2 x 1 -3 + 1)이 되는 것입니다. 따라서 (6+2-3+1)=6이 됩니다.

따라서 원본 사이즈인 6 x 6을 보존한 이미지를 얻게 됩니다. 이 픽셀은 실제로 출력의 모든 셀에 영향을 미치기 때문에 이미지의 모서리나 엣지의 정보를 버리지 않고 적게 세는 것으로 효과적입니다.

단 하나의 픽셀로 깊은 테두리를 패딩하는 효과를 보여드렸습니다. 필요에 따라서 테두리를 두 픽셀로 패딩 할 수 있는데 이 경우 여기에 다른 테두리를 추가하고 원하는 경우 더 많은 픽셀로 패딩 할 수 있습니다.

제가 여기에서 그리는 것은 p + 2와 같은 패딩이 될 것입니다.

---

![image](https://user-images.githubusercontent.com/55765292/183631024-b9b11f93-bb98-4a04-af2e-75ed6aab366e.png)

패딩의 양에 관해서는 **밸리드 합성곱**과 **세임 합성곱**이라는 두 가지 일반적인 옵션이 있습니다.

**밸리드 합성곱*valid convolution***은 기본적으로 패딩이 없는 것을 의미합니다. 이 경우, n x n 이미지를 f x f 필터로 컨볼브해서 (n-f+1) x (n-f+1) 의 출력값을 산출하게 됩니다. 이것은 이전 강의에서 n x n 이미지를 다음과 같이 컨볼브한 예와 같습니다. 3 x 3 필터로 컨볼브해서 4 x 4 출력을 도출했었습니다.

또 다른 일반적인 옵션은 **세임 합성곱*same convolution***인데 패딩을 할 때 출력 크기는 입력 크기와 동일하다는 것을 의미합니다. 실제로 이 공식을 보면 p 픽셀로 패딩을 할 때 n + 2p -f + 1 이 되는 것입니다. 따라서 n x n 이미지와 p 픽셀 테두리의 패딩이 있는 경우 이 출력의 크기는 xn + 2p -f + 1입니다.

따라서 n + 2p -f + 1 = n이 되고 출력 값이 입력 값과 같아지려면 이것을 계산하고 양변에 n 을 지워주고, p에 대해 풀어보면 p = (f - 1) / 2가 됩니다 f가 홀수라면 패딩 크기를 다음과 같이 선택하면 출력 크기가 입력 크기와 동일한지 확인할 수 있습니다.


예를 들어 이전과 같이 필터가 3 x 3인 경우 출력 크기를 입력 크기와 동일하게 만드는 패딩은 (3-1)/2=1입니다. 또 다른 예를 들어보면 필터가 5 x 5, 즉 f = 5이라면 이 공식에 패딩하면 필터가 5 x 5일 때 출력 크기를 입력 크기와 동일하게 유지하기 위해 2의 패딩이 필요하다는 것을 알 수 있습니다.

컴퓨터 비전 분야의 관습에 따르면 f는 주로 홀수입니다 사실 대부분 항상 홀수이고 짝수로 된 필터는 보기도 어렵습니다. 필터는 컴퓨터 비전을 사용해서 작동합니다.

저는 그 이유가 두 가지라고 생각하는데 첫째로 f가 짝수이면 몇 가지 비대칭 패딩을 수행해야 합니다. 따라서 f가 홀수인 경우에만 이러한 유형의 세임 합성곱이 자연스러운 패딩 영역을 제공하고 왼쪽의 패딩이 많고 오른쪽은 패딩이 적은 비대칭인 것이 아니라 동일한 크기를 갖게됩니다.

두 번째로, 3 x 3 또는 5 x 5와 같은 홀수 크기의 필터가 있을 때 중앙 위치를 가지며 때로는 구별자를 갖는 것이 좋고 컴퓨터 비전에서 필터의 위치에 대해 이야기할 수 있도록 중앙 픽셀이 있는것이 좋습니다.

이것 중 어느 것도 f가 홀수인 경우에 대한 좋은 이유는 아니지만 합성곱 문헌에서 3 x 3 필터가 매우 흔하게 사용되는 것을 알게 될 것입니다. 5 x 5 혹은 7 x 7도 사용하긴 하지만 말입니다.

f x f 필터에 대해서도 알아보고 그것이 어떻게 가능한지도 살펴보겠습니다. 관례에 따라 홀수 필터도 사용하는 것을 권장합니다. f에 짝수 값을 사용해도 괜찮은 성능을 얻을 수 있다고 생각하지만 일반적인 컴퓨터 비전 규칙에 충실하면 보통 홀수 f를 사용합니다.

패딩된 합성곱을 어떻게 사용하는지 알아보았습니다. 합성곱 작업을 위한 패딩을 지정하려면 p에 대한 값을 지정하거나 p=0인 밸리드 합성곱을 사용하거나 출력이 입력과 동일한 치수를 갖는지 확인하기 위해 필요한 만큼 패딩을 의미하는 세임 합성곱을 사용할 수 있습니다.

지금까지 패딩에 대해 알아보았습니다. 다음에는 스트라이드 합성곱을 실행하는 법에 대해 알아보겠습니다.
