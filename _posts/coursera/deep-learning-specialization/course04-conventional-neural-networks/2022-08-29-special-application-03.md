---
title: "[Ⅳ. Convolutional Neural Networks] Special Applications (3)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
  - Deep Learning
  - Facial Recognition System
  - Convolutional Neural Network
  - Tensorflow
  - Object Detection and Segmentation
toc: true
toc_sticky: true
toc_label: "Special Applications (3)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/183551502-3482e2d7-efb0-4815-9c94-b662606b4842.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Special Applications

## Neural Style Transfer

### What is Neural Style Transfer?

ConvNet의 최근 가장 재미있고 흥미로운 애플리케이션 중 하나는 **Neural Style Transfer**입니다 직접 구현하여 문제 연습에서 자신만의 예술 작품을 생성할 수 있습니다. Neural Style  Transfer는 무엇일까요? 몇 가지 예제를 보시죠.

![image](https://user-images.githubusercontent.com/55765292/187126887-dec79cbc-3304-447f-8ca3-31aeb1c39d44.png)

여러분이 이 이미지를 찍었다고 가정 해 봅시다. 이것은 실제로 저의 스탠포드 사무실에서 멀지 않은 곳에서 찍은 것인데요. 여러분은 이 사진을 오른쪽에 있는 이미지의 스타일로 재창조시키길 원합니다. 이건 실제 반 고흐의 작품 별이 빛나는 밤 입니다.

Neural Style Transfer를 사용하면 아래 그림과 같은 새로운 이미지를 생성할 수 있습니다. 스탠포드 대학 캠퍼스의 그림은 오른쪽의 이미지 스타일로 그려집니다.

직접 구현할 수 있는 방법을 설명하기 위해 콘텐츠 이미지를 나타내는 데 C를 사용하고 스타일 이미지를 나타내는 S를, 생성 할 이미지를 G로 표시하겠습니다.

여기 다른 예가 있습니다. 이러한 콘텐츠 이미지가 있다고 가정 해 보겠습니다. 이것이 샌프란시스코의 금문교이고 이 스타일의 이미지입니다. 이것은 실제로 파블로 피카소의 이미지입니다.

여러분은 이들을 결합하여 이런 이미지 G를 생성 할 수 있습니다. 이는 오른쪽에 있는 피카소 스타일로 그려진 금문교가 됩니다.

---

Neural Style Transfer를 구현하려면 컨볼네트의 다양한 레이어들, 즉 얕은 그리고 심층 레이어에 있는 컨볼네트에 의해 추출된 함수를 살펴 보아야 합니다.

Neural Style Transfer를 어떻게 구현할 수 있는지 알아보기 전에 하고싶은 것은 컨볼네트의 모든 레이어가 실제로 컴퓨팅 하는지에 대해 더 나은 관점을 얻는 것 입니다.


### What Are Deep ConvNets Learning?

심층 ConvNet 학습이란 무엇입니까? 이번에서 컨볼네트의 더 깊은 레이어가 실제로 하는 일에 대한 직관을 연마하는 데 도움이 되는 몇 가지 시각화를 알려 드리고자 합니다. 그리고 이것은 우리가 어떻게 신경 스타일 변형을 구현할 수 있는지를 생각하는 데 도움이 될 것입니다. 예를 들어 설명해 보죠.

#### Visualizaing What A Deep Network Is Learning?

![image](https://user-images.githubusercontent.com/55765292/187128114-7ed51363-5726-43c1-97e0-e426438f57c5.png)

우선 예제를 봅시다. 여러분이 컨볼네트를 훈련시킨다고 가정 해 봅시다. 그리고 다른 레이어들에 숨어있는 유닛이 연산하고 있는 것을 시각화하려고 합니다. 여러분이 할 수 있는 일은 이겁니다.


#### Visualizing Deep Layers

![image](https://user-images.githubusercontent.com/55765292/187128180-3ca836eb-a484-4113-8bbb-10fb0a3ebe21.png)

여러분이 할 수 있는 일은 이것입니다. 레이어 1에서 히든 유닛부터 시작해 봅시다. 트레이닝 세트를 스캔 하여 이미지가 무엇인지 또는 유닛의 활성화를 최대화하는 이미지 패치가 무엇인지 알아 내려고 한다고 가정 해 보겠습니다.

즉, 신경망을 통해 훈련을 일시 중지하고 특정 유닛의 활성화를 최대화하는 이미지가 무엇인지 파악하십시오.

이제 레이어 1의 히든 유닛은 신경망의 상대적으로 작은 부분 만 보게 될 것입니다. 만약 여러분이 시각화한다면, 즉, 무엇이 이 unit activation을 활성화 시켰는지 표시한다면 작은 이미지 패치를 그릴 수 있습니다. 왜냐하면 그 특정한 유닛이 보는 것은 이 모든 이미지이기 때문입니다.

따라서 한 개의 히든 유닛을 선택하고 해당 유닛의 활성화를 최대화하는 9 개의 입력 이미지를 찾으면 이와 같은 9 개의 이미지 패치를 찾을 수 있습니다. 따라서 이 특정 히든 유닛이 보는 이 이미지의 낮은 영역들에서 모서리나 선같은것을 찾고 있습니다.

이것들은 하나의 히든 유닛의 활성화를 최대로 활성화시키는 9 개의 이미지 패치입니다. 이제 레이어 1에서 다른 히든 유닛을 선택하여 같은 작업을 수행 할 수 있습니다. 이것은 다른 히든 유닛이고 이 두 번째 이미지는 이 9 개의 이미지 패치로 나타납니다.

이 히든 유닛은 마치 이것의 인풋 영역부분에 있는 선을 찾고 있는 것 같아 보이네요. 우리는 이걸 receptive field(수용 영역)라고도 부릅니다. 그리고 다른 히든 유닛에 대해 이렇게 하면 다른 히든 유닛을 발견 할 수 있습니다.

이들은 이런 모습의 이미지 패치로 활성화되는 경향이 있습니다. 이것은 수직 밝은 모서리를 선호하는 것처럼 보이지만 사실 이것의 왼쪽을 초록색으로 만드는 선호도가 있는 것입니다.

이것은 주황색을 선호하는 것이고 흥미로운 이미지 패치인데요. 이쪽에 빨간색 초록색이 섞여서 갈색같은 혹은 갈색빛의 주황색을 만들고 있죠. 하지만 신경은 여전히 이유닛이랑 활성화하는 걸 볼 수 있습니다. 계속해서 이렇게 진행됩니다.

이것은 9 개의 서로 다른 대표 신경입니다. 그리고 9 개의 이미지 패치 각각에 대해, 이들은 최대로 활성화시키는 것입니다. 그래서 이것은 레이어 1의 히든 유닛을 훈련시키는 감각을 주는 것이죠. 그들은 때로는 모서리나 특정 명암 색과 같은 상대적으로 단순한 특징를 찾습니다.

그리고 여기서 사용하고 있는 모든 예제는 Mathew Zeiler와 Rob Fergus의 논문 '컨볼루션망에 대한 이해와 시각화'에서 가져온 것을 사용하고 있습니다.

그리고 신경망에서 히든 유닛이 연산하는 것을 시각화하는 간단한 방법 중 하나를 사용하려고 합니다. 여러분이 논문을 읽어 보시면, 컨볼네트이 실행될 때 시각화하는 좀 더 정교한 방법이 있습니다. 이제는 레이어 1에 있는 9 개의 히든 유닛에 대해 이 과정을 여러 번 반복했습니다. 신경망의 심층 레이어에 있는 히든 유닛의 일부에 대해 이것을 수행하면 어떻게 될까요? 그러면 신경망이 심층 레이어에서 학습하면 히든 유닛은 이미지의 더 큰 영역을 보게 될 것입니다. 그러면 결국엔, 각 픽셀은 가정컨대, 신경망의 이 후속 레이어의 아웃풋에 영향을 줄 수 있을 겁니다. 나중에는 실제로 더 큰 이미지 패치로 보이겠죠. 저는 여전히 이 슬라이드에서 같은 크기로 이미지 패치를 표현하려고 합니다.

그러나 이 절차를 반복하면, 레이어 1에서 이전에 봤던 것과 동일하게 되죠. 이는 레이어 2 에서 9 개의 다른 히든 유닛을 최대한 활성화하는 것을 시각화 한 것 입니다.

따라서 이 시각화가 무엇인지 명확히 알고 싶은데요. 이것은 히든 유닛 하나가 고도로 활성화 되도록 만드는 9 개의 패치를 가리킵니다. 그리고 각각의 그룹핑, 즉, 이것은 하나의 히든 유닛을 활성화시키는 9 가지 이미지 패치의 또 다른 세트입니다.

따라서 이 시각화가 보여주는 것은 레이어 2에 있는 9 개의 히든 유닛이죠. 그리고 이 각각의 히든 유닛에 9개의 이미지 패치가 있습니다. 이들은 히든 유닛이 매우 큰 출력, 매우 큰 활성화를 가질 수 있게 해 줍니다. 그리고 더 심층 레이어에서도 이 작업을 반복 할 수 있습니다.

이제 이러한 작은 이미지 패치를 보는 것이 어렵다는 것을 알고 있으므로 일부 이미지를 확대 해 보겠습니다.

#### Visualizing Deep Layers: Layer 1

![image](https://user-images.githubusercontent.com/55765292/187128267-1e9aa0d6-8cc3-415c-bbae-77fb31d6a17b.png)

레이어 1의 경우 이는 여러분이 봤던 것입니다. 예를 들어 이것은 우리가 보았던 첫 번째 유닛입니다. 매우 활성화되어 있죠. 인풋 이미지 영역 안쪽을 보시면 이런 각도로 생긴 이 선을 볼 수가 있죠.

#### Visualizing Deep Layers: Layer 2

![image](https://user-images.githubusercontent.com/55765292/187128331-80457313-9620-46c6-928b-798d6032c70e.png)

이제 레이어 2의 시각화를 위해 확대 해 보겠습니다. 흥미롭네요 레이어 2는 더 복잡한 모양과 패턴을 감지합니다.

예를 들어, 이 히든 유닛은 수직선이 많은 수직 텍스처를 찾고 있는 거처럼 보입니다. 이 히든 유닛은 이미지의 왼쪽 부분에 둥근 모양이 있을 때 매우 활성화 된 것처럼 보입니다. 이게 바로 매우 얇은 세로선을 찾는 방법이고 이렇게 계속 됩니다.

따라서 두 번째 레이어가 감지하는 특징들이 점점 복잡해지고 있습니다.

#### Visualizing Deep Layers: Layer 3

![image](https://user-images.githubusercontent.com/55765292/187128361-6feb9422-7628-4ba9-97d0-6cd0ff09a8c6.png)

레이어 3은 어떨까요? 더 크게 확대해보면 더 잘 보이실 겁니다. 이것은 레이어 3을 최대로 활성화하는 것입니다. 그러나 더 크게 확대 해 보겠습니다. 다시 흥미로운 것이 나왔네요. 이미지의 왼쪽 하단 부분에 둥근 모양에 크게 반응하는 히든 유닛이있는 것 같습니다. 그래서 많은 자동차와 강아지를 발견하고 놀랍게도 사람들을 감지하기 시작합니다.

이 벌집 모양은 벌집 모양이나 정사각형 모양 같은 불규칙한 질감을 감지하는 것과 같습니다. 이 중 일부에 대해서는 무엇을 감지한 것인지 보고 수동으로 파악하기가 어렵습니다. 하지만 이것은 좀 더 복잡한 패턴을 분명하게 감지하기 시작합니다. 다음 레이어는 어떻습니까?

#### Visualizing Deep Layers: Layer 4

![image](https://user-images.githubusercontent.com/55765292/187128399-057d232c-de78-4a5c-aaeb-2bee0911528d.png)

여기에 레이어 4가 있습니다. 특징들이나 패턴들이 훨씬 더 복잡한 것을 감지하는 걸 볼 수 있습니다. 이것은 거의 개 탐지기를 배운 것처럼 보이지만 이 모든 개들은 비슷하군요. 그렇죠? 이게 개의 무슨 종인지 혹은 개가 번식을 했는지 알 수는 없습니다. 그러나 지금 이 모두 개 들이지만, 개가 비교적 비슷해 보입니다.

이 히든 유닛처럼 보이므로 이건 물을 감지하고 있습니다. 실제로 새의 다리를 감지하는 것처럼 보입니다. 그리고 이렇게 계속 되죠.

#### Visualizing Deep Layers: Layer 5

![image](https://user-images.githubusercontent.com/55765292/187128434-ec6d81e4-947d-465f-887a-e1b08967fbbb.png)

레이어 5는 더욱 정교한 것들을 감지합니다. 따라서 개 탐지기 인 것으로 보이는 뉴런도 있음을 알게 될 것입니다. 그러나 여기에서 탐지하는 개 세트는 더욱 다양해 보입니다.

그리고 이것은 키보드 혹은 키보드 텍스쳐 같은 것들을 감지하고 있는 것 같아 보이는군요 배경에 점들이 많이 있긴 하지만 말이죠.

이 신경은 텍스트를 감지하고 있을지도 모른다고 생각이 드는 군요. 언제나 확신하긴 어렵습니다. 그리고 여기 이것은 꽃을 감지하고 있습니다.

우리는 레이어 1의 선, 레이어 2의 텍스처같은 비교적 간단한 것을 감지하는 것부터 비교적 더 깊은 심층 레이어에 있는 매우 복잡한 객체를 감지하는 것까지 긴 여정을 마쳤습니다.

이것 신경망의 얕은 레이어와과 심층 레이어가 컴퓨팅하는 것에 대해 여러분에게 더 나은 직감을 주기를 바랍니다.

다음으로, 이 직관을 사용하여 신경망 스타일 변형 알고리즘을 작성해 봅시다. clustering 알고리즘입니다.


### Cost Function

**Neural Style Transfer** 시스템을 구축하기 위해 생성된 이미지에 대한 비용 함수를 정의해 봅시다. 나중에 알게 되는 것은 이 비용 함수를 최소화함으로써 원하는 이미지를 생성할 수 있습니다.

#### Neural Style Transfer Cost Function

![image](https://user-images.githubusercontent.com/55765292/187131303-924db9ca-bf90-4305-8369-f635891056ce.png)

문제의 공식화가 무엇인지 기억하세요. 컨텐츠 이미지 C가 주어지고 스타일 이미지 S가 주어지며 새로운 이미지 G를 생성하는 것이 목표입니다.

Neural Style Transfer를 구현하기 위해서는 이 이미지를 생성하기 위해 G의 J를 최소화하기 위해 생성된 특정 이미지에서 기울기를 사용합니다. 하강이 얼마나 좋은지를 측정하는 G의 비용 함수 J를 정의합니다.

이 특정 이미지는 얼마나 좋은가요? 우리는 이 비용 함수에 대해 두 부분을 정의 할 것입니다 이 첫 번째 부분을 콘텐츠 비용이라고 합니다. 이는 콘텐츠 이미지와 생성 된 이미지의 함수이며 콘텐츠 이미지 C의 콘텐츠와 생성 된 이미지의 콘텐츠가 얼마나 비슷한지를 측정합니다.

그런 다음 이를 스타일 비용 함수에 추가 할 것입니다. (S,G)와 이것이 하는 일은 얼마나 비슷한지 측정하는 것입니다. 이미지 G의 스타일에 이미지 S의 스타일에 맞춥니다.

마침내 콘텐츠 비용과 스타일 비용 간의 상대적인 가중치를 지정하기 위해 알파와 베타 두 개의 하이퍼 파라미터로 가중치를 부여합니다. 두 가지 다른 하이퍼 파라미터를 사용하여 가중치의 상대적 비용을 구체화시키는 것은 불필요합니다.

하나의 하이퍼 파라미터는 충분할 것으로 보이지만 Neural Style Transfer 알고리즘의 원래 저자는 두 개의 다른 하이퍼 파라미터를 사용합니다. 저는 단지 그들의 관습을 따를 것입니다.

Neural Style Transfer 제가 보여드릴 것은 Leon Gatys, Alexander Ecker 및 Matthias 입니다. 그들의 논문은 읽기 어렵지 않기 때문에 원한다면 이 몇 개의 영상을 보고 나서 원한다면 그들의 논문을 보는 것을 추천합니다.

#### Find The Generated Image G

![image](https://user-images.githubusercontent.com/55765292/187131355-e8451065-81e8-4cd3-b9f1-b7885854cf94.png)

알고리즘이 실행되는 방식은 다음과 같습니다. G의 비용 함수 J를 찾아야 실제로 새 이미지가 생성됩니다. 다음과 같이 하시면 되겠죠.

생성 된 이미지 G를 임의로 초기화하여 $100 \times 3 \times 3$ 혹은 $500 \times 500 \times 3$ 또는 원하시는 차원으로 만드세요. 그리고 이전 그림에서 G의 비용 함수 J를 정의하겠습니다.

기울기 하강을 사용하여 이를 최소화하는 건데요. 여러분은 G를 G에서 G를 J(G) 값에 대해 미분 함수를 뺀 값으로 업데이트 할 수 있습니다.

이 과정에서 여러분은 실제로 이 이미지 G의 픽셀 값을 업데이트하고 있는데요. 즉, $100 \times 100 \times 3$ RGB 채널의 이미지이죠.

예를 들어, 이 콘텐츠 이미지와 이 스타일 이미지에서 시작한다고 가정 해 보겠습니다. 이것은 또 다른 파블로 피카소 이미지입니다. 임의로 G를 초기화 할 때 초기에 임의로 생성 된 이미지는 각 픽셀 값이 임의로 선택된 이 백색 소음 이미지입니다.

기울기 하강을 실행하면 픽셀 값을 통해 G의 비용 함수 J를 천천히 최소화하여 스타일 이미지의 스타일로 렌더링 된 컨텐츠 이미지처럼 보이는 이미지를 천천히 얻을 수 있습니다.

여기서는 생성 된 이미지 G에 대한 비용 함수를 정의하고 그것을 최소화하는 Neural Style Transfer 알고리즘의 전체 개요를 보았습니다. 다음으로 스타일 비용 함수는 물론 컨텐츠 비용 함수를 정의하는 방법을 알아야 합니다 다음 영상에서 시작해 봅시다


### Content Cost Function

**Neural Style Transfer** 알고리즘의 비용 함수는 콘텐츠 비용 요소와 스타일 비용 요소를 가지고 있습니다. 콘텐츠 비용 구성 요소를 정의하여 시작하겠습니다.

![image](https://user-images.githubusercontent.com/55765292/187132855-6d361768-2475-4a07-9cec-1897928ac2bd.png)

이것은 **Neural Style Transfer** 알고리즘의 전체적인 비용 함수라는 것을 기억하세요 콘텐츠 비용 함수가 무엇인지 알아 봅시다. 은닉 레이어 $l$을 사용하여 콘텐츠 비용을 계산한다고 가정합니다.

$l$이 매우 작은 숫자인 경우 은닉 레이어 $l$을 사용하면 생성된 이미지가 콘텐츠 이미지와 매우 비슷한 픽셀 값을 가지도록 만듭니다.

반면에 심층 레이어를 사용하면 그것은 이렇게 요청 하는데요.

"자, 콘텐츠 이미지에 개가 있는 경우엔 생성 된 이미지의 어딘가에 개가 있는지 확인해야 해"

그래서 실제로 레이어 $l$은 그 사이 어딘가에서 선택됩니다. 너무 얕지도 않고 신경망도 너무 깊지도 않아요. 그리고 여러분이 직접 계획을 세우기 때문에 이번 할 문제 연습에서 문제 연습의 구체적인 예에 대해서 직감을 얻는 것은 당신에게 맡기겠습니다.

하지만 보통 $l$ 은 신경망 레이어의 중간 어딘가에 있도록 선택되어서 너무 얕지도 너무 깊지도 않게 되었습니다.

여러분이 할 수 있는 것은 사전 훈련 된 컨볼네트 어쩌면 VGG 네트워크를 사용하거나 다른 신경망을 사용하는 것입니다.

이제 콘텐츠 이미지와 생성된 이미지가 얼마나 유사한지 측정하려고 합니다. 그리고 나서 이 a의 위 첨자 [l] (c)와 이 2개의 이미지 레이어 $l$의 활성화라고 하면 이미지 C와 G에 표시됩니다. 이 두 가지 활성화가 유사하다면 양쪽의 이미지가 같은 내용을 가지고 있는 것을 의미합니다.

그래서 우리가 할 일은 이제 Jcontent(C,G)를 이 두 활성화가 얼마나 빠른지 또는 얼마나 다른지 정의하겠습니다. 그래서 우리는 레이어 $l$ 에 있는 은닉 유닛 활성화와 콘텐츠 이미지를 전달했을 때와 생성된 이미지를 전달했을 때의 요소별 차이를 구하여 제곱합니다.

앞에 정규화 상수가 있을 수도 있고 없을 수도 있는데 이건 1/2 혹은 다른 게 될 수도 있습니다. 이 하이퍼파라미터 알파에 의해서도 조정 될 수 있기 때문에 별로 문제가 되지 않습니다.

그래서 분명히 할 것은 이 표기법을 사용하는 경우 이 두 가지가 모두 벡터로 전개된 것으로 간주됩니다. 따라서, 이것과 이것을 벡터로 펼치고 나면 이것은 이 두 L2노름의 제곱근이 됩니다.

이 두 활성화 사이에는 실제로 요소별 차이 제곱합이 존재합니다 이것은. 실제로 레이어 $l$에서 활성화, 즉 이미지 C와 G 사이의 차이를 제곱한 요소 간 합 입니다.

그래서 나중에 여러분이 G 값을 찾기 위해 J(G)로 기울기 하강을 수행할 때 전체 비용이 낮아지는데요. 이것은 이미지 G를 찾는 알고리즘을 권장할 것입니다. 그러면 이 은닉 레이어 활성화는 콘텐츠 이미지에서 얻은 것과 비슷해져요.

이것이 신경 스타일 변형을 위한 콘텐츠 비용 함수를 정의하는 방법입니다.
