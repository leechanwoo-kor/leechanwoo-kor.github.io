---
title: "[Ⅳ. Convolutional Neural Networks] Object Detection (6)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
  - Deep Learning
  - Facial Recognition System
  - Convolutional Neural Network
  - Tensorflow
  - Object Detection and Segmentation
toc: true
toc_sticky: true
toc_label: "Object Detection (6)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/183551502-3482e2d7-efb0-4815-9c94-b662606b4842.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Object Detection

## Detection Algorithms

### Semantic Segmentation with U-Net

먼저 개체 인식에 대해 배웠습니다. 개체 인식의 목표는 그림을 입력하고 그림 안에 무엇이 있는지 파악하는 것인데요. 예를들어 이것이 고양이인지 아닌지를 알아내는 것입니다.

또 객체 감지에 대해 배웠습니다. 여기서 목표는 발견된 객체 주위에 경계 상자를 두는 것입니다. 이번에는 **시맨틱 세그멘테이션sementic segmentation**이라는 한 단계 더 정교해진 알고리즘에 대해 알아봅니다.

여기서 목표는 감지된 개체 주위에 면밀한 윤곽선을 그려서 개체에 속하는 픽셀과 그렇지 않은 픽셀을 정확하게 파악하는 것입니다. 이러한 유형의 알고리즘인 시맨틱 세그멘테이션은 오늘날 많은 상업적 응용 프로그램에도 유용합니다.

#### Object Detection vs. Sementic Segmentation

![image](https://user-images.githubusercontent.com/55765292/186330898-cda9184e-8080-4423-9664-b13cd5379961.png)

시맨틱 세그멘테이션은 무엇일까요? 여러분이 자율주행차를 만들고 있는데 이런 입력 영상을 보고 다른 차들의 위치를 감지하려고 한다고 가정해 봅시다.

객체 감지 알고리즘을 사용하는 경우 목표는 다른 차량 주위에 이와 같은 경계 상자를 그리는 것일 수 있습니다. 이것은 자율주행 자동차에 충분히 좋을 건데요. 하지만 학습 알고리즘이 이 이미지의 모든 픽셀이 무엇인지 알아내길 바란다면 그런 다음 이를 출력하는 것이 목적인 시맨틱 세그멘테이션 알고리즘을 사용할 수 있습니다.

예를 들어, 그리 유용하지 않은 도로를 감지하고 도로 주변에 경계 상자를 그리려고 하는 것 보다 시맨틱 세그멘테이션을 통해 알고리즘은 알고리즘은 모든 픽셀에 이 주행 가능한 도로인지 여부에 대한 라벨을 붙이려고 시도합니다.

이 도로는 짙은 녹색으로 표시됩니다. 시맨틱 세그멘테이션의 사용 중 하나는 자율주행 자동차 팀에 의해 사용되는데요. 어느 픽셀들이 주행하기에 안전한지 정확히 파악하기 위해 사용하는 것입니다.

다른 적용 예시를 살펴 보겠습니다

#### Motivation for U-Net

![image](https://user-images.githubusercontent.com/55765292/186330879-6d156981-0e4f-4ced-bde7-826c78792cc7.png)

이것은 Novikov외 연구진과 Dong 외 연구진의 연구 논문에서 나온 두 장의 이미지입니다. 의료 영상에서는 흉부 X-레이를 볼때, 누군가 특정한 증상을 가지고 있는지 진단해보고 싶을 겁니다.

하지만 의사들에게 더 도움이 될 수 있는 것은 이미지에서 정확하게 어떤 픽셀이 환자의 해부학적 특정 부분에 해당하는지를 분할하는 것일 겁니다.

왼쪽에 있는 이미지는 폐, 심장, 그리고 쇄골입니다. 따라서 쇄골은 여러 가지 색을 사용하여 분할됩니다.

이러한 세그멘테이션을 통해 불규칙성을 더 쉽게 발견하고 심각한 질병을 진단할 수 있으며 수술 계획 수립에도 도움이 될 수 있습니다.

이 예에서 뇌 MRI 스캔은 뇌종양 검출에 사용됩니다. 수동으로 종양을 분리하는 건 시간이 많이 걸리고 힘들지만 하지만 학습 알고리즘이 자동으로 종양을 분할할 수 있다면 방사선과 전문의들이 많은 시간을 할애할 수 있고 이는 외과 계획에도 유용한 입력입니다.

이 결과를 생성하기 위해 사용되는 알고리즘은 단위라고 불리는 알고리즘입니다. 이어서 나머지 부분에서 여러분이 배우게 될 겁니다. 시맨틱 세그멘테이션이 무엇을 하지는 알아보도록 하죠.

#### Per-pixel Class Labels

![image](https://user-images.githubusercontent.com/55765292/186330849-b0a5d38a-97d6-482c-aac6-25c1ada26294.png)

단순하게 하기 위해서 어떤 배경에서 자동차를 세그멘테이션하는 예를 들어봅시다.

이 이미지에서 여러분은 자동차를 시맨틱 세그멘테이션 하는 것밖에 신경 쓰지 않는다고 해두죠. 이 경우 두 개의 원인 라벨을 가지도록 결정할 수 있습니다. 자동차는 1로, 자동차가 아닌것은 0으로 하죠.

이 경우에는 단위 알고리즘의 세그멘테이션 알고리즘의 역할은 이 영상의 모든 단일 픽셀에 대해 1 또는 0으로 출력하는 것입니다. 자동차의 일부인 경우 픽셀에 라벨을 붙이고 자동차의 일부가 아닌 경우  0에 라벨을 붙여야 합니다.

---

![image](https://user-images.githubusercontent.com/55765292/186330921-11d75dfa-b74d-420c-821e-0fa89064cef1.png)

또는 이 이미지를 세그멘테이션하고 싶다면 보다 정교하게 보이도록 차량에 라벨을 붙이기로 결정할 수 있습니다. 아마도 여러분은 건물이 어디에 있는지 알고 싶을 것입니다. 이 경우 두 번째 클래스인 건물 2를 사용하고 마지막으로 지면 또는 도로, 클래스 3을 사용합니다.

학습 알고리즘은 모든 픽셀에 다음과 같이 레이블을 붙입니다. 픽셀 단위 라벨을 오른쪽으로 옮기면 우리가 제공할 유닛 테이블을 훈련시키고자 하는 출력입니다. 이것은 많은 출력입니다. 하나의 클래스 라벨 또는 아마도 이 경우 신경망 단위를 지정하는 데 필요한 클래스 라벨과 좌표를 부여하는 대신 라벨의 전체 매트릭스를 생성해야 합니다.

이를 수행하기 위한 올바른 신경망 아키텍처는 무엇일까요? 

#### Deep Learning for Semantic Segmentation

![image](https://user-images.githubusercontent.com/55765292/186330940-977e1c2a-c0bd-4fb5-82b3-7b2c9461b722.png)

이제 익숙한 객체 인식 신경망 아키텍처부터 시작하여 클래스 라벨의 전체 매트릭스인 새로운 네트워크 출력을 만들기 위해 이를 수정하는 방법을 알아보겠습니다.

여기에 익숙한 기초 컨볼루션 신경망 아키텍처가 있는데 여기서 클래스 레이블 $\hat{y}$을 생성하기 위해 여러 레이어를 통해 앞으로 공급되는 이미지를 입력합니다.

이 아키텍처를 시맨틱 세그멘테이션 아키텍처로 바꾸기 위해 몇 레이어를 없애고 시맨틱 세그멘테이션의 주요 단계 중 하나는 일반적으로 이미지의 차원은 왼쪽에서 오른쪽으로 갈수록 작아졌지만 이제는 이미지를 점차 출력에 필요한 전체 크기로 확대하기 위해 더 커져야 합니다.

특히, 이것이 단위 아키텍처의 모습입니다. 단위에 대해 더 깊이 알아 갈 수록 높이와 부피는 다시 높아지고 채널 수는 줄어들기 때문에 장치 아키텍처는 결국 고양이의 세그멘테이션 맵을 얻을 때까지 이렇게 보입니다.

우리가 아직 다루지 않은 연산은 이것은 어떻게 보이나요? 이미지를 더 크게 만들기 위해서 말이죠. 그것이 어떻게 작동하는지 설명하기 위해서 합성곱을 구현하는 방법을 알아야 합니다.

---

그것이 시맨틱 세그멘테이션이며 모든 픽셀을 적절한 클래스 라벨로 개별적으로 라벨링해야 하는 것이 핵심 아이디어인 많은 컴퓨터 비전 애플리케이션에 유용한 알고리즘입니다.

여러분이 보셨듯이 그러기 위한 중요한 단계는 작은 활동 세트를 취해서 그것을 더 큰 활동 세트로 확대하는 것입니다. 그러기 위해서는 전치 컨볼루션이라는 것을 구현해야 합니다. 이는 유닛 아키텍처에서 여러 번 사용되는 중요한 연산입니다.


### Transpose Convolutions

전치 콘볼루션은 유닛 아키텍처의 핵심 부분입니다. 어떻게 $2 \times 2$ 입력을 $4 \times 4$차원 출력으로 확대시킬 수 있을까요?

전치 콘볼루션을 이용하면 그것을 할 수 있습니다. 자세한 내용을 살펴봅시다.

![image](https://user-images.githubusercontent.com/55765292/186332163-26a03edf-d2c0-49a4-b4e3-a7e146e11fa4.png)

여러분은 일반 콜볼루션에 익숙합니다. 새로운 네트워크의 일반적인 레이어는 $6 \times 6 \times 3$ 이미지를 입력할 수 있는데요. 예를들어, $3 \times 3 \times 3$ 필터로 컨벌브 하였고 이 중 다섯 가지가 있다면 $4 \times 4 \times 5$인 출력으로 끝납니다.

전치 컨볼루션은 약간 차이가 납니다. $2 \times 2$를 입력할 수 있습니다. 활성화가 되면 $3 \times 3$ 필터로 변환한 다음, 원래 입력보다 더 큰 $4 \times 4$의 출력을 얻을 수 있습니다. 이것이 어떻게 작동하는지에 대한 좀 더 자세한 예제를 살펴봅시다.

![image](https://user-images.githubusercontent.com/55765292/186332195-5f677aab-24f0-463a-83d0-8dfc1cb57c08.png)

이 예에서 우리는 왼쪽에 표시된 것처럼 $2 \times 2$ 입력 값을 사용하여 $4 \times 4$ 출력 값을 얻습니다. 하지만 $2 \times 2$에서 $4 \times 4$로 넘어가기 위해서 $3 \times 3$인 필터를 사용하려고 합니다. 필터는 $f \times f$ 입니다. 그리고  $3 \times 3$을 선택하겠습니다. 그리고 그것이 우리가 사용할 필터라고 하죠.

또한 패딩 $p = 1$이며 이렇게 적용할건데요. 1p 패딩입니다. 그리고 마침내 마지막인 2에 해당하는 스트라이드 s를 이 예에 사용할 것입니다.

전치 콘볼루션이 어떻게 작동하는지 보죠. 규칙적인 컨볼루션에서 여러분은 필터를 가져와서 입력 위에 놓은 다음 곱하고 합을 구합니다. 전치 콘볼루션에서는 입력에 필터를 배치하는 대신 여러분은 출력에 필터를 배치합니다. 컨볼루션 전치 산출의 단계를 기계적인 단계를 통해 설명하겠습니다.

입력의 왼쪽 위 항목인 2부터 시작합시다. 우리는 이 숫자 2를 가지고 필터에 있는 모든 값에 곱해서 3을 곱해서 이 위치에 붙여보도록 하겠습니다.

이제 패딩 영역에 어떠한 값도 포함되지 않습니다. 우리는 결국 이 패딩 지역을 무시하고 빨간색으로 강조된 부분에 네 가지 값을 집어 넣게 될 것입니다.

그리고 특히 왼쪽 위 항목이 $2 \times 2$이므로 0이 됩니다. 두 번째 항목은 $1 \times 2$, 즉 2가 됩니다. 여기 아래는 $2 \times 2$ 그러면 4가 되고 그리고 마지막은 $1 \times 2$ 이기 때문에 2와 같게 되는거죠.

이제 살펴볼 1 입력 값의 두번째 항목입니다. 저는 이것을 위해 녹색 펜으로 바꿀 것입니다. 다시 한 번 우리는 1을 가지고 필터의 모든 단일 요소에 곱하기를 합니다.

우리가 두 개의 스트라이드를 사용하고 있기 때문에 이제 두 단계씩 를 복사하는 상자로 전환하겠습니다. 다시 말씀드리지만 패딩 안에 있는 부분은 무시하겠습니다. 그리고 숫자를 복사해야 할 부분은 이 녹색 음영 영역뿐입니다.

필터의 빨간색 버전을 복사하는 곳과 녹색 버전을 복사하는 곳이 겹쳐서 빨간색 위에 녹색 값을 복사할 수 없다는 것을 알 수 있습니다. 빨간색과 초록색 상자가 겹치는 경우 두 개의 값을 더합니다.

첫 번째 무게 필터에서 두 개가 나왔는데, 여러분은 이 첫번째 값을 2인 녹색 영역에 더합니다. 여러분은 2 + 2의 결과를 얻게 됩니다. 다음 항목은 $0 \times 1$은 0이며, 그러면 1, 2 + $0 \times 1$이 나오고, 그래서 2 + 0, 2 뒤에 1 그리고 또 다시, 빨간 박스에서 녹색 박스로 두 칸을 옮겼어요. 왜냐하면 두 칸의 스트라이드를 사용했기 때문이죠.

자, 이제 살펴볼 것은 3인 입력의 왼쪽 아래 항목입니다. 우리는 필터를 가지고 모든 요소에 3을 곱하면 한 단계 내려갑니다. 여기서 두 단계 내려가겠습니다. 우리는 이 $3 \times 3$에 우리의 숫자를 채울 것이고 여러분은 여러분이 복사한 숫자가 $2 \times 3$이라는 것을 알게 될 것입니다. 그것은 6이고, $1 \times 3$, 그것은 3이 되며, $0 \times 3$은 0이 되며, 그렇게 하면, 3, 6, 3입니다.

그리고 마침내 2인 마지막 입력 요소로 이동합시다. 필터의 모든 요소에 2를 곱하고 그것을 이 블록에 더하면 여러분은 결국 + 2인 $1 \times 2$를 더하게 되죠. 그리고 나머지 요소들에 대해서도 그렇습니다.

마지막 단계는 16개의 값에 있는 $4 \times 4$매트릭스의 수를 가지고 모두 더하면 됩니다. 여기에 0으로 끝났고, 2 + 2는 4이며, 0, 1, 4 + 6은 10이며, 2 + 0 + 3 +2는 7이 되고, 2 + 4는 6 입니다. 이게 약간은 지저분해  보인다는 것을 알고 있습니다. 왜냐하면 제가 위에 글을 쓰고 있으니깐요.

0도 있고 3 + 4는 7이며 0, 2, 6, 3 + 0는 3이었고 4, 2, 따라서 그것이 여러분의 $4 \times 4$ 출력이 됩니다. 혹시나 여러분이 왜 우리가 이런 식으로 하는지 궁금하시다면 작은 입력을 더 큰 출력으로 바꿀 수 있는 방법은 여러 가지가 있을 겁니다.

하지만 전치 컨볼루션은 유용하며 그리고 여러분이 필터의 모든 파라미터를 학습 할 때, 이것을 학습 알고리즘이 향후 사용할 단위의 맥락에 넣으면 좋은 결과를 얻을 수 있는 것이 판명됩니다. 돌아가서 유닛을 다시 짓죠.

우리는 어떻게 전치 컨볼루션에 의해서 작은 입력을 취해 예를들면 $2 \times 2$로 받아 $4 \times 4$로 확대하는 방법에 대해 차례차례 설명합니다. 이제 여러분은 전치 컨볼루션을 이해하게 됬습니다. 이제 이 빌딩 블록을 사용하여 시맨틱 세그멘테이션에 사용할 수 있는 전체 단위 아키텍처에 어떻게 적합한지 살펴보겠습니다.
