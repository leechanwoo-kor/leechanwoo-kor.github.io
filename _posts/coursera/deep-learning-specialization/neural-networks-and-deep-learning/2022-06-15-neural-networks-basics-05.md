---
title: "[Ⅰ. Neural Networks and Deep Learning] Neural Networks Basics (5)"
categories:
  - Deep Learning Specialization
tags:
  - Coursera
  - Deep Learning Specialization
toc: true
toc_sticky: true
toc_label: "Neural Networks Basics (5)"
toc_icon: "sticky-note"
---

![image](https://user-images.githubusercontent.com/55765292/172768350-41a6b2f0-9468-4b13-bc94-4a38f89ce5e6.png){: width="50%" height="50%"}{: .align-center}

<br><br>

# Neural Networks Basics

## Logistic Regression as a Neural Network

### Derivatives with a Computation Graph
이전에 계산 그래프를 사용하여 함수 J를 계산하는 예를 살펴보았습니다. 이제 해당 계산 그래프의 정리된 버전을 사용하여 도함수 계산을 하는 방법을 살펴보겠습니다.

![image](https://user-images.githubusercontent.com/55765292/173765167-963d32e0-ba59-44f4-9e3c-a6a4efbcf3c2.png)
계산 그래프를 보겠습니다. $v$에 대한 $J$의 도함수를 계산하려고 한다고 가정해보겠습니다. 값이 어떻게 나올까요? 여기 $v$의 값을 갖고 살짝 변경한다고 하면 $J$의 값은 어떻게 변할까요?

$J$는 $J=3v$로 정의됩니다. 그리고 $v=11$입니다. 따라서 $v$를 $11.001$로 조금 올리면 $J$는 $3v$이므로 $33$에서 $33.003$으로 올라갑니다. 여기서 $v$는 $0.001$만큼 늘어났습니다. 그리고 그 결과 $J$가 3배 증가합니다. 따라서 $v$에 대한 $J$의 도함수는 $3$입니다. 왜냐하면 $J$의 증가는 $v$의 3배이기 때문입니다.

그리고 사실 이것은 $f(a) = 3a$인 이전 예제와 매우 유사합니다. 그런 다음 약간 단순화된 약간 엉성한 표기법으로 $\frac{df(a)}{da}$를 도출했는데 $\frac{df}{da} = 3$으로 쓸 수 있습니다. 

그러므로 이렇게 $J = 3v$로 나타나는데요. 이경우, $\frac{dJ}{dv} = 3$이 됩니다. 여기서 $J$는 $f$의 역할을 하고 $v$는 $a$의 역할을 합니다.

그러므로 역방향 전파의 용어는 최종 출력 변수의 도함수를 계산하려는 경우 일반적으로 $v$에 대해 가장 신경 쓰는 변수이기도 합니다만 역방향 전파의 첫 번째 단계를 완료했습니다. 이 그래프에서는 이것을 한 단계 후퇴라고 부릅니다.

다른 예제를 하나 더 보겠습니다. $\frac{dJ}{da}$는 무엇일까요? 다시 말해, $a$의 값을 올리면 이것이 $J$의 값에 어떤 영향을 미칠까요?

이제 $a = 5$인 예제를 살펴보겠습니다. $5.001$로 올려보겠습니다. 순 영향력은 $v$ 즉, $a + u$이므로 이전에는 $11$ 이었습니다. 이것은 $11.001$로 증가할 것입니다. 그리고 $J$가 이제 $33.003$까지 올라간 것을 이미 위에서 보았습니다. $a$가 $0.001$ 증가하면 $J$는 $0.003$ 증가한다는 것을 말입니다.

그리고 증가한다는 것은 이 값을 $5$를 가져와서 새 값을 연결해야 한다는 것입니다. 그런 다음 $a$의 변화는 계산 그래프의 오른쪽으로 전파되어 $J$의 값이 $33.003$이 됩니다. 그래서 $J$의 증가량은 $a$의 증가량의 3배입니다. 그러면 여기 도함수는 $3$이라는 것입니다. 이것을 분해하는 한 가지 방법은 $a$가 변하면 $v$도 변할 것이라고 말하는 것입니다. 그리고 $v$를 변경하면 $J$가 변경됩니다. 따라서 값을 올리면 $J$ 값이 순변화 됩니다.

$a$의 값을 아주 조금 올렸을 때 첫째, $a$를 변경함으로써 결국 $v$를 증가시킵니다. 그러면 $v$는 얼마나 증가할까요? $ \frac{dv}{da}$에 의해 결정되는 양 만큼 증가할 것입니다. 그리고 $v$의 변화량이 $J$를 증가시킬 것입니다. 그래서 미적분학에서는 이것을 연쇄법칙이라고 합니다.

$\frac{dJ}{da} = 3 = \frac{dJ}{dv}\frac{dv}{da}$
{: .text-center}

$a$가 $v$에 영향을 주면 $J$에 영향을 주고 $a$의 값을 약간 변경하면서 $J$가 변하는 양은 $a$를 변화시킬때 변하는 $v$의 양 곱하기 $v$값이 변할때 변하는 $J$의 양입니다. 다시 말씀드리면, 미적분에서는 이것을 연쇄법칙이라 합니다.

이번 계산을 통해 배운 것은 값을 $0.001$로 증가시키면 $v$도 똑같은 양 만큼 변한다는 것입니다.
그러므로 $\frac{dv}{da} = 1$이 됩니다. 따라서 $\frac{dJ}{dv}\frac{dv}{da}$는 $3$ x $1$은 실제로 $\frac{dJ}{da} = 3$이라는 정확한 값을 제공합니다.

따라서 이 작은 그림은 $\frac{dJ}{dv}$ 즉 이변수에 대한 도함수를 계산하여 $\frac{dJ}{da}$를 계산하는 데 도움이 되는 방법을 보여줍니다. 그리고 그것은 이 역계산의 또 다른 단계입니다.

---

새로운 표기법 협약을 하나 더 소개하고 싶습니다. 즉, 역방향 전파를 구현하기 위해 코드를 작성할 때 일반적으로 최종 출력 변수가 존재하게 됩니다. 따라서 최종 출력 변수가 존재하게 됩니다. 따라서 최종 출력 변수는 정말 신경쓰거나 최적화할 수 있습니다. 이런 경우 최종 출력 변수는 $J$입니다. 계산 그래프에서 마지막 노드에 해당하는 부분입니다.

따라서 많은 연산이 최종 출력 변수의 도함수를 계산하기 위해 시도될 것입니다. 따라서 이 최종 출력 변수의 $d$는 다른 변수에 대한 것입니다. 그런 다음 그것을 $dvar$라고 부릅니다. 따라서 대부분의 계산은 $a,b,c$ 또는 $u,v$와 같은 다양한 중간 변수를 사용하여 최종 출력 변수 $J$의 도함수를 계산합니다.

이것을 소프트웨어로 구현할 때 이런 변수를 뭐라고 부를까요? 한 가지 할 수 있는 방법은 파이썬에서 dFinalOutputVar/dvar와 같은 매우 긴 변수 이름을 부여하는 겁니다. 하지만 이것은 너무 긴 변수 이름입니다. 이걸 dJdvar라고 부르셔도 될 것 같습니다. 하지만 항상 최종 출력 변수와 관련하여 dJ에 대한 미분을 취하기 때문에 새로운 표기법을 도입하겠습니다.

여기서 코딩에서는 작성한 코드로 이것을 계산할 때 변수 이름 dvar를 사용하여 그 양을 나타냅니다. 따라서 작성하는 코드의 dvar는 $J$와 같이 관심 있는 최종 출력 변수의 도함수를 나타냅니다. 가끔씩은 코딩에서 여러 중간 수량에 대한 마지막 $l$을 나타낼 것입니다.

따라서 여기 코드에서 $dv$를 사용하여 이 값을 나타냅니다. 그래서 $dv$는 $3$과 같을 것입니다. 그리고 여러분의 코드는 이것을 $da$로 표현하는데 이것은 우리도 $3$과 같다는 것을 알아냈습니다. 우리는 이 계산 그래프를 통해 부분적으로 역방향 전파를 실시했습니다.

다음으로 이 예제의 나머지 부분을 살펴보겠습니다.

![image](https://user-images.githubusercontent.com/55765292/173765274-79aca759-5949-4ee8-90b1-454d44f00d2b.png)

