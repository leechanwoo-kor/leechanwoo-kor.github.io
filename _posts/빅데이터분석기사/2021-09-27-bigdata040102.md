---
title: "[빅데이터분석기사 필기] Ⅳ.빅데이터 결과 해석 - 01. 분석 모형 평가 및 개선 (2)"
categories:
    - 빅데이터분석기사
tags:
    - 빅데이터분석기사
toc: true
toc_sticky: true
toc_label: "01. 분석 모형 평가 및 개선 (2)"
toc_icon: "sticky-note"
---

**키워드🔑**<br>
교차검증, 홀드 아웃 교차 검증, 랜덤 서브샘플링, K-Fold Cross Validation, LOOCV, LpOCV, RLT, 부트스트랩
{: .notice--warning}

# 01. 분석 모형 평가 및 개선

## 1. 분석 모형 평가

### 3) 교차 검증

<br>
(1) 교차 검증(Cross Validation)<br>
📌 홀드 아웃 교차 검증 / 랜덤 서브샘플링 / K-Fold Cross Validation / LOOCV / 부트스트랩

- 교차 검증(Cross Validation)
	- 모델의 일반화 오차에 대해 신뢰할만한 추정치를 구하기 위하여 훈련&평가 데이터를 기반한 검증 기법
	
|홀드 아웃<br>교차 검증|랜덤<br>서브 샘플링|K-Fold|LOOCV|LpOCV|RLT|부트스트랩|
| :-----: | :-----: | :-----: | :-----: | :-----: | :-----: | :-----: |
|Holdout Cross<br>Validation|Random<br>Sub-Sampling|K-Fold<br>Cross<br>Validation|Leave-One-<br>Out<br>Cross Valid|Leave-p-Out<br>Cross Valid.|Repeated<br>Learning-<br>Testing|Bootstrap|
|비복원추출<br>랜덤으로 나눔<br>-데이터손실O<br>-계산/비용적음|무작위랜덤추출<br>홀드아웃반복<br>비용 가장적음|무작위추출<br>동등분할<br>부분집합 K개<br>평가집합 1개|전체데이터N개<br>평가데이터1개<br>작은데이터적합<br>비용 가장비쌈|전체데이터N개<br>평가데이터p개<br>계산시간부담↑<br>nCp번 반복|비복원추출<br>랜덤추출<br>평균오류율계산|단순랜덤<br>복원추출(중목O)<br>동일크기표본율<br>여러개생성함|

![image](https://user-images.githubusercontent.com/55765292/135552030-25afbc53-c2f2-4ce6-b62b-eeddacf1f205.png){: .align-center}

검증방법비교
{: .text-center}

---

<br>
(2) 홀드 아웃 교차 검증(Holdout Cross Validation)<br>
📌 비복원추출로 랜덤하게 학습/평가 데이터를 나누어 검증

- 데이터를 나누는 방법에 따라 결과가 많이 달라짐(5:5, 3:7, 2:1)
	- 학습 데이터(Training set): 분류기 만들 때 사용
	- 검증 데이터(Validation set): 분류기들의 매개변수 최적화를 위해 사용
	- 평가 데이터(Test set): 최적화된 분류기 성능 평가를 위해 사용
- 데이터 손실 O: 평가 데이터는 학습에 사용할 수 없음
- 계산량 ↓ 평가 쉬움 ↑

<br>
(3) 랜덤 서브샘플링(Random Sub-Sampling)<br>
📌 모집단에서 표본을 무작위 추출

- 홀드아웃 반복 → 데이터 손실 X
- 측정/평가 비용 가장 적음
- 각 샘플들을 학습/평가에 얼마나 사용할지 횟수 제한 X → 특정 데이터만 학습할 수 있음

<br>
(4) K-Fold Cross Validation<br>
📌 무작위, 동일크기, K개 부분집합으로 나눔 → 실험결과 K개를 종합

- 데이터 분할
	- 전체 집합 = K개
	- 학습 집합 = K-1개
	- 평가 집합 = 1개
- 모든 데이터를 학습/평가에 사용 가능
- K값에 따라 달라짐
	- K값 증가할수록, 계산량도 증가함
	- K=10이면, 데이터 10% 낭비됨
- LOOCV 보다 측정/평가 비용 적음
- 절차: 동등분할 → 학습/평가데이터 구성 → 분류기 학습 → 분류기 성능확인
	- 학습/평가데이터 구성: (K-1)개 부분집합은 학습, 1개 부분집합은 평가에 쓰는 K개의 실험데이터 구성
	- 분류기 성능확인: 실험 결과 K개를 종합하여 분류기의 최종 성능을 확인

---

<br>
(5) LOOCV(Leave-One-Out Cross Validation)<br>
📌 전체 데이터 N개 중 샘플 1개만 평가 / (N-1)개는 학습 → N번 반복

- 데이터 분할
	- 전체 데이터 = N 개
	- 학습 데이터 = N-1 개
	- 평가 데이터 = 1 개
- 데이터 손실 X
- 계산량 많음 → 측정/평가 비용 가장 비쌈
- 작은 크기 데이터에 좋음
- 방법은 K-Fold랑 같음 → K-Fold는 부분집합 개수 K / LOOCV는 데이터 개수 N

<br>
(6) LpOCV(Leave-p-Out Cross Validation)<br>
📌 전체 데이터 N개 중 샘플 p개만 평가 / (N-p)개는 학습 → nCp번 반복

- 데이터 분할
	- 전체 데이터 = N 개
	- 학습 데이터 = N-p 개
	- 평가 데이터 = p 개
- 계산량/시간 부담 크다

<br>
(7) RLT(Repeated Learning-Testing)<br>
📌 랜덤 비복원추출

- 절차: 데이터 분리 → 훈련 → 에러 계산 → 반복 → 평균오류율 계산
	- 데이터 분리: 랜덤하게 학습/검증 데이터분리
	- 데이터 훈련: 학습 데이터로만 훈련
	- 에러 계싼: 검증 데이터로 Error 계산
	- 반복: 데이터 훈련과 에러 계산을 2회 더 반복
	- 평균 오류율 E = ∑E / N

<br>
(8) 부트스트랩(Bootstrap)<br>
📌 단순랜덤 복원추출 → 동일크기 표본 여러개 샘플링

- 랜덤 복원추출 → 중복 허용 → 특정 샘플이 학습 데이터에 포함될 확률 = 약 63.2%
- 학습 데이터에 한번도 포함되지 않는 데이터 발생 → 평가에 사용함 = 약 36.8%

---
