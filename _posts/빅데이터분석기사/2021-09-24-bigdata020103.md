---
title: "[빅데이터분석기사 필기] Ⅱ.빅데이터 탐색 - 01. 데이터 전처리 (3)"
categories:
    - 빅데이터분석기사
tags:
    - 빅데이터분석기사
toc: true
toc_sticky: true
toc_label: "01. 데이터 전처리 (3)"
toc_icon: "sticky-note"
---

**키워드🔑**<br>
변수, 종속변수, 독립변수, 변수선택, 필터기법, 정보 소득, 카이제곱 검정, 피셔 스코어, 상관계수, 
<br>래퍼기법, 전진선택법, 후진제거법, 단계적방법, RFE, SFS, 유전 알고리즘, 단변량 선택, mRMR, 
<br>임베디드기법, 라쏘, 릿지, 엘라스틱넷, SelectFromModel
{: .notice--warning}

# 01. 데이터 전처리

## 2. 분석 변수 처리

### 1) 변수 선택

<br>
(1) 변수 개념<br>
- 변수(Feature): 데이터 모델에서 예측에 사용되는 입력변수
- RDBMS에서 속성/열 = 머신러닝에서 변수
- 변수 유형: 알려진 값 & 예측값
    - 알려진 값: 변수, 속성, 예측변수, 차원, 관측치, 독립변수
    - 예측 값: 라벨, 클래스, 목푯값, 반응, 종속변수

<br>
(2) 변수 유형<br>
📌 인과관계에 따라 - 독립변수, 종속변수 / 속성에 따라 - 범주형(명목형, 순서형), 수치형(이산형, 연속형)
- 인과관계 ⇒ 독립변수 & 종속변수
    - 독립변수: 종속변수에 영향을 주는 변수
        - 종속변수가 특정한 값을 가지게 되는 원인이 된다고 가정함
        - 연구자가 의도적으로 변화시키는 변수
        - 독립변수 = 예측변수, 회귀자, 통제변수, 조작변수, 노출변수, 리스크 팩터, 설명변수, 입력변수
    - 종속변수: 독립변수로부터 영향을 받는 변수
        - 독립변수의 영향을 받아 그 값이 변할 것이라고 가정함
        - 어떻게 변화하는지 연구하는 변수
- 변수속성: 명목형 / 순서형 / 이산형 / 연속형
    - 명목형: 이름만 의미 부여, 크가와 순서는 상관 없음, 명사형
    - 순서형: 순서에 의미 부여 가능
    - 이산형: 하나하나 셀 수 있음
    - 연속형: 구간 안의 모든 값을 가질 수 있음
- 변수 간 관계
    - 독립변수, 종속변수 둘 다 연속형, 범주형 자료로 분석 가능
    - 연속형 자료에서 원인은 공변량(Covariate)
    - 범주형 자료에서 원인은 요인(Factor) 이라고 부름

---

<br>
(3) 변수선택(Feature Selection)<br>
📌 독립변수(x)들 중 종속변수(y)에 가장 관련성이 높은 변수만 선정하는 방법
- 변수 선택 특징
    - 해석하기 쉽도록 모델 단순화
    - 훈련 시간 축소
    - 차원의 저주 방지(차원이 증가할수록, 필요한 샘플 데이터가 기하급수적으로 증가하는 현상)
    - 과적합 줄이고 일반화
    - 모델 정확도, 성능 향상 기대
- 변수 선택 방식 분류
    - 비지도 방식: 분류를 참고하지 않고 변수들만으로 선택 수행
    - 지도 방식: 분류를 참고하여 변수 선택

<!-- < 변수 선택 기법: 필터/래퍼/임베디드 기법 >
|필터 기법|래퍼 기법|임베디드 기법|
| :-----: | :-----: | :-----: |
|정보 소득<br>카이제곱 검정<br>피셔 스코어<br>상관계수|RFE<br>SFS<br>유전 알고리즘<br>단변량 선택<br>mRMR|라쏘 (LASSO)<br>릿지 (Lidge)<br>엘라스틱넷 (Elastic Net)<br>SelectFromModel| -->

- 필터 기법(Filter Method): 데이터의 통계적 특성으로부터 변수를 선택<br>
📌 데이터의 통계적 특성으로부터 변수를 선택
    - 절차: 변수 전체집합 → 베스트 하위집합 선택 → 알고리즘 학습 → 성능 평가
    - 특징
        - 통계적 측정 방법으로 변수들의 상관관계를 알아냄
        - 계산 속도 빠름 → 래퍼 기버 사용전, 전처리에 사용함
    - 사례: 정보 소득 / 카이제곱 검정 / 피셔 스코어 / 상관계수
        - 정보 소득(Information Gain): 가장 정보 소득이 높은 속성 선택
        - 카이제곱 검정(Chi-Square Test): 관찰 빈도와 기대 빈도의 차이가 유의한가 검정
        - 피셔 스코어(Fisher Score): 최대 가능성 방정식을 풀기 위한 뉴턴의 방법
        - 상관계수(Correlation Coefficient): 두 변수간 상관관계 정도를 나타낸 계수
- 래퍼 기법(Wrapper Method)<br>
📌 변수의 일부만으로 모델링 반복
    - 절차: 변수 전체집합 → (하위 집합 → 알고리즘 학습)을 반복 → 성능 평가
    - 특징
        - 예측 정확도 성능이 가장 좋은 하위 집합을 선택하는 기법
        - 그리디 알고리즘(Greedy Algorithm): 하위 집합을 반복 선택
        - 일반적으로 필터 기법보다 예측 정확도 높음
        - 시간 오래 걸림, 과적합 위험 있음
    - 알고리즘 유형: 전진선택법 / 후진제거법 / 단계적방법(전진+후진)
        - 전진선택법: 빈모델 → 변수 하나씩 추가 (모델을 가장 많이 향상 시키는 변수)
        - 후진제거법: 풀모델 → 변수 하나씩 제거 (모델에 가장 적은 영향을 주는 변수)
    - 기법 상세: RFE / SFS / 유전 알고리즘 / 단변량 선택 / mRMR
        - RFE(Recursive Feature Elimination): SVM 사용 → 재귀적으로 제거
        - SFS(Sequential Feature Selection): 그리디 알고리즘 → 빈 모델에 하나씩 추가
        - 유전 알고리즘(Genetic Algorithm): 자연세계 진화과정에 기초한 전역 최적화 기법(존 홀랜드, 1975)
        - 단변량 선택(Univariate Selection): 각 변수를 개별 검사 → 변수와 반응변수간 관계 강도 결정
        - mRMR(Minimum Redundancy Maximum Relevance): 특성변수의 중복성 최소화하는 기법

**💡**<br>
**노드(Node)란, 컴퓨터 과학에 쓰이는 기초적인 단위이며,**<br>
**대형 네트워크에선 장치나 데이터 지점(포인트)를 의미한다.**<br>
**예를 들면 개인용 컴퓨터, 휴대전화, 프린터, 서버 같은 장치들을 말한다.**<br>
{: .notice--primary}

- 임베디드 기법(Embedded Method): 모델 자체에 변수 선택이 포함된 기법
    - 절차: 변수 전체집합 → (하위 집합 → 학습 + 평가)를 반복
    - 특징
        - 모델 정확도에 기여하는 변수를 학습
        - 제약조건: 더 적은 계수를 가지는 회귀식을 찾는 방향으로 제어
    - 사례: 라쏘 / 릿지 / 엘라스틱넷 / SelectFromModel
        - 라쏘 (LASSO): 가중치 절댓값 합을 최소화 → L1-norm
        - 릿지 (Lidge): 가중치 제곱 합을 최소화 → L2-norm
        - 엘라스틱넷(Elastic Net): 가중치 절댓값 합, 젭곱 합을 동시에 제약 → 라쏘와 릿지를 선형결합
        - SelectFromModel: 의사결정나무 기반 알고리즘으로 변수 선택

**💡**<br>
**Norm 이란, 벡터의 크기(길이)를 측정하는 방법을 말한다**<br>
**L1-norm은 벡터 p, q 각 원소간 차이의 절댓값의 합이고, L2-norm은 유클리디안 거리(직선 거리)이다**<br>
{: .notice--primary}

---