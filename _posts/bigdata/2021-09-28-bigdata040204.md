---
title: "[빅데이터분석기사 필기] Ⅳ.빅데이터 결과 해석 - 02. 분석 결과 해석 및 활용 (4)"
categories:
    - 빅데이터분석기사
tags:
    - 빅데이터분석기사
toc: true
toc_sticky: true
toc_label: "02. 분석 결과 해석 및 활용 (4)"
toc_icon: "sticky-note"
---

**키워드🔑**<br>
성능모니터링, 모니터링, 솔루션, 샤이니(R), 분석주기, 성능이벤트, 임계치, 리모델링
{: .notice--warning}

# 02. 분석 결과 해석 및 활용

## 3. 분석결과 활용

### 3) 분석 모형 모니터링

<br>
(1) 분석 모형 모니터링<br>
📌 실시간/배치(일괄) 스케줄러 실행 → 주기별로 자동 모니터링 → 이상 시에만 확인

- 분석 모형의 성과가 예상했던 수준으로 나오고 있는지 모니터링
- 모니터링 솔루션
	- 자체상태/정상 작동상태 유뮤/데이터 처리 및 분석 소요시간/모델에 따른 처리성능 관점에서 모니터링 수행
- R Shiny(샤이니)
	- 모델링 결과를 간단히 배포 가능
	- 구성: 사용자 작업 파일(ui.R)/서버파일(server.R)
	- 해당 URL에 접속하면, R로 개발한 분석 모델 실행 가능

<br>
(2) 분석 모형 성능 모니터링<br>
📌 성능 모니터링: 측정 항목 정의 → 모니터링 실시 → 측정 항목별 임계치/이벤트 등급별 알람 → 성능 관리

- 분석 주기별 모니터링 기준: 일간/주간/월간/분기/연간
	- 월간/분기: 성능 추이 집계 분석, 현황 보고 등
	- 연간: 연간 업무 계획, 연간 리포트 등
- 측정 항목별로 영향을 미치는 요소 ⇒ 응답시간/사용률/가용성/정확성
	- 응답시간
		- 서비스 요청 시점 ~ 사용자 응답 시점
		- 영향 요소
			- 정보시스템 처리 성능
			- 네트워크구간 처리용량
			- 정보시스템 자원 용량
	- 사용률
		- 일정 시간 동안 자원을 정상적으로 사용한 비율
		- 영향요소
			- 네트워크 자원을 일정시간 사용하는 정도
	- 가용성
		- 서비스 장애 없이 정상적으로 지속하여 제공할 수 있는 능력
		- 영향요소
			- 하드웨어 장애
			- 소프트웨어 버그
			- 운영자/전기적 문제
			- 작업/서비스 가용성
	- 정확성
		- 처리 결과 정확성에 영향을 주는 요인
		- 영향요소
			- 잘못된 환경 설정
			- 하드웨어 장애
			- 데이터 이상값
- 주요 성능 측정 항목
	- 응용 프로그램 성능 측정 항목: 응답시간/트랜잭션 처리량/메모리 사용/데이터베이스 처리/오류 및 예외/배치 실행 환경
	- 응용 플랫폼 성능 측정 항목: 응답시간/트랜잭션 처리량/대기 큐/대기 시간/프로세스(스레드) 상태 및 개수/ 세션 상태 및 개수/통신 큐&채널 상태/자원풀/오류 및 예외/부하 분산
	- 응용 솔루션 성능 측정 항목: 구간별 수행시간/대기 큐/메모리&버퍼/오류 및 예외
	
---

- 성능 모니터링 이벤트 유형
	- 성능 이벤트: 설정한 임계치가 초과되는 것
	- 임계치(Threshold): 성능 모니터링을 위해 정의해놓은 측정 항목마다 임계치를 설정함
		- 성능 모니터링 시, 장애 상황 및 성능 상태의 경계선
		- 임계치에 따른 등급 설정 → 정상 상태를 기준치로 설정
		- 비정상적인 상황을 판단하는 경계
	- 임계치 설정 및 관리: 각 구성요소의 특성에 따라 별도로 임계치 설정
		- 임계치 설정: 제공하는 서비스 형태&시스템 특성 고려 → 사용자 응답시간&처리속도&만족도 등을 반영
		- 임계치 관리: 단일기준X → 다양한 요소를 반영하여 조정 → 운영하면서 주변 요소의 영향을 받아 조정
	- 주요 성능 저하 요인: 서버 자원 부족/성능 조정 부족/I/O 조각화 현상/데이터 이동/프로그래밍 오류/데이터베이스 설계 오류/악성코드/버그/하드웨어 다운/외부적 요인 등
	
<br>
(4) 분석 모형 모니터링 고려 사항<br>

- 실제 운영시스템에 적용 → 상용/오픈소스 도구 활용 or 자체개발 → 데이터크기&처리속도 고려하여 적용
- 상용/오픈소스 도구에서 기능을 제공할 때만, 자동화 적용 → 모델 적용 및 갱신 자동화
- 기법에 따른 고려사항
	- 시뮬레이션: 모델적용을 위한 프로세스&업무규칙이 문서화되고 공유됨
	- 최적화: 결과를 시스템과 인터페이스 가능하도록 데이터베이스 연동 프로그램을 개발
	
---

### 4) 분석 모형 리모델링

<br>
(1) 분석 모형 리모델링<br>

- 리모델링
	- 빅데이터 모형의 지속적인 성과 모니터링을 통해 편차가 일정수준 이상으로 지속적으로 하락하는 경우에 기존 모형에 데이터마이닝/시뮬레이션/최적화를 적용하는 개조작업
- 리모델링 수행주기: 분기/반기/연 단위가 바람직
- 리모델링 업무 및 주기

|기법|데이터 마이닝|시뮬레이션|최적화|
|:---:|:---:|:---:|:---:|
|리모델링 시<br>수행하는 업무|동일한 데이터에 대해<br>재학습 or 변수추가|이벤트 발생 패턴 변화,<br>시간 지연 변화 등을 처리|목적함수의 계수 변경 or<br>제약조건의 제약 값 변화&추가|
|주기|분기|반기 or<br>주요변경이 이루어지는 시점|연 단위|

<br>
(2) 분석 모형 리모델링 절차<br>
📌 개선용 데이터 수집&처리 → 분석 모델 개선 → 분석 결과 평가&분석 모델 등록

- 개선용 데이터 수집 및 처리: 기존 모델 성능 검토/개선 데이터 선정
- 분석 모델 개선: 분석 알고리즘 선정 / 알고리즘 수행 및 분석결과 기록
	- 개선용 데이터 수집&처리
		- 기존 모델 성능 검토
			- 현황 분석 → 성능 검토 → 개선필요성 결정
		- 개선 데이터 선정
			- 제외할 데이터가 있는지 점검, 정제, 변환
		- 개선 데이터 선정 시 고려사항
			- 데이터활용도/변경도/오류율/데이터 오류율/분석가의 판단
	- 분석 모델 개선
		- 모델 개발했을 떄와 같은 절차
		- 기존 모델보다 성능이 높아지도록 파라미터를 조정하여 다시 개발
		- 분석 알고리즘 선정
			- 개선 목적&데이터 선정
			- 기존 데이터의 변경 내역 조사
		- 알고리즘 수행 및 분석결과 기록
			- 학습/검증/시험용 데이터를 분할할 때, 추가된 신규 데이터가 반영될 수 있도록
	- 분석 결과 평가 & 분석 모델 등록
		- 다양한 이해관계자가 모여 리뷰&선정
		- 분석가/데이터처리자/고객 등
		- 평가 및 등록 절차
			- 평가 기준 선정 → 분석 결과 검토 → 알고리즘별 결과 비교
			
<br>
(3) 분석 모형 리모델링 고려사항<br>
📌 정기적인 재평가와 모형 재조정(필요한 경우)이 필요함

- 모형 재조정 주기 설정
	- 초기에 자주 수행(주기 짧게) → 점진적으로 주기를 길게 설정(업무 특성에 따라 차이 있음)
- 업무 자동화
	- 관리해야하는 모델이 월 20개 이상 or 다른 업무와 함께 수행해야 하는 경우 권고됨
- 리모델링 고려사항
	- 데이터 마이닝: 최신 데이터 적용/변수 추가
	- 시뮬레이션: 업무 프로세스 KPI 변경, 주요 시스템 원칙 변경, 발생 이벤트 건수 증가에 따른 성능평가와 재조정
	- 최적화: 조건 변화, 가중치 변화, 계수값 조장, 제약조건 추가
	
---
